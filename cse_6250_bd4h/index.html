<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-04-08 Tue 19:16 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>BD4H</title>
<meta name="author" content="W" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../src/readtheorg_theme/css/readtheorg.css"/>
<script type="text/javascript" src="../src/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="../src/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="../src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">BD4H</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgf37c823">1. Introduction to Big Data</a>
<ul>
<li><a href="#org51276ea">1.1. Introduction</a></li>
<li><a href="#org55f7446">1.2. About BDAH</a></li>
<li><a href="#orgd9ae1dd">1.3. Learning Goals</a></li>
<li><a href="#org2df343f">1.4. Current Problems in Healthcare</a></li>
<li><a href="#org5f8a17e">1.5. The Four Vs</a></li>
<li><a href="#org8da0419">1.6. More About The Four Vs</a></li>
<li><a href="#orgd24d821">1.7. Data Science is Sexy</a></li>
<li><a href="#org548952d">1.8. BDAH Quiz 1 Question</a></li>
<li><a href="#orgebf06f6">1.9. BDAH Quiz 1 Solution</a></li>
<li><a href="#org4b6e166">1.10. BDAH Quiz 2 Question</a></li>
<li><a href="#org2d55ca8">1.11. BDAH Quiz 2 Solution</a></li>
<li><a href="#org6bb6397">1.12. BDAH Quiz 3 Question</a></li>
<li><a href="#org14eed08">1.13. BDAH Quiz 3 Solution</a></li>
</ul>
</li>
<li><a href="#org209ab2a">2. Big Data Course Overview</a>
<ul>
<li><a href="#org37546d2">2.1. Introduction to Course Overview</a></li>
<li><a href="#org1c110ef">2.2. Big Data Big Picture</a></li>
<li><a href="#orga4bf8ff">2.3. Healthcare Applications</a></li>
<li><a href="#org96cea0d">2.4. Predictive Modeling Quiz Question</a></li>
<li><a href="#org939a101">2.5. Predictive Modeling Quiz Solution</a></li>
<li><a href="#orgb93f6af">2.6. Predictive Modeling Challenges</a></li>
<li><a href="#org3d7b513">2.7. Computational Phenotyping</a></li>
<li><a href="#orga35c4cf">2.8. Computational Phenotyping Quiz Question</a></li>
<li><a href="#org5747d46">2.9. Computational Phenotyping Quiz Solution</a></li>
<li><a href="#orgd1fa721">2.10. Phenotyping Algorithm</a></li>
<li><a href="#org1cf4f0d">2.11. Patient Similarity Quiz Question</a></li>
<li><a href="#org8dbcb2b">2.12. Patient Similarity Quiz Solution</a></li>
<li><a href="#org9aed380">2.13. Patient Similarity</a></li>
<li><a href="#org168cdef">2.14. Algorithms</a></li>
<li><a href="#orge731666">2.15. Systems</a></li>
<li><a href="#org7b85ae4">2.16. Summary</a></li>
</ul>
</li>
<li><a href="#org10dd0bc">3. Predictive Modeling</a>
<ul>
<li><a href="#orgf7b54af">3.1. Introduction to Predictive Modeling</a></li>
<li><a href="#org154f6ce">3.2. Predictive Modeling vs EHR</a></li>
<li><a href="#orge3c1b39">3.3. Predictive Modeling Pipeline</a></li>
<li><a href="#org040f4cb">3.4. Prediction Target</a></li>
<li><a href="#org02f16a9">3.5. Heart Failure Quiz</a></li>
<li><a href="#org34c727d">3.6. Motivations for Early Detection</a></li>
<li><a href="#orgfc6660a">3.7. Cohort Construction</a></li>
<li><a href="#org0db721c">3.8. Prospective vs. Retrospective Studies</a></li>
<li><a href="#orgd2a7651">3.9. Prospective vs. Retrospective Quiz</a></li>
<li><a href="#org44d93a3">3.10. Cohort Study</a></li>
<li><a href="#org20fb0a5">3.11. Case-Control Study</a></li>
<li><a href="#org6185c92">3.12. Feature Construction</a></li>
<li><a href="#orga4021a8">3.13. Feature Construction Quizzes</a></li>
<li><a href="#org9c05e0c">3.14. Prediction Performance on Windows</a></li>
<li><a href="#org9952f14">3.15. Feature Selection</a></li>
<li><a href="#org291e60d">3.16. Predictive Model</a></li>
<li><a href="#orgf8cf417">3.17. Performance Evaluation</a></li>
<li><a href="#org5cc3c3c">3.18. Cross-Validation</a></li>
<li><a href="#org9352ca6">3.19. Conclusion</a></li>
</ul>
</li>
<li><a href="#org7319c5c">4. MapReduce&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a>
<ul>
<li><a href="#org5827340">4.1. Introduction to MapReduce</a></li>
<li><a href="#org1b52cec">4.2. What is MapReduce</a></li>
<li><a href="#org2139899">4.3. Computational Process</a></li>
<li><a href="#org61fe62d">4.4. Learning Via Aggregation Statistics</a></li>
<li><a href="#org13c55e1">4.5. MapReduce Abstraction</a></li>
<li><a href="#org156e7cf">4.6. MapReduce System</a></li>
<li><a href="#org251fa5c">4.7. MapReduce Fault Recovery</a></li>
<li><a href="#orgc3ad803">4.8. Distributed File Systems</a></li>
<li><a href="#orged2b77f">4.9. MapReduce Design Choice</a></li>
<li><a href="#org8cab3e3">4.10. Analytics with MapReduce</a></li>
<li><a href="#org0878d01">4.11. MapReduce KNN&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#org5d2f051">4.12. Linear Regression</a></li>
<li><a href="#org695ddd5">4.13. MapReduce for Linear Regression Quiz Question</a></li>
<li><a href="#org18faa0c">4.14. MapReduce for Linear Regression Quiz Solution</a></li>
<li><a href="#orgbea84c2">4.15. Limitations of MapReduce&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#org8708dd3">4.16. MapReduce Summary Quiz Question</a></li>
<li><a href="#org3a6d998">4.17. MapReduce Summary Quiz Solution</a></li>
</ul>
</li>
<li><a href="#org733a814">5. Classification Model Metrics</a>
<ul>
<li><a href="#orgfc294f0">5.1. Predictive Model review</a></li>
<li><a href="#org2bae16c">5.2. Confusion matrix</a></li>
<li><a href="#org98aef9d">5.3. Accuracy metrics</a>
<ul>
<li><a href="#orgd4b690b">5.3.1. Other notes</a></li>
</ul>
</li>
<li><a href="#org60e2667">5.4. Predictive metrics</a></li>
<li><a href="#org92fa6c6">5.5. F1 score</a></li>
<li><a href="#orgdff0b89">5.6. Classifier quiz</a></li>
<li><a href="#org60c177d">5.7. Reversing predictions</a></li>
<li><a href="#org91ca78e">5.8. Receiver operating characteristic</a></li>
<li><a href="#org3dc9c83">5.9. "Best classifier threshold" quiz</a></li>
<li><a href="#orgd162485">5.10. Regression metrics</a>
<ul>
<li><a href="#org33c5fc9">5.10.1. \(R^2\)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org57523ed">6. Ensemble methods</a>
<ul>
<li><a href="#org945ee8e">6.1. Gradient Descent Method (GDM) for Linear Regression</a></li>
<li><a href="#orga3c2cde">6.2. Stochastic Gradient Descent (SGD) Method</a></li>
<li><a href="#org08597ae">6.3. SGD for Linear Regression</a></li>
<li><a href="#org169c019">6.4. Ensemble Method Pt 1</a></li>
<li><a href="#orge85508b">6.5. Ensemble Method Pt 2</a></li>
<li><a href="#org50b8cd7">6.6. Bias Variance Tradeoff</a></li>
<li><a href="#orga9f43b2">6.7. Bias Variance Tradeoff Quiz Question</a></li>
<li><a href="#org5c7f778">6.8. Bias Variance Tradeoff Quiz Solution</a></li>
<li><a href="#org2bca06e">6.9. Bias Variance Tradeoff Quiz 2 Question</a></li>
<li><a href="#org1f7d0c2">6.10. Bias Variance Tradeoff Quiz 2 Solution</a></li>
<li><a href="#org3db2cb0">6.11. Bagging</a></li>
<li><a href="#org768d7bb">6.12. Random Forest&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#org09ddcd0">6.13. Why Bagging Works</a></li>
<li><a href="#org74a4901">6.14. Boosting</a></li>
<li><a href="#org53c9550">6.15. Bagging vs Boosting Quiz Question</a></li>
<li><a href="#orgef19d77">6.16. Bagging vs Boosting Quiz Solution</a></li>
<li><a href="#orgdd378d1">6.17. Summary for Ensemble Methods</a></li>
</ul>
</li>
<li><a href="#orgefe1990">7. Computational Phenotyping</a>
<ul>
<li><a href="#orgb407b5a">7.1. Introduction to Phenotyping</a></li>
<li><a href="#org64a428e">7.2. Computational Phenotyping</a></li>
<li><a href="#org79e7dfd">7.3. Phenotyping Algorithm</a></li>
<li><a href="#org74d4853">7.4. Applications of Phenotyping</a></li>
<li><a href="#orga8639d7">7.5. Genomic Wide Association Study</a></li>
<li><a href="#org3de99b1">7.6. Why Do We Care About Phenotyping</a></li>
<li><a href="#orgce67c30">7.7. Clinical Predictive Modeling</a></li>
<li><a href="#org177f684">7.8. Pragmatic Clinical Trials</a></li>
<li><a href="#org3d484da">7.9. Healthcare Quality Measurement</a></li>
<li><a href="#org06dc05a">7.10. Phenotyping Methods Part 1</a></li>
<li><a href="#orga3b1c2d">7.11. Phenotyping Methods Part 2</a></li>
<li><a href="#org23a9418">7.12. Phenotyping Quiz Question</a></li>
<li><a href="#org56699c0">7.13. Phenotyping Quiz Solution</a></li>
</ul>
</li>
<li><a href="#orgf6a5297">8. Clustering</a>
<ul>
<li><a href="#org4771777">8.1. Introduction to Clustering</a></li>
<li><a href="#org7a3a8bd">8.2. Healthcare Applications</a></li>
<li><a href="#org75b3cb4">8.3. What is Clustering</a></li>
<li><a href="#org75a59d8">8.4. Algorithm Overview</a></li>
<li><a href="#orgbb4c490">8.5. K Means</a></li>
<li><a href="#org0048606">8.6. K Means Quiz Question</a></li>
<li><a href="#org944530f">8.7. K Means Quiz Solution</a></li>
<li><a href="#orgd868955">8.8. Hierarchical Clustering</a></li>
<li><a href="#org240759b">8.9. Agglomerative Clustering</a></li>
<li><a href="#org08eca5e">8.10. Gaussian Mixture Model</a></li>
<li><a href="#orgd2a30c3">8.11. GMM Expectation Maximization&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#orgffad891">8.12. GMM Steps</a></li>
<li><a href="#org32679b4">8.13. GMM Visual Illustration</a></li>
<li><a href="#org37a6971">8.14. K Means Vs GMM&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#orgb769d4f">8.15. Mini Batch K Means</a></li>
<li><a href="#orgdc82de2">8.16. Mini Batch K Means Quiz Question</a></li>
<li><a href="#orga52aa86">8.17. Mini Batch K Means Quiz Solution</a></li>
<li><a href="#org2e219e7">8.18. DBScan</a></li>
<li><a href="#org399c207">8.19. DBScan Key Concepts</a></li>
<li><a href="#orge08291c">8.20. DBScan Algorithm</a></li>
<li><a href="#org0395cbc">8.21. DBScan Example</a></li>
<li><a href="#org57c82e0">8.22. DBScan Quiz Question</a></li>
<li><a href="#org1f77296">8.23. DBScan Quiz Solution</a></li>
<li><a href="#org8875349">8.24. Clustering Evaluation Metrics</a></li>
<li><a href="#org64bb603">8.25. Rand Index</a></li>
<li><a href="#orgec64ecd">8.26. Mutual Information</a></li>
<li><a href="#orgb8fce8f">8.27. Summary of RI and MI</a></li>
<li><a href="#org960b1c8">8.28. Silhouette Coefficient</a></li>
<li><a href="#orge2dfcc5">8.29. Silhouette Coefficient Pros and Cons</a></li>
</ul>
</li>
<li><a href="#org8709cbe">9. Spark&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a>
<ul>
<li><a href="#orgedd9b63">9.1. Introduction to Spark</a></li>
<li><a href="#org21d7eef">9.2. Environment</a></li>
<li><a href="#org2005716">9.3. Motivation</a></li>
<li><a href="#org1cc1ecc">9.4. Iteration in Map Reduce</a></li>
<li><a href="#orgb5d4679">9.5. Workload Illustration</a></li>
<li><a href="#org3e9392e">9.6. Challenge</a></li>
<li><a href="#orgd001c91">9.7. Solution: RDDs</a></li>
<li><a href="#org55c7f57">9.8. RDD Recovery</a></li>
<li><a href="#org050f735">9.9. Spark Stack</a></li>
<li><a href="#org4eca585">9.10. Spark Programming Interface</a></li>
<li><a href="#org3641e18">9.11. RDD Transformations</a></li>
<li><a href="#org25adadd">9.12. RDD Transformations Quiz Question</a></li>
<li><a href="#org04d7c22">9.13. RDD Transformations Quiz Solution</a></li>
<li><a href="#org5c20d6a">9.14. Spark Operations</a></li>
<li><a href="#org3b0f7be">9.15. Shared Variable</a></li>
<li><a href="#orgbe2d63b">9.16. Fault Tolerance</a></li>
<li><a href="#org0b4ad8a">9.17. Example: <span style='background-color: #FFFF00;'>Logistic Regression</span>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#org1416306">9.18. Example: Disease Risk Prediction</a></li>
<li><a href="#orgad33a85">9.19. Serial ALS</a></li>
<li><a href="#orgd6aa8ee">9.20. Naive Spark ALS</a></li>
</ul>
</li>
<li><a href="#org31cff0d">10. Medical Ontology</a>
<ul>
<li><a href="#org2816931">10.1. Introduction to Medical Ontology</a></li>
<li><a href="#org4994dc3">10.2. Health Data Standards</a></li>
<li><a href="#org326d0a3">10.3. ICD</a></li>
<li><a href="#orge9a4fb6">10.4. ICD 9 to ICD 10 Mapping</a></li>
<li><a href="#org446139e">10.5. ICD 9 Quiz Question</a></li>
<li><a href="#orge4918d4">10.6. ICD 9 Quiz Solution</a></li>
<li><a href="#org6e43698">10.7. ICD Code Quiz Question</a></li>
<li><a href="#orge047fa7">10.8. ICD Code Quiz Solution</a></li>
<li><a href="#org5909d7f">10.9. CPT</a></li>
<li><a href="#orgde076da">10.10. CPT Code Quiz Question</a></li>
<li><a href="#orgde970ee">10.11. CPT Code Quiz Solution</a></li>
<li><a href="#orga017774">10.12. LOINC</a></li>
<li><a href="#orgb72d1ed">10.13. LOINC Code Quiz Question</a></li>
<li><a href="#org3e67961">10.14. LOINC Code Quiz Solution</a></li>
<li><a href="#orgd08423c">10.15. NDC</a></li>
<li><a href="#orgdb1ff45">10.16. NDC Code Quiz Question</a></li>
<li><a href="#orgc591b17">10.17. NDC Code Quiz Solution</a></li>
<li><a href="#org85b02f1">10.18. SNOMED</a></li>
<li><a href="#org96fc2c1">10.19. Logical Model of SNOMED CT</a></li>
<li><a href="#orgd0e705b">10.20. SNOMED Example</a></li>
<li><a href="#org14de742">10.21. SNOMED Relationships</a></li>
<li><a href="#org2eb4ef6">10.22. SNOMED Design</a></li>
<li><a href="#orgedb4911">10.23. SNOMED Code Quiz Question</a></li>
<li><a href="#org6dded5c">10.24. SNOMED Code Quiz Solution</a></li>
<li><a href="#orga034638">10.25. SNOMED Quiz Question</a></li>
<li><a href="#org135ddae">10.26. SNOMED Quiz Solution</a></li>
<li><a href="#org457ad4a">10.27. UMLS</a></li>
<li><a href="#orgf90c1df">10.28. Metathesaurus Concepts</a></li>
<li><a href="#orgcccaa38">10.29. Semantic Network</a></li>
<li><a href="#orgc975459">10.30. Specialist Lexicon</a></li>
</ul>
</li>
<li><a href="#org4c5999f">11. Graph Analysis</a>
<ul>
<li><a href="#org1769ef1">11.1. Introduction to Graph Analysis</a></li>
<li><a href="#org36ddb8d">11.2. Agenda</a></li>
<li><a href="#orgbe95395">11.3. PageRank</a></li>
<li><a href="#orga5b6b62">11.4. MapReduce  PageRank</a></li>
<li><a href="#org4b5fdbc">11.5. PageRank Quiz Question</a></li>
<li><a href="#org9bc89f1">11.6. PageRank Quiz Solution</a></li>
<li><a href="#orge0bc9f6">11.7. Spectral Clustering</a></li>
<li><a href="#orgf230405">11.8. Similarity Graph Construction</a></li>
<li><a href="#org18eba61">11.9. E Neighborhood Graph</a></li>
<li><a href="#orgdd66653">11.10. K Nearest Neighbor Graph</a></li>
<li><a href="#org14cb179">11.11. Fully Connected Graph</a></li>
<li><a href="#orgfe40e4b">11.12. E Neighborhood Graph Quiz Question</a></li>
<li><a href="#orgae4fba1">11.13. E Neighborhood Graph Quiz Solution</a></li>
<li><a href="#orgb72f88e">11.14. Spectral Clustering Algorithm</a></li>
<li><a href="#orge5b04e6">11.15. Big Data Conclusion</a></li>
</ul>
</li>
<li><a href="#org113db2f">12. Dimensionality Reduction</a>
<ul>
<li><a href="#orgf356b8d">12.1. Introduction to Dimensionality Reduction</a></li>
<li><a href="#org30b683f">12.2. Dimensionality Reduction</a></li>
<li><a href="#org54b2f47">12.3. Singular Value Decomposition</a></li>
<li><a href="#org0f1d7e1">12.4. SVD Example</a></li>
<li><a href="#org474655d">12.5. SVD Properties</a></li>
<li><a href="#orgfddce12">12.6. Quiz  SVD Interpretation Question</a></li>
<li><a href="#orga43dea8">12.7. Quiz  SVD Interpretation Solution</a></li>
<li><a href="#orgcf4a5d6">12.8. Principal Component Analysis</a></li>
<li><a href="#org9b881c4">12.9. PCA Interpretation</a></li>
<li><a href="#orgec4c114">12.10. Sparsity Problem with SVD</a></li>
<li><a href="#org8b48ad5">12.11. CUR Decomposition</a></li>
<li><a href="#org8fd8514">12.12. CUR Algorithm</a></li>
<li><a href="#orge79628e">12.13. CUR Quiz Question</a></li>
<li><a href="#org87ba193">12.14. CUR Quiz Solution</a></li>
<li><a href="#org220d661">12.15. Tensor for EHR</a></li>
<li><a href="#org19c57d8">12.16. Tensor Slicing</a></li>
<li><a href="#org88ec6c4">12.17. Rank 1 Tensor</a></li>
<li><a href="#org5cd1ecc">12.18. Example Phenotype</a></li>
<li><a href="#org1eb94e1">12.19. Phenotyping Through Tensor Factorization</a></li>
<li><a href="#org1852059">12.20. CP Decomposition</a></li>
<li><a href="#orge1c9473">12.21. Phenotyping Process Using Tensor Factorization</a></li>
<li><a href="#orged1c1b5">12.22. Phenotyping for Predictive Modeling</a></li>
<li><a href="#org86682ab">12.23. Predictive Performance</a></li>
<li><a href="#orga16e176">12.24. Major Disease Phenotypes</a></li>
<li><a href="#orgbe80a0c">12.25. Tensor vs NMF</a></li>
<li><a href="#org672b029">12.26. Summary: Phenotyping Via Tensor Factorization</a></li>
</ul>
</li>
<li><a href="#org78716c6">13. Patient Similarity</a>
<ul>
<li><a href="#orgd86f2a8">13.1. Introduction to Patient Similarity</a></li>
<li><a href="#orgd6c1de9">13.2. Motivation</a></li>
<li><a href="#org72d3f32">13.3. Traditional Paradigm</a></li>
<li><a href="#orgbe18684">13.4. New Paradigm</a></li>
<li><a href="#org80cc48d">13.5. Randomized Clinical Trials</a></li>
<li><a href="#org8a160df">13.6. RCT Quiz Question</a></li>
<li><a href="#org99cf62f">13.7. RCT Quiz Solution</a></li>
<li><a href="#orgfbb97bb">13.8. Pragmatic Trials</a></li>
<li><a href="#orge6ee6cb">13.9. Pragmatic Trial Quiz Question</a></li>
<li><a href="#org0d74639">13.10. Pragmatic Trial Quiz Solution</a></li>
<li><a href="#orgb05a532">13.11. Utilize Patient Similarity</a></li>
<li><a href="#org3415add">13.12. Patient Similarity Approaches</a></li>
<li><a href="#org4b76115">13.13. Patient Similarity Through LSML</a></li>
</ul>
</li>
<li><a href="#org6f02143">14. Deep Neural Network</a>
<ul>
<li><a href="#org4e45514">14.1. Backward Computation for a Neuron</a></li>
<li><a href="#org037fb43">14.2. Sigmoid Function</a></li>
<li><a href="#org818dc43">14.3. TANH Function</a></li>
<li><a href="#org2a27c93">14.4. Rectified Linear Function</a></li>
<li><a href="#org4eba856">14.5. Activation Functions: Summary</a></li>
<li><a href="#org1af73d6">14.6. Train a Single Neuron</a></li>
<li><a href="#orgb7c5c3c">14.7. Stochastic Gradient Descent (SGD)</a></li>
<li><a href="#orga61c776">14.8. Forward Computation for a Neuron</a></li>
<li><a href="#orge50fd23">14.9. Backward Computation for a Neuron</a></li>
<li><a href="#org5a0f70b">14.10. Multilayer Neural Network</a></li>
<li><a href="#orgbe6c77d">14.11. Train a Multilayer Neural Network</a></li>
<li><a href="#orgc85fe6a">14.12. Forward Computation Part 1</a></li>
<li><a href="#org97ec294">14.13. Forward Computation Part 2</a></li>
<li><a href="#org7218c07">14.14. Forward Computation: Vector Form</a></li>
<li><a href="#org6c7ab6c">14.15. Forward Computation: More General Form</a></li>
<li><a href="#org8b63690">14.16. Forward Computation: Summary</a></li>
<li><a href="#orga4baea8">14.17. Gradient Descent for Neural Networks</a></li>
<li><a href="#orgfa5b1a8">14.18. Backward Propagation Part 1</a></li>
<li><a href="#org71f64e0">14.19. Backward Propagation Part 2</a></li>
<li><a href="#org9d5636f">14.20. Backward Propagation Part 3</a></li>
<li><a href="#orgf62a5b9">14.21. Backward Propagation Part 4</a></li>
<li><a href="#org8dbb45d">14.22. Backward Propagation Part 5</a></li>
<li><a href="#org4173b41">14.23. Backward Propagation Part 6</a></li>
<li><a href="#org75cd254">14.24. Backward Propagation Summary&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
</ul>
</li>
<li><a href="#orga1b1eaa">15. Convolutional Neural Network&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a>
<ul>
<li><a href="#org0eb6b42">15.1. Convolution Local Networks</a></li>
<li><a href="#org5743d1e">15.2. Pooling Handling Distortion</a></li>
<li><a href="#orgb6dae34">15.3. Convolutional Neural Networks</a></li>
<li><a href="#org8d5479e">15.4. Key Stages of CNN</a></li>
<li><a href="#org6ce2e9c">15.5. 1-D Convolution</a></li>
<li><a href="#orgd2c8d63">15.6. Neural Network for 1-D Convolution</a></li>
<li><a href="#org7544831">15.7. 2-D Convolution Operation</a></li>
<li><a href="#org8ed8d24">15.8. Convolution Layers</a></li>
<li><a href="#orgcb0836a">15.9. Pooling Layers&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#org19252e1">15.10. Dimension Calculation of Convolution Layers&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#org58ceded">15.11. Dimension Calculation of Pooling Layer</a></li>
<li><a href="#orgb512387">15.12. Parameter Count</a></li>
<li><a href="#org859e4e8">15.13. Forward Calculation of Convolution</a></li>
<li><a href="#org4ac5ee0">15.14. Forward Calculation of Pooling Layers</a></li>
<li><a href="#orge8985bc">15.15. Forward Calculation of Fully-Connected Layers</a></li>
<li><a href="#org040c9b7">15.16. Operation Count</a></li>
<li><a href="#orgedcf3c5">15.17. CNN Architectures and Healthcare Applications</a></li>
<li><a href="#org42fa350">15.18. Diabetic Retinopathy Diagnosis</a></li>
<li><a href="#orgf632e13">15.19. Dermatologist Classification of Skin Cancer with DNN</a></li>
</ul>
</li>
<li><a href="#org1821b7a">16. Recurrent Neural Network</a>
<ul>
<li><a href="#org049eb0a">16.1. Basic Concepts of RNN</a></li>
<li><a href="#org93d7c50">16.2. Basic RNN Structure&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></a></li>
<li><a href="#orga27b989">16.3. Forward Computation</a></li>
<li><a href="#org6dc96d1">16.4. Backpropagation Through Time</a></li>
<li><a href="#orgd6c447e">16.5. Standard RNN</a></li>
<li><a href="#org6e82bdb">16.6. Long Short Term Memory Networks</a></li>
<li><a href="#org1d8daee">16.7. Gated Recurred Unit</a></li>
<li><a href="#org5d72bac">16.8. Bidirectional RNN</a></li>
<li><a href="#orgb3cae1a">16.9. Sequence to Sequence RNN</a>
<ul>
<li><a href="#orgb9de697">16.9.1. Overview</a></li>
<li><a href="#org8d8fd82">16.9.2. Encoding Phase</a></li>
<li><a href="#orgc27599b">16.9.3. Decoding Phase</a></li>
<li><a href="#orgc8caf31">16.9.4. Applications</a></li>
<li><a href="#org48178fb">16.9.5. Key Insight</a></li>
</ul>
</li>
<li><a href="#orga4f119e">16.10. Healthcare Applications</a></li>
</ul>
</li>
<li><a href="#org40651ca">17. Focus</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf37c823" class="outline-2">
<h2 id="orgf37c823"><span class="section-number-2">1.</span> Introduction to Big Data</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org51276ea" class="outline-3">
<h3 id="org51276ea"><span class="section-number-3">1.1.</span> Introduction</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>Course: Big Data Analytics for Healthcare (BDAH)</li>
<li>Instructor: Jimeng Sun, associate professor at Georgia Tech</li>
<li>Background: Expertise in healthcare analytics and data mining, previous work at IBM TJ Watson Research Center</li>
<li>Course focus: What students will learn and why it matters</li>
</ul>
</div>
</div>

<div id="outline-container-org55f7446" class="outline-3">
<h3 id="org55f7446"><span class="section-number-3">1.2.</span> About BDAH</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>Intersection of healthcare and big data</li>
<li>Covers healthcare applications, data, analytics, and big data processing</li>
<li>Focus on how data science is applied to healthcare</li>
</ul>
</div>
</div>

<div id="outline-container-orgd9ae1dd" class="outline-3">
<h3 id="orgd9ae1dd"><span class="section-number-3">1.3.</span> Learning Goals</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>Understand healthcare data</li>
<li>Learn analytics algorithms</li>
<li>Work with big data systems</li>
<li>Application: Build models for disease risk prediction, treatment recommendation, patient clustering, and similarity analysis</li>
<li>Assessments: Homework using big data tools, project with system building, report writing, and presentations</li>
</ul>
</div>
</div>

<div id="outline-container-org2df343f" class="outline-3">
<h3 id="org2df343f"><span class="section-number-3">1.4.</span> Current Problems in Healthcare</h3>
<div class="outline-text-3" id="text-1-4">
<ul class="org-ul">
<li>High costs: $3.8 trillion/year in the U.S.</li>
<li>Massive waste: $765 billion/year</li>
<li>Poor quality: 200,000-400,000 preventable deaths annually</li>
<li>Preventable deaths ranked as the third leading cause of death</li>
<li>Hope: Big data can improve care and reduce costs</li>
</ul>
</div>
</div>

<div id="outline-container-org5f8a17e" class="outline-3">
<h3 id="org5f8a17e"><span class="section-number-3">1.5.</span> The Four Vs</h3>
<div class="outline-text-3" id="text-1-5">
<ul class="org-ul">
<li>Volume: Large healthcare data amounts</li>
<li>Variety: Different types of healthcare data sources</li>
<li>Velocity: Real-time data processing needs</li>
<li>Veracity: Issues with data quality (noise, missing data, errors)</li>
</ul>
</div>
</div>

<div id="outline-container-org8da0419" class="outline-3">
<h3 id="org8da0419"><span class="section-number-3">1.6.</span> More About The Four Vs</h3>
<div class="outline-text-3" id="text-1-6">
<ul class="org-ul">
<li>Examples of data volume:
<ul class="org-ul">
<li>Genomic data: 200 GB per genome</li>
<li>fMRI scan: ~300 GB per scan</li>
<li>US medical imaging data per year: ~100 petabytes</li>
</ul></li>
<li>Data variety:
<ul class="org-ul">
<li>Clinical (demographics, diagnosis, procedures, etc.)</li>
<li>Patient-generated (wearables, sensors)</li>
<li>Real-time (ICU monitoring data)</li>
</ul></li>
<li>Focus on managing diverse data types in the course</li>
</ul>
</div>
</div>

<div id="outline-container-orgd24d821" class="outline-3">
<h3 id="orgd24d821"><span class="section-number-3">1.7.</span> Data Science is Sexy</h3>
<div class="outline-text-3" id="text-1-7">
<ul class="org-ul">
<li>Data science is a critical field</li>
<li>Harvard Business Review: "Data Scientist, The Sexiest Job in the 21st Century"</li>
<li>Data scientists:
<ul class="org-ul">
<li>Capitalize on big data</li>
<li>Overcome technical limitations</li>
<li>Develop key tools like Hadoop and Spark</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org548952d" class="outline-3">
<h3 id="org548952d"><span class="section-number-3">1.8.</span> BDAH Quiz 1 Question</h3>
<div class="outline-text-3" id="text-1-8">
<ul class="org-ul">
<li>True/False: A graduate-level degree is necessary to become a data scientist.</li>
</ul>
</div>
</div>

<div id="outline-container-orgebf06f6" class="outline-3">
<h3 id="orgebf06f6"><span class="section-number-3">1.9.</span> BDAH Quiz 1 Solution</h3>
<div class="outline-text-3" id="text-1-9">
<ul class="org-ul">
<li>Answer: True</li>
</ul>
</div>
</div>

<div id="outline-container-org4b6e166" class="outline-3">
<h3 id="org4b6e166"><span class="section-number-3">1.10.</span> BDAH Quiz 2 Question</h3>
<div class="outline-text-3" id="text-1-10">
<ul class="org-ul">
<li>Question: What is the average salary of a data scientist?</li>
</ul>
</div>
</div>

<div id="outline-container-org2d55ca8" class="outline-3">
<h3 id="org2d55ca8"><span class="section-number-3">1.11.</span> BDAH Quiz 2 Solution</h3>
<div class="outline-text-3" id="text-1-11">
<ul class="org-ul">
<li>Answer: $120,000 per year (experienced data scientists earn over $150,000)</li>
</ul>
</div>
</div>

<div id="outline-container-org6bb6397" class="outline-3">
<h3 id="org6bb6397"><span class="section-number-3">1.12.</span> BDAH Quiz 3 Question</h3>
<div class="outline-text-3" id="text-1-12">
<ul class="org-ul">
<li>Question: What skills do data scientists need?</li>
</ul>
</div>
</div>

<div id="outline-container-org14eed08" class="outline-3">
<h3 id="org14eed08"><span class="section-number-3">1.13.</span> BDAH Quiz 3 Solution</h3>
<div class="outline-text-3" id="text-1-13">
<ul class="org-ul">
<li>Answer:
<ul class="org-ul">
<li>Math and statistics</li>
<li>Domain knowledge</li>
<li>Programming and databases</li>
<li>Communication and visualization</li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org209ab2a" class="outline-2">
<h2 id="org209ab2a"><span class="section-number-2">2.</span> Big Data Course Overview</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org37546d2" class="outline-3">
<h3 id="org37546d2"><span class="section-number-3">2.1.</span> Introduction to Course Overview</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>Overview of big data analytics for healthcare.</li>
<li>Topics covered:
<ul class="org-ul">
<li>Healthcare applications of big data.</li>
<li>Algorithms used in applications.</li>
<li>Software systems for implementation.</li>
</ul></li>
<li>Course structure alternates among these topics.</li>
</ul>
</div>
</div>

<div id="outline-container-org1c110ef" class="outline-3">
<h3 id="org1c110ef"><span class="section-number-3">2.2.</span> Big Data Big Picture</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li>Course focuses on three key areas:
<ul class="org-ul">
<li>Big data systems.</li>
<li>Scalable machine learning algorithms.</li>
<li>Healthcare applications.</li>
</ul></li>
<li>Integration of these elements to solve healthcare problems.</li>
</ul>
</div>
</div>

<div id="outline-container-orga4bf8ff" class="outline-3">
<h3 id="orga4bf8ff"><span class="section-number-3">2.3.</span> Healthcare Applications</h3>
<div class="outline-text-3" id="text-2-3">
<ul class="org-ul">
<li>Three types of healthcare applications:
<ol class="org-ol">
<li><b><b>Predictive Modeling</b></b>: Uses historical data to predict future outcomes.</li>
<li><b><b>Computational Phenotyping</b></b>: Converts electronic health records (EHRs) into meaningful clinical concepts.</li>
<li><b><b>Patient Similarity</b></b>: Identifies groups of patients with similar characteristics.</li>
</ol></li>
<li>Starts with predictive modeling.</li>
</ul>
</div>
</div>

<div id="outline-container-org96cea0d" class="outline-3">
<h3 id="org96cea0d"><span class="section-number-3">2.4.</span> Predictive Modeling Quiz Question</h3>
<div class="outline-text-3" id="text-2-4">
<ul class="org-ul">
<li>Predictive modeling example: predicting treatment effectiveness for epilepsy patients.</li>
<li>Quiz: Estimate percentage of patients responding to different treatments.</li>
</ul>
</div>
</div>

<div id="outline-container-org939a101" class="outline-3">
<h3 id="org939a101"><span class="section-number-3">2.5.</span> Predictive Modeling Quiz Solution</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li>Solution breakdown:
<ul class="org-ul">
<li><b><b>Group A</b></b> (responded within 2 years): 32%.</li>
<li><b><b>Group B</b></b> (responded between 2-5 years): 24%.</li>
<li><b><b>Group C</b></b> (did not respond after 5 years): 44%.</li>
</ul></li>
<li>Goal of predictive modeling:
<ul class="org-ul">
<li>Improve early response rates.</li>
<li>Identify non-responders for alternative treatments.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgb93f6af" class="outline-3">
<h3 id="orgb93f6af"><span class="section-number-3">2.6.</span> Predictive Modeling Challenges</h3>
<div class="outline-text-3" id="text-2-6">
<ul class="org-ul">
<li>Challenges in predictive modeling:
<ul class="org-ul">
<li>Handling large patient datasets with various types of data.</li>
<li>Managing multiple models in a complex computational pipeline.</li>
<li>Evaluating and comparing multiple predictive pipelines.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org3d7b513" class="outline-3">
<h3 id="org3d7b513"><span class="section-number-3">2.7.</span> Computational Phenotyping</h3>
<div class="outline-text-3" id="text-2-7">
<ul class="org-ul">
<li>Converts raw patient data (e.g., demographics, diagnoses, medications, procedures, lab tests, clinical notes) into clinical concepts or phenotypes.</li>
</ul>
</div>
</div>

<div id="outline-container-orga35c4cf" class="outline-3">
<h3 id="orga35c4cf"><span class="section-number-3">2.8.</span> Computational Phenotyping Quiz Question</h3>
<div class="outline-text-3" id="text-2-8">
<ul class="org-ul">
<li>Identifying data issues in phenotyping.</li>
<li>Quiz: List potential "waste products" in raw data.</li>
</ul>
</div>
</div>

<div id="outline-container-org5747d46" class="outline-3">
<h3 id="org5747d46"><span class="section-number-3">2.9.</span> Computational Phenotyping Quiz Solution</h3>
<div class="outline-text-3" id="text-2-9">
<ul class="org-ul">
<li>Common data issues:
<ul class="org-ul">
<li><b><b>Missing values</b></b>: Some important data may be absent.</li>
<li><b><b>Duplicates</b></b>: Patient records may appear multiple times.</li>
<li><b><b>Irrelevant data</b></b>: Not all raw information is useful.</li>
<li><b><b>Redundant information</b></b>: Different records may indicate the same condition (e.g., diagnosis and medication for diabetes).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgd1fa721" class="outline-3">
<h3 id="orgd1fa721"><span class="section-number-3">2.10.</span> Phenotyping Algorithm</h3>
<div class="outline-text-3" id="text-2-10">
<ul class="org-ul">
<li>Example: Identifying Type 2 Diabetes from EHR data.</li>
<li>Decision process:
<ul class="org-ul">
<li>Check for Type 1 Diabetes diagnosis.</li>
<li>Check for Type 2 Diabetes diagnosis.</li>
<li>Verify medication records and abnormal lab results.</li>
</ul></li>
<li>Importance:
<ul class="org-ul">
<li>EHR data is often unreliable.</li>
<li>Multiple data sources improve diagnostic accuracy.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org1cf4f0d" class="outline-3">
<h3 id="org1cf4f0d"><span class="section-number-3">2.11.</span> Patient Similarity Quiz Question</h3>
<div class="outline-text-3" id="text-2-11">
<ul class="org-ul">
<li>Different types of reasoning doctors use:
<ul class="org-ul">
<li>Flowchart-based reasoning (like phenotyping algorithms).</li>
<li>Instinct and intuition.</li>
<li>Case-based reasoning (comparing patients to past cases).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org8dbcb2b" class="outline-3">
<h3 id="org8dbcb2b"><span class="section-number-3">2.12.</span> Patient Similarity Quiz Solution</h3>
<div class="outline-text-3" id="text-2-12">
<ul class="org-ul">
<li>Correct answer: <b><b>Case-based reasoning</b></b>.</li>
<li>Doctors often compare current patients to previous similar cases.</li>
</ul>
</div>
</div>

<div id="outline-container-org9aed380" class="outline-3">
<h3 id="org9aed380"><span class="section-number-3">2.13.</span> Patient Similarity</h3>
<div class="outline-text-3" id="text-2-13">
<ul class="org-ul">
<li>Simulating case-based reasoning using algorithms.</li>
<li>Process:
<ul class="org-ul">
<li>Search for similar patients in a database.</li>
<li>Identify treatment outcomes for similar cases.</li>
<li>Recommend best treatment based on historical data.</li>
</ul></li>
<li>Objective: Utilize full database knowledge instead of relying on a single doctor's experience.</li>
</ul>
</div>
</div>

<div id="outline-container-org168cdef" class="outline-3">
<h3 id="org168cdef"><span class="section-number-3">2.14.</span> Algorithms</h3>
<div class="outline-text-3" id="text-2-14">
<ul class="org-ul">
<li>Introduction to machine learning algorithms in healthcare.</li>
<li>Covered topics:
<ol class="org-ol">
<li><b><b>Classification</b></b>: Mapping patient data to target variables (e.g., predicting heart attack risk).</li>
<li><b><b>Clustering</b></b>: Grouping similar patients based on health conditions.</li>
<li><b><b>Dimensionality Reduction</b></b>: Reducing large patient datasets to essential features.</li>
<li><b><b>Graph Analysis</b></b>: Analyzing relationships between patients and diseases.</li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-orge731666" class="outline-3">
<h3 id="orge731666"><span class="section-number-3">2.15.</span> Systems</h3>
<div class="outline-text-3" id="text-2-15">
<ul class="org-ul">
<li>Introduction to big data systems for healthcare applications.</li>
<li>Covered systems:
<ul class="org-ul">
<li><b><b>Hadoop</b></b>: Disk-based distributed system.</li>
<li><b><b>Spark</b></b>: In-memory distributed system (faster than Hadoop).</li>
</ul></li>
<li>Topics include:
<ul class="org-ul">
<li>Hadoop infrastructure (MapReduce, HDFS, Pig, Hive, HBase).</li>
<li>Spark infrastructure (Spark SQL, Spark Streaming, MLlib, GraphX).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org7b85ae4" class="outline-3">
<h3 id="org7b85ae4"><span class="section-number-3">2.16.</span> Summary</h3>
<div class="outline-text-3" id="text-2-16">
<ul class="org-ul">
<li>Recap of three key areas:
<ul class="org-ul">
<li>Healthcare applications.</li>
<li>Machine learning algorithms.</li>
<li>Big data systems.</li>
</ul></li>
<li>Course integrates these areas:
<ul class="org-ul">
<li>Example: Using logistic regression on Hadoop to predict heart failure.</li>
</ul></li>
<li>Next step: Begin applying concepts.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org10dd0bc" class="outline-2">
<h2 id="org10dd0bc"><span class="section-number-2">3.</span> Predictive Modeling</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-orgf7b54af" class="outline-3">
<h3 id="orgf7b54af"><span class="section-number-3">3.1.</span> Introduction to Predictive Modeling</h3>
<div class="outline-text-3" id="text-3-1">
<dl class="org-dl">
<dt>Predictive modeling</dt><dd>using historical data to predict future events.

<ul class="org-ul">
<li>Example: Using electronic health records (EHR) to model heart failure</li>
<li>Key Goal: Develop a good predictive model using EHR efficiently.</li>
</ul></dd>
</dl>
</div>
</div>

<div id="outline-container-org154f6ce" class="outline-3">
<h3 id="org154f6ce"><span class="section-number-3">3.2.</span> Predictive Modeling vs EHR</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>Importance: Increased research interest in using EHR for clinical predictive modeling.</li>
<li>Data Sources: EHR has become a major source for predictive modeling research.</li>
</ul>
</div>
</div>

<div id="outline-container-orge3c1b39" class="outline-3">
<h3 id="orge3c1b39"><span class="section-number-3">3.3.</span> Predictive Modeling Pipeline</h3>
<div class="outline-text-3" id="text-3-3">
<ul class="org-ul">
<li>Predictive modeling is a multi-step computational process:
<ol class="org-ol">
<li>Define the prediction target.</li>
<li>Construct the relevant patient cohort.</li>
<li>Identify potentially relevant features.</li>
<li>Select the most relevant features.</li>
<li>Compute the predictive model.</li>
<li>Evaluate the predictive model.</li>
</ol></li>
<li>Iterative process until a satisfactory model is obtained.</li>
</ul>
</div>
</div>

<div id="outline-container-org040f4cb" class="outline-3">
<h3 id="org040f4cb"><span class="section-number-3">3.4.</span> Prediction Target</h3>
<div class="outline-text-3" id="text-3-4">
<ul class="org-ul">
<li>Investigators may have many targets, but only some are feasible.</li>
<li>Selection criteria: The target should be interesting and possible with the available data.</li>
<li>Example: Predicting the onset of heart failure.</li>
</ul>
</div>
</div>

<div id="outline-container-org02f16a9" class="outline-3">
<h3 id="org02f16a9"><span class="section-number-3">3.5.</span> Heart Failure Quiz</h3>
<div class="outline-text-3" id="text-3-5">
<ul class="org-ul">
<li>Question: How many new heart failure cases occur annually in the U.S.?</li>
<li>Options: 17,000; 260,000; 550,000; 1,250,000.</li>
<li>Answer: 550,000 cases per year.</li>
</ul>
</div>
</div>

<div id="outline-container-org34c727d" class="outline-3">
<h3 id="org34c727d"><span class="section-number-3">3.6.</span> Motivations for Early Detection</h3>
<div class="outline-text-3" id="text-3-6">
<ul class="org-ul">
<li>Heart failure is complex with diverse symptoms and subsets.</li>
<li>Early detection can:
<ul class="org-ul">
<li>Reduce hospitalization costs.</li>
<li>Introduce early interventions to slow progression.</li>
<li>Improve clinical guidelines for heart failure prevention.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgfc6660a" class="outline-3">
<h3 id="orgfc6660a"><span class="section-number-3">3.7.</span> Cohort Construction</h3>
<div class="outline-text-3" id="text-3-7">
<ul class="org-ul">
<li>Defines the study population for predictive modeling.</li>
<li>Study population is a subset of all patients.</li>
<li>Four study designs based on two axes:
<ul class="org-ul">
<li>Prospective vs. Retrospective studies.</li>
<li>Cohort vs. Case-Control studies.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org0db721c" class="outline-3">
<h3 id="org0db721c"><span class="section-number-3">3.8.</span> Prospective vs. Retrospective Studies</h3>
<div class="outline-text-3" id="text-3-8">
<ul class="org-ul">
<li><b><b>Prospective Study</b></b>: Define cohort first, then collect data.</li>
<li><b><b>Retrospective Study</b></b>: Use existing data from past records.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd2a7651" class="outline-3">
<h3 id="orgd2a7651"><span class="section-number-3">3.9.</span> Prospective vs. Retrospective Quiz</h3>
<div class="outline-text-3" id="text-3-9">
<ul class="org-ul">
<li>Comparison of study properties:
<ul class="org-ul">
<li>Retrospective studies have more noise.</li>
<li>Prospective studies are more expensive and time-consuming.</li>
<li>Retrospective studies can handle larger datasets.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org44d93a3" class="outline-3">
<h3 id="org44d93a3"><span class="section-number-3">3.10.</span> Cohort Study</h3>
<div class="outline-text-3" id="text-3-10">
<ul class="org-ul">
<li>Includes patients exposed to a particular risk (e.g., heart failure readmission).</li>
<li>Defines inclusion and exclusion criteria.</li>
</ul>
</div>
</div>

<div id="outline-container-org20fb0a5" class="outline-3">
<h3 id="org20fb0a5"><span class="section-number-3">3.11.</span> Case-Control Study</h3>
<div class="outline-text-3" id="text-3-11">
<ul class="org-ul">
<li>Compares patients with a condition (cases) to similar patients without it (controls).</li>
<li>Matching criteria: Age, gender, clinic visits.</li>
<li>Cases are rarer than controls in real-world data.</li>
</ul>
</div>
</div>

<div id="outline-container-org6185c92" class="outline-3">
<h3 id="org6185c92"><span class="section-number-3">3.12.</span> Feature Construction</h3>
<div class="outline-text-3" id="text-3-12">
<ul class="org-ul">
<li>Defines patient features for predicting outcomes.</li>
<li>Data sequences from EHR:
<ul class="org-ul">
<li>Events (diagnoses, medications, lab results).</li>
<li>Observation window (used for feature extraction).</li>
<li>Prediction window (future period to predict).</li>
</ul></li>
<li>Impact of window sizes on model accuracy.</li>
</ul>
</div>
</div>

<div id="outline-container-orga4021a8" class="outline-3">
<h3 id="orga4021a8"><span class="section-number-3">3.13.</span> Feature Construction Quizzes</h3>
<div class="outline-text-3" id="text-3-13">
<ul class="org-ul">
<li>Quiz 1: Best timeline for modeling → Large observation, small prediction window.</li>
<li>Quiz 2: Most useful model → Small observation, large prediction window (ideal but difficult).</li>
</ul>
</div>
</div>

<div id="outline-container-org9c05e0c" class="outline-3">
<h3 id="org9c05e0c"><span class="section-number-3">3.14.</span> Prediction Performance on Windows</h3>
<div class="outline-text-3" id="text-3-14">
<ul class="org-ul">
<li><b><b>Prediction Window</b></b>: Longer window reduces accuracy.</li>
<li><b><b>Observation Window</b></b>: Longer window improves model performance until plateau.</li>
</ul>
</div>
</div>

<div id="outline-container-org9952f14" class="outline-3">
<h3 id="org9952f14"><span class="section-number-3">3.15.</span> Feature Selection</h3>
<div class="outline-text-3" id="text-3-15">
<ul class="org-ul">
<li>Identifies relevant features from EHR data.</li>
<li>EHR provides a large number of potential features (e.g., demographics, vitals).</li>
<li>Different targets require different feature subsets.</li>
</ul>
</div>
</div>

<div id="outline-container-org291e60d" class="outline-3">
<h3 id="org291e60d"><span class="section-number-3">3.16.</span> Predictive Model</h3>
<div class="outline-text-3" id="text-3-16">
<ul class="org-ul">
<li>Maps input features to predicted outcomes.</li>
<li>Regression models for continuous targets (e.g., healthcare costs).</li>
<li>Classification models for categorical targets (e.g., heart failure).</li>
<li>Common methods: Logistic regression, decision trees, random forests.</li>
</ul>
</div>
</div>

<div id="outline-container-orgf8cf417" class="outline-3">
<h3 id="orgf8cf417"><span class="section-number-3">3.17.</span> Performance Evaluation</h3>
<div class="outline-text-3" id="text-3-17">
<ul class="org-ul">
<li>Key metric: Testing error (not training error).</li>
<li>Models must generalize to unseen data.</li>
</ul>
</div>
</div>

<div id="outline-container-org5cc3c3c" class="outline-3">
<h3 id="org5cc3c3c"><span class="section-number-3">3.18.</span> Cross-Validation</h3>
<div class="outline-text-3" id="text-3-18">
<ul class="org-ul">
<li>Splits data into training and validation sets.</li>
<li>Common methods:
<ul class="org-ul">
<li>Leave-One-Out Cross-Validation.</li>
<li>K-Fold Cross-Validation.</li>
<li>Randomized Cross-Validation.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org9352ca6" class="outline-3">
<h3 id="org9352ca6"><span class="section-number-3">3.19.</span> Conclusion</h3>
<div class="outline-text-3" id="text-3-19">
<ul class="org-ul">
<li>Summary of the predictive modeling pipeline:
<ul class="org-ul">
<li>Define the prediction target.</li>
<li>Construct the patient cohort.</li>
<li>Generate relevant features.</li>
<li>Select important features.</li>
<li>Train the predictive model.</li>
<li>Evaluate model performance.</li>
</ul></li>
<li>Goal: Design high-level predictive modeling studies using EHR data.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org7319c5c" class="outline-2">
<h2 id="org7319c5c"><span class="section-number-2">4.</span> MapReduce&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org5827340" class="outline-3">
<h3 id="org5827340"><span class="section-number-3">4.1.</span> Introduction to MapReduce</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>Overview of MapReduce as a big data processing tool.</li>
<li>Utilizes distributed computation and storage.</li>
<li>Covers:
<ul class="org-ul">
<li>What MapReduce is</li>
<li>Fault tolerance in distributed environments</li>
<li>Analytical use cases and limitations</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org1b52cec" class="outline-3">
<h3 id="org1b52cec"><span class="section-number-3">4.2.</span> What is MapReduce</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>Hadoop/MapReduce is:
<ul class="org-ul">
<li>A programming model for parallel computation</li>
<li>An execution environment (Hadoop with HDFS)</li>
<li>A software package with various tools</li>
</ul></li>
<li>Capabilities:
<ul class="org-ul">
<li>Distributed storage via HDFS</li>
<li>Distributed computation via MapReduce</li>
<li>Built-in fault tolerance</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org2139899" class="outline-3">
<h3 id="org2139899"><span class="section-number-3">4.3.</span> Computational Process</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>Originated at Google (2004), open-sourced via Apache Hadoop.</li>
<li>Java-based platform.</li>
<li>Programming constrained to Map and Reduce functions for scalability.</li>
<li>Designed for parallel, fault-tolerant processing.</li>
<li>Emphasis on mastering computational patterns for analytics.</li>
</ul>
</div>
</div>

<div id="outline-container-org61fe62d" class="outline-3">
<h3 id="org61fe62d"><span class="section-number-3">4.4.</span> Learning Via Aggregation Statistics</h3>
<div class="outline-text-3" id="text-4-4">
<ul class="org-ul">
<li>Core design: express ML algorithms as aggregation tasks.</li>
<li>Example: Heart failure risk factor frequency analysis.</li>
<li>Map: extract risk factors per patient.</li>
<li>Reduce: aggregate frequencies across population.</li>
<li>Leads into deeper abstraction needs and trade-offs.</li>
</ul>
</div>
</div>

<div id="outline-container-org13c55e1" class="outline-3">
<h3 id="org13c55e1"><span class="section-number-3">4.5.</span> MapReduce Abstraction</h3>
<div class="outline-text-3" id="text-4-5">
<ul class="org-ul">
<li>Example task: count disease cases from patient records.</li>
<li>Map:
<ul class="org-ul">
<li>Emit (disease, 1) for each mention</li>
</ul></li>
<li>Shuffle:
<ul class="org-ul">
<li>Group by disease</li>
</ul></li>
<li>Reduce:
<ul class="org-ul">
<li>Sum values for each disease</li>
</ul></li>
<li>Emphasizes two-phase logic for scalability.</li>
</ul>
</div>
</div>

<div id="outline-container-org156e7cf" class="outline-3">
<h3 id="org156e7cf"><span class="section-number-3">4.6.</span> MapReduce System</h3>
<div class="outline-text-3" id="text-4-6">
<ul class="org-ul">
<li>Real-world data is too large for single machines.</li>
<li>Data is partitioned and processed by multiple mappers.</li>
<li>Intermediate results are shuffled and passed to reducers.</li>
<li>Final results computed from reduce function.</li>
<li>Three stages:
<ul class="org-ul">
<li>Map</li>
<li>Shuffle</li>
<li>Reduce</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org251fa5c" class="outline-3">
<h3 id="org251fa5c"><span class="section-number-3">4.7.</span> MapReduce Fault Recovery</h3>
<div class="outline-text-3" id="text-4-7">
<ul class="org-ul">
<li>Fault tolerance is a built-in system feature.</li>
<li>On failure:
<ul class="org-ul">
<li>Mappers/reducers are restarted with minimal recomputation.</li>
</ul></li>
<li>Goal: Only failed components are recomputed.</li>
<li>System handles all failure recovery.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc3ad803" class="outline-3">
<h3 id="orgc3ad803"><span class="section-number-3">4.8.</span> Distributed File Systems</h3>
<div class="outline-text-3" id="text-4-8">
<ul class="org-ul">
<li>HDFS: Hadoop's storage system.</li>
<li>Splits large files into partitions.</li>
<li>Partitions stored on multiple machines with redundancy.</li>
<li>Benefits:
<ul class="org-ul">
<li>Faster concurrent access</li>
<li>Fault tolerance (recover from worker failures)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orged2b77f" class="outline-3">
<h3 id="orged2b77f"><span class="section-number-3">4.9.</span> MapReduce Design Choice</h3>
<div class="outline-text-3" id="text-4-9">
<ul class="org-ul">
<li>Design principle: minimal functionality for reliability and scalability.</li>
<li>Restricted computation model (e.g., aggregation queries).</li>
<li>Map: operate on individual records</li>
<li>Reduce: aggregate results</li>
<li>Supports straggler mitigation (slow mappers duplicated)</li>
</ul>
</div>
</div>

<div id="outline-container-org8cab3e3" class="outline-3">
<h3 id="org8cab3e3"><span class="section-number-3">4.10.</span> Analytics with MapReduce</h3>
<div class="outline-text-3" id="text-4-10">
<ul class="org-ul">
<li>Application examples:
<ul class="org-ul">
<li>K-Nearest Neighbors (KNN)</li>
<li>Linear Regression</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org0878d01" class="outline-3">
<h3 id="org0878d01"><span class="section-number-3">4.11.</span> MapReduce KNN&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-4-11">
<ul class="org-ul">
<li>KNN implementation:
<ul class="org-ul">
<li>Map:
<ul class="org-ul">
<li>Find K nearest neighbors per partition</li>
</ul></li>
<li>Reduce:
<ul class="org-ul">
<li>Combine local results to find global nearest neighbors</li>
</ul></li>
</ul></li>
<li>Patient data partitioned, processed in parallel</li>
</ul>
</div>
</div>

<div id="outline-container-org5d2f051" class="outline-3">
<h3 id="org5d2f051"><span class="section-number-3">4.12.</span> Linear Regression</h3>
<div class="outline-text-3" id="text-4-12">
<ul class="org-ul">
<li>Goal: map patient features to heart disease risk</li>
<li>Normal equation:
<ul class="org-ul">
<li>β = (XᵗX)⁻¹Xᵗy</li>
</ul></li>
<li>MapReduce:
<ul class="org-ul">
<li>Map f1: compute xi * xiᵗ</li>
<li>Map f2: compute xi * yi</li>
<li>Reduce: aggregate sums</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org695ddd5" class="outline-3">
<h3 id="org695ddd5"><span class="section-number-3">4.13.</span> MapReduce for Linear Regression Quiz Question</h3>
<div class="outline-text-3" id="text-4-13">
<ul class="org-ul">
<li>Quiz: specify map/reduce pseudo code for computing Xᵗy</li>
</ul>
</div>
</div>

<div id="outline-container-org18faa0c" class="outline-3">
<h3 id="org18faa0c"><span class="section-number-3">4.14.</span> MapReduce for Linear Regression Quiz Solution</h3>
<div class="outline-text-3" id="text-4-14">
<ul class="org-ul">
<li>Solution:
<ul class="org-ul">
<li>Map: compute xi * yi</li>
<li>Reduce: aggregate results</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgbea84c2" class="outline-3">
<h3 id="orgbea84c2"><span class="section-number-3">4.15.</span> Limitations of MapReduce&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-4-15">
<ul class="org-ul">
<li>Example: Logistic Regression via Gradient Descent</li>
<li>Challenge: Requires iterative computation
<ul class="org-ul">
<li>Each iteration loads data twice</li>
</ul></li>
<li>MapReduce not efficient for:
<ul class="org-ul">
<li>Iterative, multi-stage computation</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org8708dd3" class="outline-3">
<h3 id="org8708dd3"><span class="section-number-3">4.16.</span> MapReduce Summary Quiz Question</h3>
<div class="outline-text-3" id="text-4-16">
<ul class="org-ul">
<li>Quiz on ideal conditions for MapReduce:
<ul class="org-ul">
<li>Single vs. multiple passes</li>
<li>Skewed vs. uniform key distribution</li>
<li>Synchronization needs</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org3a6d998" class="outline-3">
<h3 id="org3a6d998"><span class="section-number-3">4.17.</span> MapReduce Summary Quiz Solution</h3>
<div class="outline-text-3" id="text-4-17">
<ul class="org-ul">
<li>Best suited for:
<ul class="org-ul">
<li>Single-pass jobs (e.g., histograms)</li>
<li>Both skewed and uniform key distributions</li>
<li>Minimal synchronization (only between Map and Reduce phases)</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org733a814" class="outline-2">
<h2 id="org733a814"><span class="section-number-2">5.</span> Classification Model Metrics</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgfc294f0" class="outline-3">
<h3 id="orgfc294f0"><span class="section-number-3">5.1.</span> Predictive Model review</h3>
<div class="outline-text-3" id="text-5-1">
<dl class="org-dl">
<dt>Predictive model</dt><dd>mapping function between model inputs and outputs (pred's)</dd>
<dt>Model metrics</dt><dd>needed to know how well they're performing</dd>
</dl>
</div>
</div>
<div id="outline-container-org2bae16c" class="outline-3">
<h3 id="org2bae16c"><span class="section-number-3">5.2.</span> Confusion matrix</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>True positive/negative also known as "Condition" positive/negative</li>
<li>Predicted positive/negative also known as "Prediction Outcome" positive/negative</li>
</ul>
</div>
</div>
<div id="outline-container-org98aef9d" class="outline-3">
<h3 id="org98aef9d"><span class="section-number-3">5.3.</span> Accuracy metrics</h3>
<div class="outline-text-3" id="text-5-3">
<p>
All divided by ground truth values.
</p>
<dl class="org-dl">
<dt>Accuracy</dt><dd>(TP+TN)/TP. Not most useful for imbalanced class</dd>
<dt>True positive rate</dt><dd>TP/CP (Sensitivity, Recall)</dd>
<dt>False positive rate</dt><dd>FP/CN</dd>
<dt>False negative</dt><dd>FN/CP</dd>
<dt>True negative rate</dt><dd>TN/CN (Specificity)</dd>
</dl>
</div>
<div id="outline-container-orgd4b690b" class="outline-4">
<h4 id="orgd4b690b"><span class="section-number-4">5.3.1.</span> Other notes</h4>
<div class="outline-text-4" id="text-5-3-1">
<ul class="org-ul">
<li>FP is a type I error.</li>
<li>FN is a type II error.</li>
<li>Hard to perform well on all metrics</li>
<li>Important to choose the right metrics</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org60e2667" class="outline-3">
<h3 id="org60e2667"><span class="section-number-3">5.4.</span> Predictive metrics</h3>
<div class="outline-text-3" id="text-5-4">
<p>
All divided by prediction outcomes.
</p>
<dl class="org-dl">
<dt>Prevalence</dt><dd>CP/Total population. How likely disease occurs in population</dd>
<dt>Positive predictive value (Precision)</dt><dd>TP/Pred outcome positive.</dd>
<dt>False discovery rate</dt><dd>FP/Pred outcome positive</dd>
<dt>Negative predictive value</dt><dd>TN/Pred outcome negative</dd>
<dt>False omission rate</dt><dd>FN/Pred outcome negative</dd>
</dl>
</div>
</div>
<div id="outline-container-org92fa6c6" class="outline-3">
<h3 id="org92fa6c6"><span class="section-number-3">5.5.</span> F1 score</h3>
<div class="outline-text-3" id="text-5-5">
<p>
Harmonic mean of PPV and TPR
\[
F_1 = 2 \times \frac{PPV \times TPR}{PPV + TPR}
\]
</p>
</div>
</div>
<div id="outline-container-orgdff0b89" class="outline-3">
<h3 id="orgdff0b89"><span class="section-number-3">5.6.</span> Classifier quiz</h3>
<div class="outline-text-3" id="text-5-6">
<p>
Which is the best classifier?
</p>
<ul class="org-ul">
<li>Highest F1, PPV and Accuracy is the best classifier</li>
</ul>
</div>
</div>
<div id="outline-container-org60c177d" class="outline-3">
<h3 id="org60c177d"><span class="section-number-3">5.7.</span> Reversing predictions</h3>
<div class="outline-text-3" id="text-5-7">
<p>
It's always possible to reverse the predictions so 0.21 might perform better than 0.69/0.50.
</p>
</div>
</div>
<div id="outline-container-org91ca78e" class="outline-3">
<h3 id="org91ca78e"><span class="section-number-3">5.8.</span> Receiver operating characteristic</h3>
<div class="outline-text-3" id="text-5-8">
<ul class="org-ul">
<li>Predictive models generally output continuous score.</li>
<li>Threshold is needed as precision bound to force to a certain category</li>
<li>ROC provides a way to compare performance of classifiers as the decision boundary is varied</li>
<li>ROC curve is the plot of TP rate vs FP rate at various threshold values
<ul class="org-ul">
<li>We sort by prediction score (highest first)</li>
<li>Use prediction score as threshold values</li>
<li>Plot on the chart and see how many are misclassified (needs True value to be known)</li>
</ul></li>
<li>AUROC does not depend on the choice of threshold.</li>
<li>AUROC is the most popular metric for classification</li>
</ul>
</div>
</div>
<div id="outline-container-org3dc9c83" class="outline-3">
<h3 id="org3dc9c83"><span class="section-number-3">5.9.</span> "Best classifier threshold" quiz</h3>
<div class="outline-text-3" id="text-5-9">
<ul class="org-ul">
<li>There isn't a standard answer, it depends on whether TP, TN or other metric is prioritized</li>
</ul>
</div>
</div>
<div id="outline-container-orgd162485" class="outline-3">
<h3 id="orgd162485"><span class="section-number-3">5.10.</span> Regression metrics</h3>
<div class="outline-text-3" id="text-5-10">
<dl class="org-dl">
<dt>MAE</dt><dd>average of absolute errors, harder to work with since the absolute value is not differentiable</dd>
<dt>MSE</dt><dd>average of squared errors, easier to work with as the derivative of squared term is linear. Increases a lot faster than MAE</dd>
<dt>\(R^2\)</dt><dd>bounded by \((-\infty,1)\). AKA coefficient of determination.</dd>
</dl>
</div>
<div id="outline-container-org33c5fc9" class="outline-4">
<h4 id="org33c5fc9"><span class="section-number-4">5.10.1.</span> \(R^2\)</h4>
<div class="outline-text-4" id="text-5-10-1">
<p>
\[
R^2 = 1-\frac{\sum_i (y_i - \hat{y}_i)^2}{\sum_i(y_i - \bar{y})^2}
\]
i.e. 1-MSE/Variance
</p>

<p>
Negative \(R^2\) values means they perform worse than a simple average of raw data.
As noise increases, \(R^2\) decreases.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org57523ed" class="outline-2">
<h2 id="org57523ed"><span class="section-number-2">6.</span> Ensemble methods</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org945ee8e" class="outline-3">
<h3 id="org945ee8e"><span class="section-number-3">6.1.</span> Gradient Descent Method (GDM) for Linear Regression</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>Illustrates gradient descent using linear regression.</li>
<li>Dataset: each row = patient; features in X, outcome Y (e.g., hospital cost).</li>
<li>Objective: learn linear mapping from features X to outcome Y.</li>
<li>Assumes Gaussian distribution → log-likelihood leads to squared error minimization.</li>
<li>Gradient: derived by taking derivative of log-likelihood w.r.t. coefficients β.</li>
<li>Update rule: move β in direction of gradient with step size η.</li>
<li><span style='background-color: #FFFF00;'>Requires multiple iterations over full dataset → computationally expensive.</span></li>
</ul>
</div>
</div>

<div id="outline-container-orga3c2cde" class="outline-3">
<h3 id="orga3c2cde"><span class="section-number-3">6.2.</span> Stochastic Gradient Descent (SGD) Method</h3>
<div class="outline-text-3" id="text-6-2">
<ul class="org-ul">
<li>SGD is a scalable variant of gradient descent for large datasets.</li>
<li>Instead of using full dataset, <span style='background-color: #FFFF00;'>computes gradients on random subsets (mini-batches)</span>.</li>
<li>One-point update = SGD; larger batches = mini-batch gradient descent.</li>
<li>Faster per-iteration updates compared to full batch gradient descent.</li>
</ul>
</div>
</div>

<div id="outline-container-org08597ae" class="outline-3">
<h3 id="org08597ae"><span class="section-number-3">6.3.</span> SGD for Linear Regression</h3>
<div class="outline-text-3" id="text-6-3">
<ul class="org-ul">
<li>Applies SGD to same regression problem.</li>
<li>Each update uses one patient:
<ul class="org-ul">
<li>Compute individual log-likelihood and gradient.</li>
<li>Update β using gradient.</li>
</ul></li>
<li>More efficient than full gradient computation.</li>
<li>Key idea: updates based on single or small group of samples.</li>
</ul>
</div>
</div>

<div id="outline-container-org169c019" class="outline-3">
<h3 id="org169c019"><span class="section-number-3">6.4.</span> Ensemble Method Pt 1</h3>
<div class="outline-text-3" id="text-6-4">
<ul class="org-ul">
<li>Ensemble methods combine multiple models for improved performance.</li>
<li>Can use same (e.g., Random Forest) or different base models.</li>
<li>Real-world example: Netflix Prize → ensemble models won.</li>
<li>Many teams merged, forming more powerful ensembles.</li>
</ul>
</div>
</div>

<div id="outline-container-orge85508b" class="outline-3">
<h3 id="orge85508b"><span class="section-number-3">6.5.</span> Ensemble Method Pt 2</h3>
<div class="outline-text-3" id="text-6-5">
<ul class="org-ul">
<li>General ensemble steps:
<ol class="org-ol">
<li>Generate multiple datasets (via bagging or boosting).</li>
<li>Train separate models on each.</li>
<li>Aggregate outputs using functions like averaging or weighted sum.</li>
</ol></li>
<li>Outcome: different ensemble strategies.</li>
</ul>
</div>
</div>

<div id="outline-container-org50b8cd7" class="outline-3">
<h3 id="org50b8cd7"><span class="section-number-3">6.6.</span> Bias Variance Tradeoff</h3>
<div class="outline-text-3" id="text-6-6">
<ul class="org-ul">
<li>Key insight: <span style='background-color: #FFFF00;'>model error = bias² + variance</span>.</li>
<li>Bias: error from wrong assumptions (e.g., assuming linear when it's not).</li>
<li>Variance: error from sensitivity to training data.</li>
<li>Ideal model: low bias and low variance.</li>
<li>Graphical example: dartboard showing different combinations.
<img src="./img/bias-variance-tradeoff.png" alt="bias-variance-tradeoff.png" /></li>
<li>As model complexity increases:
<ul class="org-ul">
<li>Bias ↓</li>
<li>Variance ↑</li>
<li>Total error = minimum at an optimal complexity.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orga9f43b2" class="outline-3">
<h3 id="orga9f43b2"><span class="section-number-3">6.7.</span> Bias Variance Tradeoff Quiz Question</h3>
<div class="outline-text-3" id="text-6-7">

<div id="org8a9680e" class="figure">
<p><img src="./img/bias-var-quiz.png" alt="bias-var-quiz.png" />
</p>
</div>
<ul class="org-ul">
<li>Task: rank four models (flat, linear, smooth curve, wiggly) by complexity.</li>
<li>A → D: D (flat) &lt; A (linear) &lt; B (curve) &lt; C (wiggly)</li>
</ul>
</div>
</div>

<div id="outline-container-org5c7f778" class="outline-3">
<h3 id="org5c7f778"><span class="section-number-3">6.8.</span> Bias Variance Tradeoff Quiz Solution</h3>
<div class="outline-text-3" id="text-6-8">
<ul class="org-ul">
<li>Explanation:
<ul class="org-ul">
<li>D: lowest complexity (flat line).</li>
<li>A: next, simple linear model.</li>
<li>B: more complex curve.</li>
<li>C: most complex (wiggly).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org2bca06e" class="outline-3">
<h3 id="org2bca06e"><span class="section-number-3">6.9.</span> Bias Variance Tradeoff Quiz 2 Question</h3>
<div class="outline-text-3" id="text-6-9">
<ul class="org-ul">
<li>Given same models, asked which best fits data.</li>
</ul>
</div>
</div>

<div id="outline-container-org1f7d0c2" class="outline-3">
<h3 id="org1f7d0c2"><span class="section-number-3">6.10.</span> Bias Variance Tradeoff Quiz 2 Solution</h3>
<div class="outline-text-3" id="text-6-10">
<ul class="org-ul">
<li>Answer: B (smooth curve)</li>
<li>Balances bias and variance well.</li>
</ul>
</div>
</div>

<div id="outline-container-org3db2cb0" class="outline-3">
<h3 id="org3db2cb0"><span class="section-number-3">6.11.</span> Bagging</h3>
<div class="outline-text-3" id="text-6-11">
<ul class="org-ul">
<li>Bagging = <span style='background-color: #FFFF00;'>Bootstrap Aggregation</span>.</li>
<li>Method:
<ul class="org-ul">
<li>Sample data <span style='background-color: #FFFF00;'>with replacement</span>.</li>
<li>Train models on each sample.</li>
<li>Combine predictions via majority vote or averaging.</li>
</ul></li>
<li>Reduces variance of the final model.</li>
</ul>
</div>
</div>

<div id="outline-container-org768d7bb" class="outline-3">
<h3 id="org768d7bb"><span class="section-number-3">6.12.</span> Random Forest&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-6-12">
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Special case of bagging</span> with decision trees.
<img src="./img/rf1.png" alt="rf1.png" />
<img src="./img/rf2.png" alt="rf2.png" /></li>
<li>Steps:
<ul class="org-ul">
<li>Randomly sample both rows (patients) and columns (features).</li>
<li>Train simple decision trees on these subsets.</li>
</ul></li>
<li>Final prediction = average of all trees.</li>
<li>Simple trees help maintain diversity and lower computation.</li>
</ul>
</div>
</div>

<div id="outline-container-org09ddcd0" class="outline-3">
<h3 id="org09ddcd0"><span class="section-number-3">6.13.</span> Why Bagging Works</h3>
<div class="outline-text-3" id="text-6-13">
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Reduces variance without increasing bias.</span></li>
<li>Variance reduction from averaging independent model predictions.</li>
<li>Based on statistical principle: variance of mean = variance / \(T\) for \(T\) models, assuming
the resulting bootstrap samples are close to i.i.d.</li>
</ul>
</div>
</div>

<div id="outline-container-org74a4901" class="outline-3">
<h3 id="org74a4901"><span class="section-number-3">6.14.</span> Boosting</h3>
<div class="outline-text-3" id="text-6-14">
<ul class="org-ul">
<li>Builds models sequentially.</li>
<li>Each new model focuses on mistakes of previous ones.</li>
<li>Final model = weighted combination of all models.</li>
<li>Pros: better accuracy.</li>
<li>Cons: <span style='background-color: #FFFF00;'>prone to overfitting</span> vs bagging.</li>
<li>Example: AdaBoost is most popular.</li>
</ul>
</div>
</div>

<div id="outline-container-org53c9550" class="outline-3">
<h3 id="org53c9550"><span class="section-number-3">6.15.</span> Bagging vs Boosting Quiz Question</h3>
<div class="outline-text-3" id="text-6-15">
<ul class="org-ul">
<li>Quiz to compare characteristics:
<ul class="org-ul">
<li>Combination method (simple vs weighted average)</li>
<li>Parallelism</li>
<li>Noise sensitivity</li>
<li>Accuracy</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgef19d77" class="outline-3">
<h3 id="orgef19d77"><span class="section-number-3">6.16.</span> Bagging vs Boosting Quiz Solution</h3>
<div class="outline-text-3" id="text-6-16">
<ul class="org-ul">
<li>Bagging:
<ul class="org-ul">
<li>Simple average, parallel-friendly, less sensitive to noise, reliable accuracy (good in all cases).</li>
</ul></li>
<li>Boosting:
<ul class="org-ul">
<li>Weighted average, sequential (hard to parallelize), sensitive to noise, potentially higher accuracy but less reliable.l</li>
</ul></li>
<li>Analogy:
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Bagging = reliable Japanese car.</span></li>
<li><span style='background-color: #FFFF00;'>Boosting = high-performance but risky sports car.</span></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgdd378d1" class="outline-3">
<h3 id="orgdd378d1"><span class="section-number-3">6.17.</span> Summary for Ensemble Methods</h3>
<div class="outline-text-3" id="text-6-17">
<ul class="org-ul">
<li>Pros:
<ul class="org-ul">
<li>Simple, flexible, few parameters, theoretical backing.</li>
</ul></li>
<li>Cons:
<ul class="org-ul">
<li>Computational cost (training + inference).</li>
<li>Harder interpretation (due to model complexity).</li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgefe1990" class="outline-2">
<h2 id="orgefe1990"><span class="section-number-2">7.</span> Computational Phenotyping</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-orgb407b5a" class="outline-3">
<h3 id="orgb407b5a"><span class="section-number-3">7.1.</span> Introduction to Phenotyping</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>Introduction to clustering in healthcare, specifically "phenotyping".</li>
<li>Phenotypes refer to diseases or conditions; known phenotypes exist, but many more are undiscovered.</li>
<li>Computational phenotyping helps discover novel phenotypes using available data.</li>
<li>Applications include disease diagnosis, cost prediction, readmission risk, and genomic studies.</li>
</ul>
</div>
</div>

<div id="outline-container-org64a428e" class="outline-3">
<h3 id="org64a428e"><span class="section-number-3">7.2.</span> Computational Phenotyping</h3>
<div class="outline-text-3" id="text-7-2">
<ul class="org-ul">
<li>Converts raw EHR data into meaningful phenotypes using algorithms.</li>
<li>EHR data includes demographics, diagnosis codes, medications, procedures, labs, notes.</li>
<li>Challenges:
<ul class="org-ul">
<li>Noisy and incomplete data esp. raw data.</li>
<li>Primarily designed for clinical use, not directly for supporting research.</li>
<li>Redundancy across data sources.</li>
</ul></li>
<li>Goal: derive research-grade phenotypes from raw clinical data.</li>
</ul>
</div>
</div>

<div id="outline-container-org79e7dfd" class="outline-3">
<h3 id="org79e7dfd"><span class="section-number-3">7.3.</span> Phenotyping Algorithm</h3>
<div class="outline-text-3" id="text-7-3">
<ul class="org-ul">
<li>Example: Type 2 diabetes phenotyping algorithm.</li>
<li>Sequential logic:
<ol class="org-ol">
<li>Exclude Type 1 diagnosis.</li>
<li>Check for Type 2 diagnosis.</li>
<li>Check medication and lab results.</li>
</ol></li>
<li>Multiple confirmation paths possible.</li>
<li>Developed manually by clinical experts.</li>
</ul>
</div>
</div>

<div id="outline-container-org74d4853" class="outline-3">
<h3 id="org74d4853"><span class="section-number-3">7.4.</span> Applications of Phenotyping</h3>
<div class="outline-text-3" id="text-7-4">
<ul class="org-ul">
<li>Genomic studies: link genomic and phenotypic data.</li>
<li>Clinical predictive modeling: forecast disease onset, hospitalizations.</li>
<li>Pragmatic clinical trials: assess treatment effectiveness in real-world settings.</li>
<li>Healthcare quality measurement: compare care quality across institutions.</li>
<li>All rely on robust phenotyping algorithms.</li>
</ul>
</div>
</div>

<div id="outline-container-orga8639d7" class="outline-3">
<h3 id="orga8639d7"><span class="section-number-3">7.5.</span> Genomic Wide Association Study</h3>
<div class="outline-text-3" id="text-7-5">
<ul class="org-ul">
<li>GWAS scans SNPs to associate genetic variations with diseases.</li>
<li>Steps:
<ol class="org-ol">
<li>Identify phenotypes.</li>
<li>Divide subjects into cases/controls.</li>
<li>Collect DNA and scan for SNPs.</li>
<li>Calculate odds ratios and p-values.</li>
</ol></li>
<li>Statistically significant SNPs may indicate disease relevance.</li>
<li>High-quality phenotyping critical for accurate GWAS.</li>
</ul>
</div>
</div>

<div id="outline-container-org3de99b1" class="outline-3">
<h3 id="org3de99b1"><span class="section-number-3">7.6.</span> Why Do We Care About Phenotyping</h3>
<div class="outline-text-3" id="text-7-6">
<p>
<span style='background-color: #FFFF00;'>We need rich and deep phentotyping to analyze genomic data.</span>
</p>
<ul class="org-ul">
<li>Genomic data is rapidly becoming cheaper and more abundant.</li>
<li>Phenotypic data remains complex and costly to acquire.</li>
<li>Demand for better phenotyping algorithms to support scalable, high-quality genomic research.</li>
</ul>
</div>
</div>

<div id="outline-container-orgce67c30" class="outline-3">
<h3 id="orgce67c30"><span class="section-number-3">7.7.</span> Clinical Predictive Modeling</h3>
<div class="outline-text-3" id="text-7-7">
<ul class="org-ul">
<li>Predictive modeling using raw EHR data is problematic (noise, complexity, lack of portability).</li>
<li>Phenotyping transforms raw data into simpler, meaningful concepts.</li>
<li>Benefits:
<ul class="org-ul">
<li>Better model accuracy.</li>
<li>Easier interpretation.</li>
<li>Generalizability across hospitals/settings (input data schemas may be different).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org177f684" class="outline-3">
<h3 id="org177f684"><span class="section-number-3">7.8.</span> Pragmatic Clinical Trials</h3>
<div class="outline-text-3" id="text-7-8">
<ul class="org-ul">
<li>Traditional vs. pragmatic trials:
<ul class="org-ul">
<li>Traditional: controlled, single condition/drug, strict selection, randomized.</li>
<li>Pragmatic: <span style='background-color: #FFFF00;'>real-world</span>, <span style='background-color: #FFFF00;'>multiple</span> conditions/drugs, minimal selection, often <span style='background-color: #FFFF00;'>not randomized</span>.</li>
</ul></li>
<li>High-quality phenotyping essential for identifying patient conditions and treatments in pragmatic settings.</li>
</ul>
</div>
</div>

<div id="outline-container-org3d484da" class="outline-3">
<h3 id="org3d484da"><span class="section-number-3">7.9.</span> Healthcare Quality Measurement</h3>
<div class="outline-text-3" id="text-7-9">
<ul class="org-ul">
<li>Challenge: hospitals use <span style='background-color: #FFFF00;'>diverse EHR formats</span>.</li>
<li>Centralized processing of raw data is complex.</li>
<li>Solution: local phenotyping at hospitals → send standardized phenotype data to central site.</li>
<li>Enables <span style='background-color: #FFFF00;'>scalable and fair</span> quality comparison across institutions.</li>
</ul>
</div>
</div>

<div id="outline-container-org06dc05a" class="outline-3">
<h3 id="org06dc05a"><span class="section-number-3">7.10.</span> Phenotyping Methods Part 1</h3>
<div class="outline-text-3" id="text-7-10">
<ul class="org-ul">
<li>Two main approaches:
<ul class="org-ul">
<li>Supervised learning: uses labeled data (function <span style='background-color: #FFFF00;'>approximation</span>).</li>
<li>Unsupervised learning: identifies patterns/structures without labels (<span style='background-color: #FFFF00;'>description</span>/summarization).</li>
</ul></li>
<li>Illustrative examples and playful dialogue explore these ideas in depth.</li>
</ul>
</div>
</div>

<div id="outline-container-orga3b1c2d" class="outline-3">
<h3 id="orga3b1c2d"><span class="section-number-3">7.11.</span> Phenotyping Methods Part 2</h3>
<div class="outline-text-3" id="text-7-11">
<ul class="org-ul">
<li>Supervised: expert-defined rules (Boolean logic, decision trees), or machine learning classifiers.
<ul class="org-ul">
<li>Pros: interpretable, low validation effort.</li>
<li>Cons: high development <span style='background-color: #FFFF00;'>cost</span>, <span style='background-color: #FFFF00;'>not good for unknown phenotypes</span>, potential <span style='background-color: #FFFF00;'>poor transferability</span>.</li>
</ul></li>
<li>Unsupervised: clustering, dimensionality reduction.
<ul class="org-ul">
<li>Pros: less manual effort, no need for labels.</li>
<li>Cons: <span style='background-color: #FFFF00;'>hard to validate</span>, large data requirements.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org23a9418" class="outline-3">
<h3 id="org23a9418"><span class="section-number-3">7.12.</span> Phenotyping Quiz Question</h3>
<div class="outline-text-3" id="text-7-12">
<ul class="org-ul">
<li>Quiz:
<ul class="org-ul">
<li>Which approach requires more human effort during evaluation?</li>
<li>Which is easier to interpret?</li>
<li>Choices: expert-defined rules vs. classification models.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org56699c0" class="outline-3">
<h3 id="org56699c0"><span class="section-number-3">7.13.</span> Phenotyping Quiz Solution</h3>
<div class="outline-text-3" id="text-7-13">
<ul class="org-ul">
<li>Answer:
<ul class="org-ul">
<li>Classification models require more evaluation effort (need more labeled data).</li>
<li>Expert-defined rules are easier to interpret (clinician-derived, intuitive).</li>
</ul></li>
</ul>
</div>
</div>
</div>


<div id="outline-container-orgf6a5297" class="outline-2">
<h2 id="orgf6a5297"><span class="section-number-2">8.</span> Clustering</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-org4771777" class="outline-3">
<h3 id="org4771777"><span class="section-number-3">8.1.</span> Introduction to Clustering</h3>
<div class="outline-text-3" id="text-8-1">
<ul class="org-ul">
<li>Introduction of clustering as a method distinct from classification.</li>
<li>Classification: Grouping by known labels.</li>
<li>Clustering: Discovering groups from raw data.</li>
<li>Topics covered:
<ul class="org-ul">
<li>Definition of clustering.</li>
<li>Algorithms: K-means, Gaussian Mixture Models (GMM).</li>
<li>Scalable algorithms for large datasets.</li>
<li>Applications in healthcare.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org7a3a8bd" class="outline-3">
<h3 id="org7a3a8bd"><span class="section-number-3">8.2.</span> Healthcare Applications</h3>
<div class="outline-text-3" id="text-8-2">
<ul class="org-ul">
<li>Clustering in healthcare:
<ul class="org-ul">
<li>Patient stratification: group patients with similar characteristics.</li>
<li>Disease hierarchy discovery: learn structure/relationships among diseases.</li>
<li>Phenotyping: convert raw data into meaningful phenotypes (clinical concepts).</li>
<li>Phenotypes = clusters of similar patients.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org75b3cb4" class="outline-3">
<h3 id="org75b3cb4"><span class="section-number-3">8.3.</span> What is Clustering</h3>
<div class="outline-text-3" id="text-8-3">
<ul class="org-ul">
<li>Clustering explained via patient-disease matrix:
<ul class="org-ul">
<li>Rows = patients, Columns = diseases.</li>
<li>Apply clustering to rows → patient clusters (e.g., P1, P2, P3).</li>
<li>Apply clustering to columns → disease clusters (e.g., D1, D2, D3).</li>
<li>Supports applications like phenotyping and disease discovery.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org75a59d8" class="outline-3">
<h3 id="org75a59d8"><span class="section-number-3">8.4.</span> Algorithm Overview</h3>
<div class="outline-text-3" id="text-8-4">
<ul class="org-ul">
<li>Two categories of clustering algorithms:
<ul class="org-ul">
<li>Classical: K-means, Hierarchical, Gaussian Mixture Model.</li>
<li>Scalable: Mini-batch K-means, DBSCAN.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgbb4c490" class="outline-3">
<h3 id="orgbb4c490"><span class="section-number-3">8.5.</span> K Means</h3>
<div class="outline-text-3" id="text-8-5">
<ul class="org-ul">
<li>Hard cluster (every data point belongs to one cluster)</li>
<li>Inputs: data points X₁ to Xₙ, number of clusters K.</li>
<li>Outputs: K clusters S₁ to Sₖ.</li>
<li>Objective: Minimize distance of data points to cluster centers (µᵢ).</li>
<li>Algorithm steps:
<ol class="org-ol">
<li>Initialize K centers.</li>
<li>Assign points to nearest center.</li>
<li>Update centers based on mean of assigned points.</li>
<li>Repeat until convergence.</li>
</ol></li>
<li>Example illustrated using \(K=2\).</li>
</ul>
</div>
</div>

<div id="outline-container-org0048606" class="outline-3">
<h3 id="org0048606"><span class="section-number-3">8.6.</span> K Means Quiz Question</h3>
<div class="outline-text-3" id="text-8-6">
<ul class="org-ul">
<li>Quiz: Given n, k, d (dimensions), i (iterations), what's the complexity?</li>
</ul>

<div id="orgbbdab72" class="figure">
<p><img src="./img/kmeans-o.png " alt="kmeans-o.png " />
</p>
</div>
</div>
</div>
<div id="outline-container-org944530f" class="outline-3">
<h3 id="org944530f"><span class="section-number-3">8.7.</span> K Means Quiz Solution</h3>
<div class="outline-text-3" id="text-8-7">
<ul class="org-ul">
<li>Complexity: O(n × k × d × i)
<ul class="org-ul">
<li>Cost driven by assignment and update operations.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgd868955" class="outline-3">
<h3 id="orgd868955"><span class="section-number-3">8.8.</span> Hierarchical Clustering</h3>
<div class="outline-text-3" id="text-8-8">
<ul class="org-ul">
<li>Hard cluster (every data point belongs to one cluster)</li>
<li>Builds a <span style='background-color: #FFFF00;'>hierarchy</span> of data points.</li>
<li>Two approaches:
<ul class="org-ul">
<li>Agglomerative (bottom-up): Merge smallest clusters until one remains.</li>
<li>Divisive (top-down): Split one big cluster into smaller ones.</li>
</ul></li>
<li><span style='background-color: #FFFF00;'>Agglomerative (bottom up) is more efficient and more commonly</span> used.</li>
</ul>
</div>
</div>

<div id="outline-container-org240759b" class="outline-3">
<h3 id="org240759b"><span class="section-number-3">8.9.</span> Agglomerative Clustering</h3>
<div class="outline-text-3" id="text-8-9">
<ul class="org-ul">
<li>Steps:
<ol class="org-ol">
<li>Compute n×n distance matrix.</li>
<li>Initialize each point as its own cluster.</li>
<li>Iteratively merge 2  closest clusters and update distance matrix.</li>
<li>Stop when one cluster remains (produces a hierarchy).</li>
</ol></li>
</ul>

<div id="orgdac3a5b" class="figure">
<p><img src="./img//agg-cluster.png " alt="agg-cluster.png " />
</p>
</div>
</div>
</div>
<div id="outline-container-org08eca5e" class="outline-3">
<h3 id="org08eca5e"><span class="section-number-3">8.10.</span> Gaussian Mixture Model</h3>
<div class="outline-text-3" id="text-8-10">
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Soft</span> clustering: points belong to multiple clusters with probabilities.</li>
<li>Each cluster is a Gaussian (<span style='background-color: #FFFF00;'>normal</span> distribution).</li>
<li>Parameters:
<dl class="org-dl">
<dt>mean</dt><dd>µₖ</dd>
<dt>variance</dt><dd>σₖ</dd>
<dt>mixing coefficient</dt><dd>πₖ</dd>
</dl></li>
<li>Goal: Estimate GMM parameters from data.</li>
</ul>
<p>
\[
p(X) = \sum_{k=1}^{K} \pi_k \, N(X | \mu_k, \Sigma_k)
\]
</p>
</div>
</div>


<div id="outline-container-orgd2a30c3" class="outline-3">
<h3 id="orgd2a30c3"><span class="section-number-3">8.11.</span> GMM Expectation Maximization&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-8-11">
<ul class="org-ul">
<li>Uses Expectation-Maximization (EM) algorithm:
<ul class="org-ul">
<li>Initialize parameters.</li>
<li>E-step: Compute assignment scores (γₙₖ).</li>
<li>M-step: Update parameters using γₙₖ.</li>
<li>Iterate until convergence.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgffad891" class="outline-3">
<h3 id="orgffad891"><span class="section-number-3">8.12.</span> GMM Steps</h3>
<div class="outline-text-3" id="text-8-12">
<ul class="org-ul">
<li>Details of EM:
<ul class="org-ul">
<li>Initialization: K-means can be used for better results.</li>
<li>E-step: Compute γₙₖ using cluster probabilities.</li>
<li>M-step:
<ul class="org-ul">
<li>Compute cluster size (Nₖ), mean (µₖ), covariance (σₖ), mixing coefficient (πₖ).</li>
</ul></li>
</ul></li>
<li>Inefficient choice of start points will result in more iterations before convergence.</li>
</ul>
</div>
</div>

<div id="outline-container-org32679b4" class="outline-3">
<h3 id="org32679b4"><span class="section-number-3">8.13.</span> GMM Visual Illustration</h3>
<div class="outline-text-3" id="text-8-13">
<ul class="org-ul">
<li>Visual demo of GMM clustering.</li>
<li>Iteratively updates Gaussians until convergence.</li>
<li>Final model reflects soft cluster assignments.</li>
</ul>
</div>
</div>

<div id="outline-container-org37a6971" class="outline-3">
<h3 id="org37a6971"><span class="section-number-3">8.14.</span> K Means Vs GMM&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-8-14">
<ul class="org-ul">
<li>Comparison:
<ul class="org-ul">
<li>K-means: hard assignment, single center (µₖ).</li>
<li>GMM: soft assignment, parameters include µₖ, σₖ, πₖ.</li>
<li>Both use iterative updates.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgb769d4f" class="outline-3">
<h3 id="orgb769d4f"><span class="section-number-3">8.15.</span> Mini Batch K Means</h3>
<div class="outline-text-3" id="text-8-15">
<ul class="org-ul">
<li>Scalable version of K-means.</li>
<li>Works with small batches (M) instead of full dataset.</li>
<li>Updates centers incrementally.
<ol class="org-ol">
<li>Cache the center</li>
<li>Increment center count</li>
<li>Set step size</li>
<li>Update c. Center is eventually stabilized.</li>
</ol></li>
<li>Reduces computational cost for large data.</li>
</ul>
</div>
</div>

<div id="outline-container-orgdc82de2" class="outline-3">
<h3 id="orgdc82de2"><span class="section-number-3">8.16.</span> Mini Batch K Means Quiz Question</h3>
<div class="outline-text-3" id="text-8-16">
<ul class="org-ul">
<li>Quiz: Given the following, compute complexity.

<dl class="org-dl">
<dt>k</dt><dd>number of clusters</dd>
<dt>t</dt><dd>iterations</dd>
<dt>b</dt><dd>batch size</dd>
<dt>d</dt><dd>number of dimensions</dd>
</dl></li>
</ul>
</div>
</div>


<div id="outline-container-orga52aa86" class="outline-3">
<h3 id="orga52aa86"><span class="section-number-3">8.17.</span> Mini Batch K Means Quiz Solution</h3>
<div class="outline-text-3" id="text-8-17">
<ul class="org-ul">
<li>Complexity: O(t × b × k × d)</li>
</ul>
</div>
</div>

<div id="outline-container-org2e219e7" class="outline-3">
<h3 id="org2e219e7"><span class="section-number-3">8.18.</span> DBScan</h3>
<div class="outline-text-3" id="text-8-18">
<ul class="org-ul">
<li>Density-Based Spatial Clustering of Applications with Noise.</li>
<li>Clusters = dense areas, separated by sparse regions.</li>
<li>Can identify clusters of <span style='background-color: #FFFF00;'>arbitrary shape</span>.</li>
<li>Effective for noisy data.</li>
</ul>
</div>
</div>

<div id="outline-container-org399c207" class="outline-3">
<h3 id="org399c207"><span class="section-number-3">8.19.</span> DBScan Key Concepts</h3>
<div class="outline-text-3" id="text-8-19">
<ul class="org-ul">
<li>Density = <span style='background-color: #FFFF00;'>number of points</span> within ε-distance.
<ul class="org-ul">
<li>Dense region: point in area &gt;= MinPoints.</li>
</ul></li>
<li>Key concepts:
<dl class="org-dl">
<dt>Core points</dt><dd>high-density.</dd>
<dt>Border points</dt><dd>near core points.</dd>
<dt>Noise</dt><dd>not in dense region.</dd>
</dl></li>
</ul>
</div>
</div>

<div id="outline-container-orge08291c" class="outline-3">
<h3 id="orge08291c"><span class="section-number-3">8.20.</span> DBScan Algorithm</h3>
<div class="outline-text-3" id="text-8-20">
<ul class="org-ul">
<li>Steps:
<ol class="org-ol">
<li>Build graph connecting core points to neighbors.</li>
<li>Identify connected components as clusters.</li>
<li>Remove clustered points and repeat.</li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-org0395cbc" class="outline-3">
<h3 id="org0395cbc"><span class="section-number-3">8.21.</span> DBScan Example</h3>
<div class="outline-text-3" id="text-8-21">
<ul class="org-ul">
<li>Visual example: finds 6 clusters, some noise points remain.</li>
</ul>
</div>
</div>

<div id="outline-container-org57c82e0" class="outline-3">
<h3 id="org57c82e0"><span class="section-number-3">8.22.</span> DBScan Quiz Question</h3>
<div class="outline-text-3" id="text-8-22">
<ul class="org-ul">
<li>Quiz: How many clusters can a point belong to in DBSCAN?</li>
</ul>
</div>
</div>

<div id="outline-container-org1f77296" class="outline-3">
<h3 id="org1f77296"><span class="section-number-3">8.23.</span> DBScan Quiz Solution</h3>
<div class="outline-text-3" id="text-8-23">
<ul class="org-ul">
<li>Answer: 0 or 1 (noise = 0, core/border = 1)</li>
</ul>
</div>
</div>

<div id="outline-container-org8875349" class="outline-3">
<h3 id="org8875349"><span class="section-number-3">8.24.</span> Clustering Evaluation Metrics</h3>
<div class="outline-text-3" id="text-8-24">
<ul class="org-ul">
<li>Metrics:
<ul class="org-ul">
<li>Rand Index (RI)</li>
<li>Mutual Information (MI)</li>
<li>Silhouette Coefficient</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org64bb603" class="outline-3">
<h3 id="org64bb603"><span class="section-number-3">8.25.</span> Rand Index</h3>
<div class="outline-text-3" id="text-8-25">
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Requires ground truth</span>.</li>
<li>Measures agreement between predicted and true clusters.</li>
<li>RI = (number of correct pairs) / (total pairs)</li>
<li>Value between 0 (bad) and 1 (perfect).</li>
</ul>
</div>
</div>

<div id="outline-container-orgec64ecd" class="outline-3">
<h3 id="orgec64ecd"><span class="section-number-3">8.26.</span> Mutual Information</h3>
<div class="outline-text-3" id="text-8-26">
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Requires ground truth</span>.</li>
<li>From information theory: measures <span style='background-color: #FFFF00;'>shared info</span> between predicted and true clusters, using joint probability of x and y.</li>
<li>Normalized Mutual Information (NMI) between 0 and 1 by dividing with sqrt of entropy of \(x\) &times; entropy of \(y\).</li>
</ul>
</div>
</div>

<div id="outline-container-orgb8fce8f" class="outline-3">
<h3 id="orgb8fce8f"><span class="section-number-3">8.27.</span> Summary of RI and MI</h3>
<div class="outline-text-3" id="text-8-27">
<ul class="org-ul">
<li>Pros of both:
<ul class="org-ul">
<li>Bounded values, interpretable.</li>
<li>No assumptions about cluster shapes.</li>
</ul></li>
<li>Cons of both:
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Require ground truth</span>, which may be unavailable.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org960b1c8" class="outline-3">
<h3 id="org960b1c8"><span class="section-number-3">8.28.</span> Silhouette Coefficient</h3>
<div class="outline-text-3" id="text-8-28">
<ul class="org-ul">
<li>Measures how similar a point is to its own cluster vs. others.</li>
<li>Formula: \((b - a) / max(a, b)\)</li>
<li>a: Find the average distance of \(x\) to all the points in its cluster.</li>
<li>b: Find the average distance of \(x\) to all the points <b><b>not</b></b> in its cluster.</li>
<li><span style='background-color: #FFFF00;'>Does not require ground truth</span>.</li>
</ul>
</div>
</div>

<div id="outline-container-orge2dfcc5" class="outline-3">
<h3 id="orge2dfcc5"><span class="section-number-3">8.29.</span> Silhouette Coefficient Pros and Cons</h3>
<div class="outline-text-3" id="text-8-29">
<ul class="org-ul">
<li>Range: -1 (bad) to 1 (good), 0 = overlapping clusters.</li>
<li>Assumes <span style='background-color: #FFFF00;'>spherical clusters</span> → less effective for complex shapes (e.g. DBSCAN).</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org8709cbe" class="outline-2">
<h2 id="org8709cbe"><span class="section-number-2">9.</span> Spark&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h2>
<div class="outline-text-2" id="text-9">
</div>
<div id="outline-container-orgedd9b63" class="outline-3">
<h3 id="orgedd9b63"><span class="section-number-3">9.1.</span> Introduction to Spark</h3>
<div class="outline-text-3" id="text-9-1">
<ul class="org-ul">
<li>Spark is introduced as an alternative to MapReduce, better suited for iterative workloads.</li>
<li>Leverages distributed memory across machines.</li>
<li>Core concept: Resilient Distributed Dataset (RDD).</li>
<li>Promotes efficiency for machine learning and healthcare applications.</li>
</ul>
</div>
</div>

<div id="outline-container-org21d7eef" class="outline-3">
<h3 id="org21d7eef"><span class="section-number-3">9.2.</span> Environment</h3>
<div class="outline-text-3" id="text-9-2">
<ul class="org-ul">
<li>Big data analytics typically run in data centers or cloud platforms like AWS, GCP, Azure.</li>
<li>Environment includes interconnected racks of servers.</li>
<li>Context set to understand the need for systems like Spark.</li>
</ul>
</div>
</div>

<div id="outline-container-org2005716" class="outline-3">
<h3 id="org2005716"><span class="section-number-3">9.3.</span> Motivation</h3>
<div class="outline-text-3" id="text-9-3">
<ul class="org-ul">
<li>Hadoop &amp; MapReduce explained with acyclic data flow using stable storage.
<img src="./img/acyclic-hadoop.png" alt="acyclic-hadoop.png" /></li>
<li>Strength: fault-tolerance via disk storage.</li>
<li>Weakness: inefficiency with <span style='background-color: #FFFF00;'>iterative</span> or <span style='background-color: #FFFF00;'>interactive</span> workloads (e.g. ML, graph analysis).</li>
<li>Need for in-memory computation system like Spark.</li>
</ul>
</div>
</div>

<div id="outline-container-org1cc1ecc" class="outline-3">
<h3 id="org1cc1ecc"><span class="section-number-3">9.4.</span> Iteration in Map Reduce</h3>
<div class="outline-text-3" id="text-9-4">
<ul class="org-ul">
<li>Machine learning models need <span style='background-color: #FFFF00;'>repeated computation</span>.</li>
<li>Hadoop repeatedly reads/writes from disk, causing inefficiency.</li>
<li>Highlights the need for <span style='background-color: #FFFF00;'>in-memory</span> operations.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb5d4679" class="outline-3">
<h3 id="orgb5d4679"><span class="section-number-3">9.5.</span> Workload Illustration</h3>
<div class="outline-text-3" id="text-9-5">
<ul class="org-ul">
<li>Iterative workloads: same computation on same data (e.g., model training).</li>
<li>Interactive workloads: varying computations on evolving data (e.g., data exploration).</li>
<li>Key: keep working sets <span style='background-color: #FFFF00;'>in memory</span> for speed.</li>
</ul>
</div>
</div>

<div id="outline-container-org3e9392e" class="outline-3">
<h3 id="org3e9392e"><span class="section-number-3">9.6.</span> Challenge</h3>
<div class="outline-text-3" id="text-9-6">
<ul class="org-ul">
<li>Challenge: <span style='background-color: #FFFF00;'>memory is not fault-tolerant</span>.</li>
<li>Existing storage abstractions rely on <span style='background-color: #FFFF00;'>fine-grained</span> updates, which are expensive to track.
<ul class="org-ul">
<li>Examples: databases, key-value stores, distributed memory.</li>
<li>These require replicating data or logs across nods for fault tolerance.</li>
</ul></li>
<li>Need for a better balance between efficiency and fault tolerance.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd001c91" class="outline-3">
<h3 id="orgd001c91"><span class="section-number-3">9.7.</span> Solution: RDDs</h3>
<div class="outline-text-3" id="text-9-7">
<ul class="org-ul">
<li>Spark uses RDDs to balance <span style='background-color: #FFFF00;'>fault-tolerance</span> and efficiency.</li>
<li>RDDs support <span style='background-color: #FFFF00;'>coarse-grained</span> transformations (e.g., map, group-by, join).
<ul class="org-ul">
<li>Coarse-grained = performed on <span style='background-color: #FFFF00;'>entire dataset</span> instead of specific parts of the dataset.</li>
</ul></li>
<li><span style='background-color: #FFFF00;'>Lineage</span> tracking enables fault recovery without excessive replication.
<ul class="org-ul">
<li>If failure happens, Spark recomputes the coarse-grained operations.</li>
<li><span style='background-color: #FFFF00;'>No cost if nothing fails</span>.</li>
</ul></li>
<li>Definition
<dl class="org-dl">
<dt>RDD</dt><dd>Resilient Distributed Dataset</dd>
</dl></li>
</ul>
</div>
</div>

<div id="outline-container-org55c7f57" class="outline-3">
<h3 id="org55c7f57"><span class="section-number-3">9.8.</span> RDD Recovery</h3>
<div class="outline-text-3" id="text-9-8">

<div id="org2694056" class="figure">
<p><img src="./img/rdd-recovery.png" alt="rdd-recovery.png" />
</p>
</div>
<ul class="org-ul">
<li>Recovery through recomputation based on lineage.</li>
<li>Interactive: rerun only failed <span style='background-color: #FFFF00;'>iterations</span>.</li>
<li>Iterative: reload or recompute <span style='background-color: #FFFF00;'>chunks</span> from previous iterations.</li>
<li>Spark is a big-data system built on top of RDDs.</li>
</ul>
</div>
</div>

<div id="outline-container-org050f735" class="outline-3">
<h3 id="org050f735"><span class="section-number-3">9.9.</span> Spark Stack</h3>
<div class="outline-text-3" id="text-9-9">

<div id="orgd2e5b10" class="figure">
<p><img src="./img/spark-stack.png" alt="spark-stack.png" />
</p>
</div>
<ul class="org-ul">
<li>Core: scheduling, memory management, fault recovery.</li>
<li>APIs: Spark SQL, Streaming, MLib (ML), GraphX.</li>
<li>Compatible with YARN, Mesos, or standalone.</li>
</ul>
</div>
</div>

<div id="outline-container-org4eca585" class="outline-3">
<h3 id="org4eca585"><span class="section-number-3">9.10.</span> Spark Programming Interface</h3>
<div class="outline-text-3" id="text-9-10">
<ul class="org-ul">
<li>Interfaces: Scala, Python, Java.</li>
<li>RDD operations: transformations and actions.</li>
<li>Support for shared variables (broadcast, accumulator).</li>
</ul>
</div>
</div>

<div id="outline-container-org3641e18" class="outline-3">
<h3 id="org3641e18"><span class="section-number-3">9.11.</span> RDD Transformations</h3>
<div class="outline-text-3" id="text-9-11">
<ul class="org-ul">
<li>Examples: map vs flatMap, distinct, union, intersection, subtract.</li>
<li>flatMap flattens nested lists from map.
<ul class="org-ul">
<li>Often want `flatMap` instead to get everything in 1 single flat list, instead of lists of lists.</li>
</ul></li>
<li>Distinct, union are relatively cheap.</li>
<li>Intersection and subtract are more costly due to set operations (distinct, combining, sorting, etc).</li>
</ul>
</div>
</div>
<div id="outline-container-org25adadd" class="outline-3">
<h3 id="org25adadd"><span class="section-number-3">9.12.</span> RDD Transformations Quiz Question</h3>
<div class="outline-text-3" id="text-9-12">
<ul class="org-ul">
<li>Quiz: Apply map and filter on input RDD to understand transformation output.</li>
</ul>
</div>
</div>

<div id="outline-container-org04d7c22" class="outline-3">
<h3 id="org04d7c22"><span class="section-number-3">9.13.</span> RDD Transformations Quiz Solution</h3>
<div class="outline-text-3" id="text-9-13">
<ul class="org-ul">
<li>Map squares each number: [1, 4, 9, 16].</li>
<li>Filter excludes ‘1’: resulting in [2, 3, 4].</li>
</ul>
</div>
</div>

<div id="outline-container-org5c20d6a" class="outline-3">
<h3 id="org5c20d6a"><span class="section-number-3">9.14.</span> Spark Operations</h3>
<div class="outline-text-3" id="text-9-14">

<div id="orgb7eb852" class="figure">
<p><img src="./img/spark-ops.png" alt="spark-ops.png" />
</p>
</div>
<ul class="org-ul">
<li>Transformations: map, filter, groupByKey, etc.</li>
<li>Actions: reduce, collect, count, etc.</li>
<li>Broader set than Hadoop MapReduce.</li>
</ul>
</div>
</div>

<div id="outline-container-org3b0f7be" class="outline-3">
<h3 id="org3b0f7be"><span class="section-number-3">9.15.</span> Shared Variable</h3>
<div class="outline-text-3" id="text-9-15">
<ul class="org-ul">
<li>Broadcast variables: <span style='background-color: #FFFF00;'>efficient read-only</span> shared data.</li>
<li>Example Spark job with clinical notes:
<ul class="org-ul">
<li>Load data → filter → split → cache.</li>
<li>Perform actions like counting specific symptoms (e.g., fever, cough).</li>
<li>Benefits from <span style='background-color: #FFFF00;'>caching</span> and <span style='background-color: #FFFF00;'>distributed execution</span>.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgbe2d63b" class="outline-3">
<h3 id="orgbe2d63b"><span class="section-number-3">9.16.</span> Fault Tolerance</h3>
<div class="outline-text-3" id="text-9-16">
<ul class="org-ul">
<li>RDD tracks transformations (<span style='background-color: #FFFF00;'>lineage</span>).</li>
<li>Lost partitions can be recomputed using lineage.</li>
<li>Visuals: sequence of filters and maps reconstruct lost data.</li>
</ul>
</div>
</div>

<div id="outline-container-org0b4ad8a" class="outline-3">
<h3 id="org0b4ad8a"><span class="section-number-3">9.17.</span> Example: <span style='background-color: #FFFF00;'>Logistic Regression</span>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-9-17">
<ul class="org-ul">
<li>Spark efficiently supports logistic regression via iteration.</li>
<li>Data cached in memory → quick updates.</li>
<li>Uses map + reduce to <span style='background-color: #FFFF00;'>compute gradient</span>.</li>
<li>Spark (6s/iter) is <span style='background-color: #FFFF00;'>much faster</span> than Hadoop (127s/iter) for this use case.</li>
</ul>
</div>
</div>

<div id="outline-container-org1416306" class="outline-3">
<h3 id="org1416306"><span class="section-number-3">9.18.</span> Example: Disease Risk Prediction</h3>
<div class="outline-text-3" id="text-9-18">
<ul class="org-ul">
<li>Predict patient disease risks using collaborative filtering.</li>
<li>Matrix R = patient × disease.</li>
<li>ALS algorithm: alternates updating patient and disease features.</li>
<li>Definition:
<dl class="org-dl">
<dt>ALS</dt><dd>Alternating least squares</dd>
</dl></li>
</ul>
</div>
</div>

<div id="outline-container-orgad33a85" class="outline-3">
<h3 id="orgad33a85"><span class="section-number-3">9.19.</span> Serial ALS</h3>
<div class="outline-text-3" id="text-9-19">
<ul class="org-ul">
<li>Serial implementation of ALS.</li>
<li>Iterative updates of A (patient) and B (disease) matrices.</li>
<li>Uses map functions over patient/disease ranges.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd6aa8ee" class="outline-3">
<h3 id="orgd6aa8ee"><span class="section-number-3">9.20.</span> Naive Spark ALS</h3>
<div class="outline-text-3" id="text-9-20">
<ul class="org-ul">
<li>Parallel ALS using <code>spark.parallelize</code>.</li>
<li>Broadcast used for efficient data sharing.</li>
<li>Broadcast improves performance 3× over naive version.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org31cff0d" class="outline-2">
<h2 id="org31cff0d"><span class="section-number-2">10.</span> Medical Ontology</h2>
<div class="outline-text-2" id="text-10">
</div>
<div id="outline-container-org2816931" class="outline-3">
<h3 id="org2816931"><span class="section-number-3">10.1.</span> Introduction to Medical Ontology</h3>
<div class="outline-text-3" id="text-10-1">
<ul class="org-ul">
<li>Healthcare benefits from structured medical knowledge.</li>
<li>Ontologies and knowledge graphs are common in this domain.</li>
<li>Historically, healthcare has developed ontologies for:
<ul class="org-ul">
<li>Diseases</li>
<li>Medical procedures</li>
<li>Medications</li>
<li>Lab tests</li>
</ul></li>
<li>Ontologies aid understanding of healthcare data and validate data models.</li>
<li>The lesson discusses various ontologies and their role in analytics.</li>
</ul>
</div>
</div>

<div id="outline-container-org4994dc3" class="outline-3">
<h3 id="org4994dc3"><span class="section-number-3">10.2.</span> Health Data Standards</h3>
<div class="outline-text-3" id="text-10-2">
<ul class="org-ul">
<li>Overview of major health data standards:
<dl class="org-dl">
<dt>LOINC</dt><dd>Lab test codes (Logical Observation Identifiers Names and Codes)</dd>
<dt>ICD</dt><dd>Diagnostic codes (International Classification of Disease)</dd>
<dt>CPT</dt><dd>Procedure codes (Current Procedural Terminology)</dd>
<dt>NDC</dt><dd>Medication codes (National Drug Code)</dd>
<dt>SNOMED</dt><dd>A comprehensive ontology integrating all the above (Systemized Nomenclature of Medicine)</dd>
<dt>UMLS</dt><dd>Software system that accesses integrated medical knowledge (Unified Medical Language System)</dd>
</dl></li>
<li>Use case: Patient encounter example illustrating all standard usages.</li>
<li>Importance:
<ul class="org-ul">
<li>Insurance claim processing</li>
<li>Research and data analysis</li>
</ul></li>
<li>Preview of upcoming detailed discussions on individual standards.</li>
</ul>
</div>
</div>

<div id="outline-container-org326d0a3" class="outline-3">
<h3 id="org326d0a3"><span class="section-number-3">10.3.</span> ICD</h3>
<div class="outline-text-3" id="text-10-3">
<ul class="org-ul">
<li>ICD = International Classification of Diseases.</li>
<li>Developed by WHO and categorizes diseases.</li>
<li>ICD-9: 17,000+ codes; <span style='background-color: #FFFF00;'>3-5</span> digits
<img src="./img/icd9.png" alt="icd9.png" />
<ul class="org-ul">
<li>Includes main and supplementary categories (e.g., <span style='background-color: #FFFF00;'>E</span> codes).</li>
</ul></li>
<li>ICD-10: 141,000+ codes; 7-character alphanumeric structure.
<img src="./img/icd10.png" alt="icd10.png" /></li>
<li>Detailed coding for category, etiology, body part, severity, and extension.</li>
<li>Examples:
<ul class="org-ul">
<li>ICD-9: 250.01 = Type 1 diabetes, no complications</li>
<li>ICD-10: M1A.31X2 = Chronic gout with renal impairment in left shoulder, no tophus</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orge9a4fb6" class="outline-3">
<h3 id="orge9a4fb6"><span class="section-number-3">10.4.</span> ICD 9 to ICD 10 Mapping</h3>
<div class="outline-text-3" id="text-10-4">
<ul class="org-ul">
<li>Mapping is mostly <span style='background-color: #FFFF00;'>one-to-many</span> due to ICD-10's higher specificity.</li>
<li>Some mappings are one-to-one (e.g., Tietze's Syndrome) if ICD-9 is already specific.</li>
<li>Complicated mappings: e.g., ICD-9 code maps to 2,530 ICD-10 codes.</li>
<li>Complexity highlights the increased detail of ICD-10.</li>
</ul>
</div>
</div>

<div id="outline-container-org446139e" class="outline-3">
<h3 id="org446139e"><span class="section-number-3">10.5.</span> ICD 9 Quiz Question</h3>
<div class="outline-text-3" id="text-10-5">
<ul class="org-ul">
<li>Identifies valid and invalid ICD-9 codes.</li>
</ul>
</div>
</div>

<div id="outline-container-orge4918d4" class="outline-3">
<h3 id="orge4918d4"><span class="section-number-3">10.6.</span> ICD 9 Quiz Solution</h3>
<div class="outline-text-3" id="text-10-6">
<ul class="org-ul">
<li>Valid: 501, 802.3, V70, E820.0</li>
<li>Invalid: U80.1, 5A0.01</li>
</ul>
</div>
</div>

<div id="outline-container-org6e43698" class="outline-3">
<h3 id="org6e43698"><span class="section-number-3">10.7.</span> ICD Code Quiz Question</h3>
<div class="outline-text-3" id="text-10-7">
<ul class="org-ul">
<li>Task: Find ICD-9 and ICD-10 codes for Influenza.</li>
</ul>
</div>
</div>

<div id="outline-container-orge047fa7" class="outline-3">
<h3 id="orge047fa7"><span class="section-number-3">10.8.</span> ICD Code Quiz Solution</h3>
<div class="outline-text-3" id="text-10-8">
<ul class="org-ul">
<li>ICD-9: 487.1</li>
<li>ICD-10: J11.1</li>
</ul>
</div>
</div>

<div id="outline-container-org5909d7f" class="outline-3">
<h3 id="org5909d7f"><span class="section-number-3">10.9.</span> CPT</h3>
<div class="outline-text-3" id="text-10-9">
<ul class="org-ul">
<li>CPT = Current Procedural Terminology. US standard.</li>
<li>Used for medical, surgical, diagnostic procedures.</li>
<li>Maintained by the American Medical Association.</li>
<li>Key for insurance reimbursement.</li>
<li>Categories:
<ul class="org-ul">
<li>Category 1: Common procedures (e.g., surgery, radiology)</li>
<li>Category 2: Quality metrics</li>
<li>Category 3: Experimental procedures (e.g., codes ending in T)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgde076da" class="outline-3">
<h3 id="orgde076da"><span class="section-number-3">10.10.</span> CPT Code Quiz Question</h3>
<div class="outline-text-3" id="text-10-10">
<ul class="org-ul">
<li>Task: Find CPT code for detailed office visit.</li>
</ul>
</div>
</div>

<div id="outline-container-orgde970ee" class="outline-3">
<h3 id="orgde970ee"><span class="section-number-3">10.11.</span> CPT Code Quiz Solution</h3>
<div class="outline-text-3" id="text-10-11">
<ul class="org-ul">
<li>Office visit range: 99201–99205</li>
<li>Time-based codes (e.g., 99201 = 10 mins, 99205 = 1 hour)</li>
</ul>
</div>
</div>

<div id="outline-container-orga017774" class="outline-3">
<h3 id="orga017774"><span class="section-number-3">10.12.</span> LOINC</h3>
<div class="outline-text-3" id="text-10-12">
<ul class="org-ul">
<li>LOINC = Logical Observation Identifiers Names and Codes.</li>
<li>Created by Regenstrief Institute.</li>
<li>Standard for <span style='background-color: #FFFF00;'>lab tests and clinical observations</span>.</li>
<li>Example: 2865-4 = a specific lab test</li>
<li>Attributes:
<ul class="org-ul">
<li>Component</li>
<li>Property</li>
<li>Time aspect (e.g., Pt = point in time)</li>
<li>Sample type</li>
<li>Scale (quantitative, ordinal, narrative, etc.)</li>
<li>Method (e.g. electrophoresis)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgb72d1ed" class="outline-3">
<h3 id="orgb72d1ed"><span class="section-number-3">10.13.</span> LOINC Code Quiz Question</h3>
<div class="outline-text-3" id="text-10-13">
<ul class="org-ul">
<li>Task: Find LOINC code for Creatinine lab test.</li>
</ul>
</div>
</div>

<div id="outline-container-org3e67961" class="outline-3">
<h3 id="org3e67961"><span class="section-number-3">10.14.</span> LOINC Code Quiz Solution</h3>
<div class="outline-text-3" id="text-10-14">
<ul class="org-ul">
<li>Answer: 2160-0</li>
</ul>
</div>
</div>

<div id="outline-container-orgd08423c" class="outline-3">
<h3 id="orgd08423c"><span class="section-number-3">10.15.</span> NDC</h3>
<div class="outline-text-3" id="text-10-15">
<ul class="org-ul">
<li>NDC = National Drug Code (for medications).</li>
<li>Maintained by the FDA, US standard.</li>
<li>Structure: 3 segments
<ul class="org-ul">
<li>Labeler code (company)</li>
<li>Product code (drug type)</li>
<li>Package code (package details)</li>
</ul></li>
<li>Different digit combinations exist but total is 10 digits.</li>
</ul>
</div>
</div>

<div id="outline-container-orgdb1ff45" class="outline-3">
<h3 id="orgdb1ff45"><span class="section-number-3">10.16.</span> NDC Code Quiz Question</h3>
<div class="outline-text-3" id="text-10-16">
<ul class="org-ul">
<li>Task: Find NDC code for metformin hydrochloride, 500mg.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc591b17" class="outline-3">
<h3 id="orgc591b17"><span class="section-number-3">10.17.</span> NDC Code Quiz Solution</h3>
<div class="outline-text-3" id="text-10-17">
<ul class="org-ul">
<li>Example code: 0093-7214-01 (labeler-dependent)</li>
</ul>
</div>
</div>

<div id="outline-container-org85b02f1" class="outline-3">
<h3 id="org85b02f1"><span class="section-number-3">10.18.</span> SNOMED</h3>
<div class="outline-text-3" id="text-10-18">
<ul class="org-ul">
<li>SNOMED = Systematized Nomenclature of Medicine.</li>
<li>Maintained by IHTSDO (Denmark).</li>
<li>Supports clinical documentation and semantic interoperability.</li>
<li>National editions and implementation subsets exist.</li>
<li>Broad user base: clinicians, researchers, analysts.</li>
</ul>
</div>
</div>

<div id="outline-container-org96fc2c1" class="outline-3">
<h3 id="org96fc2c1"><span class="section-number-3">10.19.</span> Logical Model of SNOMED CT</h3>
<div class="outline-text-3" id="text-10-19">
<ul class="org-ul">
<li>Core components:
<ul class="org-ul">
<li>Concepts (with unique ID)</li>
<li>Descriptions (Fully specified name, FSN, and synonyms)</li>
<li>Relationships (e.g., “is a”, attributes)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgd0e705b" class="outline-3">
<h3 id="orgd0e705b"><span class="section-number-3">10.20.</span> SNOMED Example</h3>
<div class="outline-text-3" id="text-10-20">
<ul class="org-ul">
<li>Example concept: 22298006 = Myocardial infarction disorder</li>
<li>Multiple descriptions including synonyms</li>
<li>Preferred vs. acceptable terms are defined by reference sets by country.</li>
</ul>
</div>
</div>

<div id="outline-container-org14de742" class="outline-3">
<h3 id="org14de742"><span class="section-number-3">10.21.</span> SNOMED Relationships</h3>
<div class="outline-text-3" id="text-10-21">
<ul class="org-ul">
<li>“Is a” relationship creates concept hierarchies.</li>
<li>Example: Cellulitis of foot “is a” cellulitis, and “is a” disorder of foot.</li>
<li>Relationships are directional and acyclic.</li>
</ul>
</div>
</div>

<div id="outline-container-org2eb4ef6" class="outline-3">
<h3 id="org2eb4ef6"><span class="section-number-3">10.22.</span> SNOMED Design</h3>
<div class="outline-text-3" id="text-10-22">
<ul class="org-ul">
<li>19-level hierarchy of concepts.</li>
<li>Concepts range from general to highly specific.</li>
<li>Relationships include “is a” and others with attributes.</li>
<li>Each concept has a unique ID and descriptions.</li>
</ul>
</div>
</div>

<div id="outline-container-orgedb4911" class="outline-3">
<h3 id="orgedb4911"><span class="section-number-3">10.23.</span> SNOMED Code Quiz Question</h3>
<div class="outline-text-3" id="text-10-23">
<ul class="org-ul">
<li>Task: Find SNOMED code for chronic gouty arthritis.</li>
</ul>
</div>
</div>

<div id="outline-container-org6dded5c" class="outline-3">
<h3 id="org6dded5c"><span class="section-number-3">10.24.</span> SNOMED Code Quiz Solution</h3>
<div class="outline-text-3" id="text-10-24">
<ul class="org-ul">
<li>Answer: 68451005</li>
</ul>
</div>
</div>

<div id="outline-container-orga034638" class="outline-3">
<h3 id="orga034638"><span class="section-number-3">10.25.</span> SNOMED Quiz Question</h3>
<div class="outline-text-3" id="text-10-25">
<ul class="org-ul">
<li>Question: What is the structure of "is a" relationships in SNOMED?</li>
</ul>
</div>
</div>

<div id="outline-container-org135ddae" class="outline-3">
<h3 id="org135ddae"><span class="section-number-3">10.26.</span> SNOMED Quiz Solution</h3>
<div class="outline-text-3" id="text-10-26">
<ul class="org-ul">
<li>Answer: Directed acyclic graph (not a tree), without cycles. Every relationship has directions (start from specific to general &amp; will not come back).</li>
</ul>
</div>
</div>

<div id="outline-container-org457ad4a" class="outline-3">
<h3 id="org457ad4a"><span class="section-number-3">10.27.</span> UMLS</h3>
<div class="outline-text-3" id="text-10-27">
<ul class="org-ul">
<li>UMLS = Unified Medical Language System.</li>
<li>Maintained by US National Library of Medicine.</li>
<li>Integrates multiple standards into a unified system.</li>
<li>Components:
<ul class="org-ul">
<li>Metathesaurus</li>
<li>Semantic network</li>
<li>Specialist lexicon and tools</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgf90c1df" class="outline-3">
<h3 id="orgf90c1df"><span class="section-number-3">10.28.</span> Metathesaurus Concepts</h3>
<div class="outline-text-3" id="text-10-28">
<ul class="org-ul">
<li>Concept hierarchy:
<ul class="org-ul">
<li>Atom (AUI) → String (SUI) → Term (LUI) → Concept (CUI)</li>
</ul></li>
<li>Multiple ontologies/sources integrated.</li>
<li>Term: normalized name</li>
<li>Concept: synonym</li>
</ul>
</div>
</div>

<div id="outline-container-orgcccaa38" class="outline-3">
<h3 id="orgcccaa38"><span class="section-number-3">10.29.</span> Semantic Network</h3>
<div class="outline-text-3" id="text-10-29">
<ul class="org-ul">
<li>135+ semantic types (e.g., diseases, drugs)</li>
<li>54+ semantic relationships (e.g., cause, treat)</li>
<li>Organizes concepts and their interrelations.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc975459" class="outline-3">
<h3 id="orgc975459"><span class="section-number-3">10.30.</span> Specialist Lexicon</h3>
<div class="outline-text-3" id="text-10-30">
<ul class="org-ul">
<li>Lexicon of 300,000+ biomedical terms.</li>
<li>Includes syntax, morphology, orthography.</li>
<li>Used in NLP tools like MetaMap and MMTX.</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org4c5999f" class="outline-2">
<h2 id="org4c5999f"><span class="section-number-2">11.</span> Graph Analysis</h2>
<div class="outline-text-2" id="text-11">
</div>
<div id="outline-container-org1769ef1" class="outline-3">
<h3 id="org1769ef1"><span class="section-number-3">11.1.</span> Introduction to Graph Analysis</h3>
<div class="outline-text-3" id="text-11-1">
<ul class="org-ul">
<li>Overview of graph analysis and its applications.</li>
<li>Used in search engines, social networks, and healthcare.</li>
<li>Identifies clusters of related entities (webpages, patients, conditions).</li>
<li>Will cover similarity graphs and spectral clustering.</li>
</ul>
</div>
</div>

<div id="outline-container-org36ddb8d" class="outline-3">
<h3 id="org36ddb8d"><span class="section-number-3">11.2.</span> Agenda</h3>
<div class="outline-text-3" id="text-11-2">
<ul class="org-ul">
<li>Two main graph-based algorithms introduced:
<ul class="org-ul">
<li>PageRank: Ranks nodes in a directed graph based on importance.</li>
<li>Spectral Clustering: A graph partitioning-based clustering algorithm.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgbe95395" class="outline-3">
<h3 id="orgbe95395"><span class="section-number-3">11.3.</span> PageRank</h3>
<div class="outline-text-3" id="text-11-3">
<ul class="org-ul">
<li>Developed by Google co-founders for webpage ranking.</li>
<li>Traditional content-based ranking is prone to spam.</li>
<li>PageRank relies on the graph structure (links between pages).</li>
<li>Intuition: More high-quality pages linking to a page → higher rank.</li>
<li>Represent graph using an adjacency matrix:
<ul class="org-ul">
<li>where: row represents <b><b>source</b></b> and column <b><b>destination</b></b>.</li>
<li>Normalize matrix rows to represent transition probabilities.</li>
<li>PageRank computed using recursion: browsing + teleporting.</li>
<li>Browsing redistributes rank via adjacency matrix; teleporting randomly jumps.</li>
<li>Equation:
\[
    q = cAT^ q + \frac{1 - c}{N} e
    \]
where:
<dl class="org-dl">
<dt>\(c\)</dt><dd>the % of activity that is "structured and not random", between 0-1 (e.g., 0.85)</dd>
<dt>\(e\)</dt><dd>the ones vector.</dd>
</dl></li>
</ul></li>

<li>Next steps: Implement PageRank using big data systems like Hadoop MapReduce.</li>
</ul>
</div>
</div>

<div id="outline-container-orga5b6b62" class="outline-3">
<h3 id="orga5b6b62"><span class="section-number-3">11.4.</span> MapReduce  PageRank</h3>
<div class="outline-text-3" id="text-11-4">
<ul class="org-ul">
<li>Implementation of PageRank in MapReduce:
<ul class="org-ul">
<li><b><b>Map Phase</b></b>:
<img src="./img/map-pagerank.png" alt="map-pagerank.png" />
<ul class="org-ul">
<li>Emit current page and its PageRank.</li>
<li>Distribute PageRank to each outgoing link equally.</li>
</ul></li>
<li><b><b>Reduce Phase</b></b>:
<img src="./img/preduce-pagerank.png" alt="preduce-pagerank.png" />
<ul class="org-ul">
<li>Aggregate partial PageRanks from map phase.</li>
<li>Add teleporting component.</li>
<li>Emit updated PageRank.</li>
</ul></li>
<li>Hadoop shuffles partial sums to reducers.</li>
<li><span style='background-color: #FFFF00;'>Iterative process</span>: repeat map-reduce steps to converge.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org4b5fdbc" class="outline-3">
<h3 id="org4b5fdbc"><span class="section-number-3">11.5.</span> PageRank Quiz Question</h3>
<div class="outline-text-3" id="text-11-5">
<ul class="org-ul">
<li>Quiz: Rank webpages in a directed graph by PageRank (based on structure).</li>
</ul>
</div>
</div>

<div id="outline-container-org9bc89f1" class="outline-3">
<h3 id="org9bc89f1"><span class="section-number-3">11.6.</span> PageRank Quiz Solution</h3>
<div class="outline-text-3" id="text-11-6">
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>More incoming links = better</span></li>
<li>Highest: YouTube (3 incoming links).</li>
<li>Lowest: Google (no incoming links).</li>
<li>Recursive PageRank shows differences despite similar local structures.</li>
<li>Amazon &gt; Wikipedia &gt; Facebook in mid-tier due to recursion effects.</li>
</ul>
</div>
</div>

<div id="outline-container-orge0bc9f6" class="outline-3">
<h3 id="orge0bc9f6"><span class="section-number-3">11.7.</span> Spectral Clustering</h3>
<div class="outline-text-3" id="text-11-7">
<ul class="org-ul">
<li>Spectral Clustering vs Traditional Clustering:
<ul class="org-ul">
<li>Uses similarity graph of patients based on features.</li>
<li>Steps:
<img src="./img/spec-graph-matrix.png" alt="spec-graph-matrix.png" />
<ol class="org-ol">
<li>Construct similarity graph (nodes = patients, edges = similarity).</li>
<li>Convert graph to adjacency matrix.
<img src="./img/spec-eigen.png" alt="spec-eigen.png" /></li>
<li>Compute top-k eigenvectors of the matrix.</li>
<li>Cluster eigenvectors into groups.</li>
</ol></li>
<li>Effective for high-dimensional or noisy data.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgf230405" class="outline-3">
<h3 id="orgf230405"><span class="section-number-3">11.8.</span> Similarity Graph Construction</h3>
<div class="outline-text-3" id="text-11-8">
<ul class="org-ul">
<li>Several ways to construct similarity graphs:
<ul class="org-ul">
<li>Epsilon-neighborhood.</li>
<li>K-nearest neighbors.</li>
<li>Fully connected with edge weights (e.g., Gaussian kernel).</li>
</ul></li>
<li>Purpose: capture local similarity between patients.</li>
</ul>
</div>
</div>

<div id="outline-container-org18eba61" class="outline-3">
<h3 id="org18eba61"><span class="section-number-3">11.9.</span> E Neighborhood Graph</h3>
<div class="outline-text-3" id="text-11-9">
<ul class="org-ul">
<li>Connect nodes within ε distance.</li>
<li>No edge if distance &gt; ε.</li>
<li>Defines sparsity based on ε.</li>
</ul>
</div>
</div>

<div id="outline-container-orgdd66653" class="outline-3">
<h3 id="orgdd66653"><span class="section-number-3">11.10.</span> K Nearest Neighbor Graph</h3>
<div class="outline-text-3" id="text-11-10">
<ul class="org-ul">
<li>Each node connects to its k-nearest neighbors (directed).</li>
<li>Results in <span style='background-color: #FFFF00;'>sparse graphs for small k</span>.</li>
<li>Variants: binary edges vs weighted edges based on distance.</li>
</ul>
</div>
</div>

<div id="outline-container-org14cb179" class="outline-3">
<h3 id="org14cb179"><span class="section-number-3">11.11.</span> Fully Connected Graph</h3>
<div class="outline-text-3" id="text-11-11">
<ul class="org-ul">
<li>Every node connected to every other.</li>
<li>Edge weights determined by similarity (e.g., similarity function \(w\) is the Gaussian kernel).</li>
<li><span style='background-color: #FFFF00;'>Most dense</span> graph representation.</li>
</ul>
</div>
</div>

<div id="outline-container-orgfe40e4b" class="outline-3">
<h3 id="orgfe40e4b"><span class="section-number-3">11.12.</span> E Neighborhood Graph Quiz Question</h3>
<div class="outline-text-3" id="text-11-12">
<ul class="org-ul">
<li>Quiz: Select best ε value to reflect clustering structure in 2D patient data.</li>
</ul>
</div>
</div>

<div id="outline-container-orgae4fba1" class="outline-3">
<h3 id="orgae4fba1"><span class="section-number-3">11.13.</span> E Neighborhood Graph Quiz Solution</h3>
<div class="outline-text-3" id="text-11-13">
<ul class="org-ul">
<li>Small ε: too many disconnected clusters.</li>
<li>Large ε: single cluster.</li>
<li>Optimal ε (e.g., B or C) reveals natural clusters in data.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb72f88e" class="outline-3">
<h3 id="orgb72f88e"><span class="section-number-3">11.14.</span> Spectral Clustering Algorithm</h3>
<div class="outline-text-3" id="text-11-14">
<ul class="org-ul">
<li>Variations exist:
<ul class="org-ul">
<li>Unnormalized vs Normalized Spectral Clustering.</li>
</ul></li>
<li>Example: simplest uses eigenvectors + k-means.</li>
<li>Spectral clustering <span style='background-color: #FFFF00;'>transforms data to eigenspace</span> where clusters are clearer.</li>
<li>Recommended reading for theoretical underpinnings.</li>
</ul>
</div>
</div>

<div id="outline-container-orge5b04e6" class="outline-3">
<h3 id="orge5b04e6"><span class="section-number-3">11.15.</span> Big Data Conclusion</h3>
<div class="outline-text-3" id="text-11-15">
<ul class="org-ul">
<li>Wrap-up of the video series.</li>
<li>Presenter: Jimmy Son.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org113db2f" class="outline-2">
<h2 id="org113db2f"><span class="section-number-2">12.</span> Dimensionality Reduction</h2>
<div class="outline-text-2" id="text-12">
</div>
<div id="outline-container-orgf356b8d" class="outline-3">
<h3 id="orgf356b8d"><span class="section-number-3">12.1.</span> Introduction to Dimensionality Reduction</h3>
<div class="outline-text-3" id="text-12-1">
<ul class="org-ul">
<li>Overview of dimensionality reduction as a method for simplifying noisy, high-dimensional data.</li>
<li>Methods covered:
<ul class="org-ul">
<li>Singular Value Decomposition (SVD)</li>
<li>Principal Component Analysis (PCA)</li>
<li>CUR Decomposition</li>
<li>Tensor Factorization</li>
</ul></li>
<li>Applications in predictive modeling and healthcare phenotyping.</li>
</ul>
</div>
</div>

<div id="outline-container-org30b683f" class="outline-3">
<h3 id="org30b683f"><span class="section-number-3">12.2.</span> Dimensionality Reduction</h3>
<div class="outline-text-3" id="text-12-2">
<ul class="org-ul">
<li>Recap of clustering algorithms (hard, soft, and scalable).</li>
<li>Motivation for dimensionality reduction: <span style='background-color: #FFFF00;'>efficiency and robustness</span>.</li>
<li>Classical methods:
<ul class="org-ul">
<li>SVD and PCA: summarize features via linear combinations.</li>
<li>CUR: uses actual data rows/columns, preserves sparsity.</li>
</ul></li>
<li>Introduction to Tensor Factorization for higher-order data.</li>
</ul>
</div>
</div>

<div id="outline-container-org54b2f47" class="outline-3">
<h3 id="org54b2f47"><span class="section-number-3">12.3.</span> Singular Value Decomposition</h3>
<div class="outline-text-3" id="text-12-3">

<div id="orge228fd8" class="figure">
<p><img src="./img/svd1.png" alt="svd1.png" />
</p>
</div>
<ul class="org-ul">
<li>Definition: SVD decomposes a matrix \(X\) into \(U, \Sigma, V^T\).</li>
<li>U and V: orthogonal matrices (singular vectors).</li>
<li>Σ: diagonal matrix with singular values (in descending order).</li>
<li>Visual interpretation with patients (rows) and diseases (columns).</li>
</ul>
</div>
</div>

<div id="outline-container-org0f1d7e1" class="outline-3">
<h3 id="org0f1d7e1"><span class="section-number-3">12.4.</span> SVD Example</h3>
<div class="outline-text-3" id="text-12-4">
<ul class="org-ul">
<li>Spectral view: rank-1 approximations via \(\sigma_i u_i v_i^T\).</li>
<li>Example with documents and terms:
<ul class="org-ul">
<li>Computer Science vs. Medical documents.</li>
<li>Each rank-1 component captures topic-specific vocabulary.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org474655d" class="outline-3">
<h3 id="org474655d"><span class="section-number-3">12.5.</span> SVD Properties</h3>
<div class="outline-text-3" id="text-12-5">
<dl class="org-dl">
<dt>V</dt><dd>eigenvectors of covariance matrix \(X^T X\) with eigenvalues Σ².
\(X^T X = (U \Sigma V^T)^T (U \Sigma V^T) = V \Sigma^2 V^T\)</dd>
<dt>U</dt><dd>eigenvectors of the Gram (inner-product) matrix \(X X^T\).
\(X X^T = (U \Sigma V^T)(U \Sigma V^T)^T = U \Sigma^2 U^T\)</dd>
</dl>

<p>
Reinforces relationship between SVD and eigen-decomposition.
</p>
</div>
</div>

<div id="outline-container-orgfddce12" class="outline-3">
<h3 id="orgfddce12"><span class="section-number-3">12.6.</span> Quiz  SVD Interpretation Question</h3>
<div class="outline-text-3" id="text-12-6">
<ul class="org-ul">
<li>Question about \(A^T A\) matrix from a document-term matrix.</li>
</ul>
</div>
</div>

<div id="outline-container-orga43dea8" class="outline-3">
<h3 id="orga43dea8"><span class="section-number-3">12.7.</span> Quiz  SVD Interpretation Solution</h3>
<div class="outline-text-3" id="text-12-7">
<ul class="org-ul">
<li>Answer: \(A^T A\) is a <span style='background-color: #FFFF00;'>term-to-term</span> similarity matrix.
Number of rows &amp; columns = number of terms.</li>
</ul>
</div>
</div>

<div id="outline-container-orgcf4a5d6" class="outline-3">
<h3 id="orgcf4a5d6"><span class="section-number-3">12.8.</span> Principal Component Analysis</h3>
<div class="outline-text-3" id="text-12-8">
<p>
<img src="./img/pca1.png" alt="pca1.png" />
\(X = (U \Sigma) V^T\)
</p>
<ul class="org-ul">
<li>PCA is derived from SVD: \(U \Sigma\) = principal components, \(V^T\) = loadings.</li>
<li>Visualized with a patient-by-disease matrix.</li>
<li>Principal components capture the main variance direction.</li>
</ul>
</div>
</div>

<div id="outline-container-org9b881c4" class="outline-3">
<h3 id="org9b881c4"><span class="section-number-3">12.9.</span> PCA Interpretation</h3>
<div class="outline-text-3" id="text-12-9">

<div id="org8c57c55" class="figure">
<p><img src="./img/pca-int.png" alt="pca-int.png" />
</p>
</div>
<ul class="org-ul">
<li>PCA reduces dimensions by projecting onto principal component directions.</li>
<li>Example with weight and height to one dimension.</li>
</ul>
</div>
</div>

<div id="outline-container-orgec4c114" class="outline-3">
<h3 id="orgec4c114"><span class="section-number-3">12.10.</span> Sparsity Problem with SVD</h3>
<div class="outline-text-3" id="text-12-10">
<ul class="org-ul">
<li>SVD and PCA generate dense outputs, losing sparsity of original data, especially the \(U\) and \(V\) matrices.</li>
<li>SVD destroys the sparsity of the original data and takes a lot <span style='background-color: #FFFF00;'>more</span> storage space and computation time for subsequent analysis.</li>
<li>CUR decomposition preserves sparsity and <span style='background-color: #FFFF00;'>reduces storage/computation cost</span> by using original rows and columns from the original matrix, where:
<dl class="org-dl">
<dt>C</dt><dd>sample columns from the original matrix</dd>
<dt>R</dt><dd>sample rows from the original matrix</dd>
</dl></li>
</ul>
</div>
</div>

<div id="outline-container-org8b48ad5" class="outline-3">
<h3 id="org8b48ad5"><span class="section-number-3">12.11.</span> CUR Decomposition</h3>
<div class="outline-text-3" id="text-12-11">
<div class="BLOCKQUOTE" id="org64109b2">
<p>
CUR definition: Given input matrix \(A\), find columns \(C\), rows \(R\) and matrix \(U\) such that \(\parallel A - C U R\parallel\) is small.
</p>

</div>
<ul class="org-ul">
<li>Norm term indicates the errors when approximating matrix \(A\) using \(C U R\).</li>
<li>CUR approximates A ≈ CUR using actual rows and columns.</li>
<li>Comparison with SVD: CUR retains interpretability and sparsity.</li>
</ul>
</div>
</div>

<div id="outline-container-org8fd8514" class="outline-3">
<h3 id="org8fd8514"><span class="section-number-3">12.12.</span> CUR Algorithm</h3>
<div class="outline-text-3" id="text-12-12">
<ul class="org-ul">
<li>Algorithm steps:
<ol class="org-ol">
<li>Perform SVD. Find the top rank-k approximation after SVD.</li>
<li>Sample \(R\) rows and \(C\) columns based on vector norms.</li>
<li>Compute U as \(U = C^+ A R^+\) where \(+\) means pseudo-inverse operation, which can be computed using SVD, e.g. \(X^+ = V \Sigma^{-1} U^T\)</li>
</ol></li>
<li>Probability of sampling is based on row length of the \(U\) and \(V\) matrices. Bigger row length = more likelihood of sampling.</li>
</ul>
</div>
</div>

<div id="outline-container-orge79628e" class="outline-3">
<h3 id="orge79628e"><span class="section-number-3">12.13.</span> CUR Quiz Question</h3>
<div class="outline-text-3" id="text-12-13">
<ul class="org-ul">
<li>Question: what do C and R represent in CUR decomposition?</li>
</ul>
</div>
</div>

<div id="outline-container-org87ba193" class="outline-3">
<h3 id="org87ba193"><span class="section-number-3">12.14.</span> CUR Quiz Solution</h3>
<div class="outline-text-3" id="text-12-14">

<div id="org27605dc" class="figure">
<p><img src="./img/cur-quiz.png" alt="cur-quiz.png" />
</p>
</div>
<ul class="org-ul">
<li>Answer: C = actual diagnoses (columns), R = actual patients (rows).</li>
<li>Emphasizes CUR’s interpretability and sparsity preservation.</li>
</ul>
</div>
</div>

<div id="outline-container-org220d661" class="outline-3">
<h3 id="org220d661"><span class="section-number-3">12.15.</span> Tensor for EHR</h3>
<div class="outline-text-3" id="text-12-15">
<ul class="org-ul">
<li>Tensor = generalized matrix (e.g., 3D tensor: patient × diagnosis × medication).</li>
<li>Matrix = 2nd order tensor.</li>
<li>Tensors better capture multi-dimensional interactions in EHR data.</li>
</ul>
</div>
</div>

<div id="outline-container-org19c57d8" class="outline-3">
<h3 id="org19c57d8"><span class="section-number-3">12.16.</span> Tensor Slicing</h3>
<div class="outline-text-3" id="text-12-16">
<ul class="org-ul">
<li>Extract subtensors (matrices) by fixing all but two dimensions.</li>
<li>Examples:
<ul class="org-ul">
<li>Diagnosis-medication matrix for a patient.</li>
<li>Patients and diseases by medication.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org88ec6c4" class="outline-3">
<h3 id="org88ec6c4"><span class="section-number-3">12.17.</span> Rank 1 Tensor</h3>
<div class="outline-text-3" id="text-12-17">
<ul class="org-ul">
<li>Rank-1 tensor = outer product of vectors from each mode.</li>
<li>Element-wise: aᵢ * bⱼ * cₖ.</li>
</ul>

<p>
\[
x = a \circ b \circ c  \\
x_{ijk} = a_i \cdot b_j \cdot c_k
\]
</p>
</div>
</div>

<div id="outline-container-org5cd1ecc" class="outline-3">
<h3 id="org5cd1ecc"><span class="section-number-3">12.18.</span> Example Phenotype</h3>
<div class="outline-text-3" id="text-12-18">
<ul class="org-ul">
<li>Phenotypes modeled as rank-1 tensors.</li>
<li>Phenotype: a group of patients that share common characteristics e.g. diagnosis, medication</li>
<li>Example: hypertension phenotype with specific meds and patients.</li>
</ul>
</div>
</div>

<div id="outline-container-org1eb94e1" class="outline-3">
<h3 id="org1eb94e1"><span class="section-number-3">12.19.</span> Phenotyping Through Tensor Factorization</h3>
<div class="outline-text-3" id="text-12-19">
<ul class="org-ul">
<li>Extracting phenotypes through tensor factorization.</li>
<li>Tensor = sum of rank-1 tensors (each = phenotype).</li>
<li>Each component has patient, diagnosis, and medication factors.</li>
<li>Outer product = rank-1 approximation of input tensor, and we have R of those.</li>
<li>\(\lambda\) = importance of each phenotype.</li>
</ul>
</div>
</div>

<div id="outline-container-org1852059" class="outline-3">
<h3 id="org1852059"><span class="section-number-3">12.20.</span> CP Decomposition</h3>
<div class="outline-text-3" id="text-12-20">
<ul class="org-ul">
<li>CP: Canonical Decomposition and Parallel Factorization
= sum of R rank-1 tensors.</li>
<li>Each tensor has one λ and one vector per mode.</li>
<li>Output: three factor matrices and λ vector.</li>
<li>For phenotyping application, we use CP Decomposition with non-negativity constraints.</li>
<li>We can also treat CP Decomposition as black box, just like SVD and PCA.</li>
</ul>
</div>
</div>

<div id="outline-container-orge1c9473" class="outline-3">
<h3 id="orge1c9473"><span class="section-number-3">12.21.</span> Phenotyping Process Using Tensor Factorization</h3>
<div class="outline-text-3" id="text-12-21">
<ul class="org-ul">
<li>Process:
<ol class="org-ol">
<li><span style='background-color: #FFFF00;'>Factorize</span> training tensor to learn phenotype definitions</li>
<li><span style='background-color: #FFFF00;'>Project</span> new patients onto phenotype space</li>
</ol></li>
<li>Result: low-dimensional patient representation.</li>
</ul>
</div>
</div>

<div id="outline-container-orged1c1b5" class="outline-3">
<h3 id="orged1c1b5"><span class="section-number-3">12.22.</span> Phenotyping for Predictive Modeling</h3>
<div class="outline-text-3" id="text-12-22">
<ul class="org-ul">
<li>Build tensor from EHR events within an observation window (\(t_0\) to \(t_4\)).</li>
<li>Target = <span style='background-color: #FFFF00;'>predict heart failure</span>.</li>
<li>Tensor = patient × diagnosis × medication.</li>
<li>Process:
<ol class="org-ol">
<li>Find the index date and observation window</li>
<li>Aggregate diagnosis-medication pairs within observation window to populate tensor</li>
<li>Look back during observation window and count occurrences of the pairs</li>
<li>Go through all patients with these occurrences</li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-org86682ab" class="outline-3">
<h3 id="org86682ab"><span class="section-number-3">12.23.</span> Predictive Performance</h3>
<div class="outline-text-3" id="text-12-23">
<ul class="org-ul">
<li>Compared PCA, NMF, and Tensor Factorization.</li>
<li>All outperformed baseline with fewer features (phenotypes).</li>
<li>Tensor and NMF had better performance than PCA.</li>
</ul>
</div>
</div>

<div id="outline-container-orga16e176" class="outline-3">
<h3 id="orga16e176"><span class="section-number-3">12.24.</span> Major Disease Phenotypes</h3>
<div class="outline-text-3" id="text-12-24">
<ul class="org-ul">
<li>Tensor reveals intuitive disease phenotypes:
<ul class="org-ul">
<li>Uncomplicated diabetes (17.6%)</li>
<li>Mild hypertension (31.1%)</li>
</ul></li>
<li>Also identifies subtypes (e.g., mild/moderate/severe hypertension).</li>
</ul>
</div>
</div>

<div id="outline-container-orgbe80a0c" class="outline-3">
<h3 id="orgbe80a0c"><span class="section-number-3">12.25.</span> Tensor vs NMF</h3>
<div class="outline-text-3" id="text-12-25">
<ul class="org-ul">
<li>Tensor factorization offers more <span style='background-color: #FFFF00;'>concise</span> phenotypes.</li>
<li>NMF generates complex feature sets with many interactions (over 1000 combinations).</li>
</ul>
</div>
</div>

<div id="outline-container-org672b029" class="outline-3">
<h3 id="org672b029"><span class="section-number-3">12.26.</span> Summary: Phenotyping Via Tensor Factorization</h3>
<div class="outline-text-3" id="text-12-26">
<ul class="org-ul">
<li>Tensor factorization = <span style='background-color: #FFFF00;'>unsupervised</span> phenotyping.</li>
<li>Phenotypes help in prediction (e.g., heart failure).</li>
<li>Benefits: <span style='background-color: #FFFF00;'>no expert supervision</span> needed, compact representations, more predictive power than just using raw data.</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org78716c6" class="outline-2">
<h2 id="org78716c6"><span class="section-number-2">13.</span> Patient Similarity</h2>
<div class="outline-text-2" id="text-13">
</div>
<div id="outline-container-orgd86f2a8" class="outline-3">
<h3 id="orgd86f2a8"><span class="section-number-3">13.1.</span> Introduction to Patient Similarity</h3>
<div class="outline-text-3" id="text-13-1">
<ul class="org-ul">
<li>Patient similarity introduces a new paradigm in medical practice.</li>
<li>Enables identifying similar patients for specific clinical contexts.</li>
<li>Supports pragmatic trials and practice-based medicine.</li>
<li>A supervised distance metric learning algorithm is introduced.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd6c1de9" class="outline-3">
<h3 id="orgd6c1de9"><span class="section-number-3">13.2.</span> Motivation</h3>
<div class="outline-text-3" id="text-13-2">
<ul class="org-ul">
<li>Traditional medicine relies on randomized clinical trials (RCT) for evidence (evidence-based medicine).
<ul class="org-ul">
<li>Limitations: patient heterogeneity, outdated/inapplicable guidelines.</li>
</ul></li>
<li>Electronic health records (EHR) data enables a new paradigm: <span style='background-color: #FFFF00;'>precision medicine</span>.
<ul class="org-ul">
<li>Personalized care requires ability to measure patient similarity.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org72d3f32" class="outline-3">
<h3 id="org72d3f32"><span class="section-number-3">13.3.</span> Traditional Paradigm</h3>
<div class="outline-text-3" id="text-13-3">
<ul class="org-ul">
<li>Evidence-based medicine uses:
<ol class="org-ol">
<li>RCTs to test hypotheses.</li>
<li>Publications and drug approvals.</li>
<li>Expert-created clinical guidelines.</li>
<li>Guideline application in clinical practice.</li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-orgbe18684" class="outline-3">
<h3 id="orgbe18684"><span class="section-number-3">13.4.</span> New Paradigm</h3>
<div class="outline-text-3" id="text-13-4">
<ul class="org-ul">
<li>Precision medicine promotes personalized care through:
<ol class="org-ol">
<li><b><b>Pragmatic trials</b></b> using EHR data.</li>
<li><b><b>Patient similarity</b></b> searches to inform treatment.</li>
<li>Practice-based evidence derived from real-world data, with <b><b>individualized recommendation</b></b></li>
<li><b><b>Precision medicine</b></b></li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-org80cc48d" class="outline-3">
<h3 id="org80cc48d"><span class="section-number-3">13.5.</span> Randomized Clinical Trials</h3>
<div class="outline-text-3" id="text-13-5">
<ul class="org-ul">
<li>Involves <span style='background-color: #FFFF00;'>randomly assigning</span> patients to :
<ul class="org-ul">
<li>control or</li>
<li>treatment groups.</li>
</ul></li>
<li>Compares average outcomes to assess treatment effectiveness.</li>
<li>Considered successful if treatment group shows better outcomes, otherwise trial considered failure.</li>
</ul>
</div>
</div>

<div id="outline-container-org8a160df" class="outline-3">
<h3 id="org8a160df"><span class="section-number-3">13.6.</span> RCT Quiz Question</h3>
<div class="outline-text-3" id="text-13-6">
<ul class="org-ul">
<li>Asks about drawbacks of RCTs.</li>
</ul>
</div>
</div>


<div id="outline-container-org99cf62f" class="outline-3">
<h3 id="org99cf62f"><span class="section-number-3">13.7.</span> RCT Quiz Solution</h3>
<div class="outline-text-3" id="text-13-7">
<ul class="org-ul">
<li>RCT drawbacks:
<ul class="org-ul">
<li>Require <b><b>controlled environments</b></b> with selective populations.</li>
<li>Test only <b><b>one intervention</b></b> at a time.</li>
<li>Are <b><b>expensive</b></b> and time-consuming.</li>
</ul></li>

<li>Not RCT drawbacks:
<ul class="org-ul">
<li>Discover causal relationships (not a drawback).</li>
<li>RCT data is clean/pristine since they're collected specifically
for the trial, hence data is not dirty.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgfbb97bb" class="outline-3">
<h3 id="orgfbb97bb"><span class="section-number-3">13.8.</span> Pragmatic Trials</h3>
<div class="outline-text-3" id="text-13-8">
<ul class="org-ul">
<li>Measure real-world <b><b>treatment effectiveness</b></b> using EHR data, from routine clinical practice.</li>
<li>Use similarity searches to group patients by <b><b>treatment</b></b> and <b><b>outcomes</b></b>.</li>
<li>Aim to recommend <b><b>best-performing treatments</b></b> to current patients.</li>
<li>Reflect real-world <b><b>patient variations</b></b> and support individual care choices.</li>
</ul>
</div>
</div>

<div id="outline-container-orge6ee6cb" class="outline-3">
<h3 id="orge6ee6cb"><span class="section-number-3">13.9.</span> Pragmatic Trial Quiz Question</h3>
<div class="outline-text-3" id="text-13-9">
<ul class="org-ul">
<li>Questions benefits and limitations of pragmatic trials.</li>
</ul>
</div>
</div>

<div id="outline-container-org0d74639" class="outline-3">
<h3 id="org0d74639"><span class="section-number-3">13.10.</span> Pragmatic Trial Quiz Solution</h3>
<div class="outline-text-3" id="text-13-10">
<ul class="org-ul">
<li>Pragmatic trial benefits:
<ul class="org-ul">
<li>Operate in real-world settings.</li>
<li>Can automatically gather more data.</li>
<li>Deal with noisy data. <span style='background-color: #FFFF00;'>unsure why this is benefit</span></li>
</ul></li>
<li>Pragmatic trial - not benefits:
<ul class="org-ul">
<li>Can't test new drugs.</li>
<li>Expensive and time-consuming (vs. RCT).</li>
<li>Don't establish causality (no randomization).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgb05a532" class="outline-3">
<h3 id="orgb05a532"><span class="section-number-3">13.11.</span> Utilize Patient Similarity</h3>
<div class="outline-text-3" id="text-13-11">
<p>
How to utilize patient similarity today?
</p>
<ul class="org-ul">
<li>Practice-based medicine uses patient similarity to:
<ul class="org-ul">
<li>Generate hypotheses from retrospective evidence.</li>
<li>Confirm them through RCTs.</li>
<li>Update clinical guidelines.</li>
</ul></li>
<li>Decision process:
<ul class="org-ul">
<li>Apply guidelines if available.</li>
<li>Use similar patient data if guidelines aren't applicable.</li>
<li>Use professional judgment if similar data is lacking.</li>
</ul></li>
<li>Paradigms are complementary (evidence-based + practice-based).</li>
</ul>


<div id="org3bee6f4" class="figure">
<p><img src="./img/pt-sim-rct-prg.png" alt="pt-sim-rct-prg.png" />
</p>
</div>

<p>
Pragmatic trial (practice-based medicine) is green-dotted, everything else is evidence-based medicine/RCT reliant.
</p>
</div>
</div>

<div id="outline-container-org3415add" class="outline-3">
<h3 id="org3415add"><span class="section-number-3">13.12.</span> Patient Similarity Approaches</h3>
<div class="outline-text-3" id="text-13-12">
<ul class="org-ul">
<li>One way to solve patient similarity problem is to pose as  <b><b>distance metric learning</b></b> problem: supervised approach using feature vectors and labels.
<ul class="org-ul">
<li>Ground truth vector \(Y\)</li>
<li>Patient vector \(X\)</li>
</ul></li>
<li>Learn distance function \(d(x_1 x_2)\) to reflect distance between patients.</li>
<li>Graph-based methods use medical ontologies/disease networks to relate patients.
<ul class="org-ul">
<li>Given set of patients, figure out who is similar to whom.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org4b76115" class="outline-3">
<h3 id="org4b76115"><span class="section-number-3">13.13.</span> Patient Similarity Through LSML</h3>
<div class="outline-text-3" id="text-13-13">
<ul class="org-ul">
<li>LSML (Locally Supervised Metric Learning) intuition:
<ul class="org-ul">
<li>Learns a distance metric tailored to clinical context, e.g. heart failure management.</li>
<li>Given a new patient, use baseline similarity measure (e.g. euclidean distance or cosine similarity)to retrieve potential matches. This is supervised, with ground truth labels.</li>
<li>Refines metric to bring similar patients closer and dissimilar ones further.</li>
</ul></li>
<li>Objective: <span style='background-color: #FFFF00;'>maximize total margin</span> between homogeneous and heterogeneous neighbors, i.e.
\[
  max_(w: w\top w) = I^{\text{tr}(W^\top HW)} \\
  \text{and } H = L^e - L^0
  \]
where:
<dl class="org-dl">
<dt>\(L^e\)</dt><dd>heterogeneous neighbours (different)</dd>
<dt>\(L^0\)</dt><dd>homogeneous neighbours</dd>
</dl></li>
<li>Mathematical formulation:
<ul class="org-ul">
<li>Learn a low-rank symmetric matrix W (via Mahalanobis distance).</li>
<li>Maximize trace(WᵀHW) where H captures margin information.</li>
<li>Solved via <span style='background-color: #FFFF00;'>eigenvalue decomposition</span>.</li>
</ul></li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org6f02143" class="outline-2">
<h2 id="org6f02143"><span class="section-number-2">14.</span> Deep Neural Network</h2>
<div class="outline-text-2" id="text-14">
</div>
<div id="outline-container-org4e45514" class="outline-3">
<h3 id="org4e45514"><span class="section-number-3">14.1.</span> Backward Computation for a Neuron</h3>
<div class="outline-text-3" id="text-14-1">

<div id="org4cf8dd1" class="figure">
<p><img src="./img/backcomp.png" alt="backcomp.png" />
</p>
</div>
<ul class="org-ul">
<li>A neuron processes inputs \( x_1, x_2, \dots, x_n \) with corresponding weights and a bias term to output a value \( y \).</li>
<li>Computation involves:
<ul class="org-ul">
<li>Linear combination: \( z = \sum w_i x_i + b \)</li>
<li>Nonlinear activation: \( y = g(z) \)</li>
</ul></li>
<li>Output type:
<ul class="org-ul">
<li>Binary (for classification) or continuous (for regression)</li>
</ul></li>
<li>Learning involves:
<ol class="org-ol">
<li>Learning weights and bias from data</li>
</ol></li>
</ul>

<p>
after specifying the activation function \( g \)
</p>
</div>
</div>

<div id="outline-container-org037fb43" class="outline-3">
<h3 id="org037fb43"><span class="section-number-3">14.2.</span> Sigmoid Function</h3>
<div class="outline-text-3" id="text-14-2">

<div id="org2563c04" class="figure">
<p><img src="./img/sigmoid1.png" alt="sigmoid1.png" />
</p>
</div>
<ul class="org-ul">
<li>Nonlinear transformation specified by the modeler (<b><b>not learned</b></b> from data).</li>
<li>Popular activation functions: sigmoid, tanh, ReLU.</li>
<li>Sigmoid function: \( \sigma(x) = \frac{1}{1 + e^{-x}} \)</li>
<li>Output range: [0, 1]; interpretable as probability</li>
<li>Common for <span style='background-color: #FFFF00;'>classification</span> tasks</li>
<li>Problem: <b><b>vanishing gradients</b></b> when \( x \) is very small or very large</li>
</ul>
</div>
</div>

<div id="outline-container-org818dc43" class="outline-3">
<h3 id="org818dc43"><span class="section-number-3">14.3.</span> TANH Function</h3>
<div class="outline-text-3" id="text-14-3">

<div id="org1827308" class="figure">
<p><img src="./img/tanh1.png" alt="tanh1.png" />
</p>
</div>
<ul class="org-ul">
<li>Defined as: \( \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} = \frac{2}{1+e^{-2x}} - 1 \)</li>
<li>Output range: (–1, 1); centered at 0</li>
<li>Scaled and shifted version of Sigmoid</li>
<li>stronger gradient but still has vanishing gradient problem (when input is far from 0)</li>
</ul>
</div>
</div>

<div id="outline-container-org2a27c93" class="outline-3">
<h3 id="org2a27c93"><span class="section-number-3">14.4.</span> Rectified Linear Function</h3>
<div class="outline-text-3" id="text-14-4">

<div id="org5d0433b" class="figure">
<p><img src="./img/relu1.png" alt="relu1.png" />
</p>
</div>
<ul class="org-ul">
<li>ReLU: \( \max(0, x) \)</li>
<li>Output: [0, ∞); linear for \( x > 0 \), 0 otherwise
<ul class="org-ul">
<li>Linearly increasing curve when \(x > 0\)</li>
</ul></li>
<li><span style='background-color: #FFFF00;'>Does not suffer</span> from vanishing gradient (gradient = 1 for \( x > 0 \))</li>
<li>Half rectified: activation threshold at \(0\)</li>
<li>Not bounded (for \(x>0\))</li>
</ul>
</div>
</div>

<div id="outline-container-org4eba856" class="outline-3">
<h3 id="org4eba856"><span class="section-number-3">14.5.</span> Activation Functions: Summary</h3>
<div class="outline-text-3" id="text-14-5">

<div id="orgeb3084d" class="figure">
<p><img src="./img/comp-activation.png" alt="comp-activation.png" />
</p>
</div>
<ul class="org-ul">
<li>Sigmoid and tanh are bounded; ReLU is unbounded above \(x>0\).</li>
<li>Choice of activation function is <span style='background-color: #FFFF00;'>application dependent</span>.</li>
</ul>
</div>
</div>

<div id="outline-container-org1af73d6" class="outline-3">
<h3 id="org1af73d6"><span class="section-number-3">14.6.</span> Train a Single Neuron</h3>
<div class="outline-text-3" id="text-14-6">

<div id="org94337b9" class="figure">
<p><img src="./img/train-single.png" alt="train-single.png" />
</p>
</div>
<ul class="org-ul">
<li>Goal: Learn <span style='background-color: #FFFF00;'>weights and bias</span> to <span style='background-color: #FFFF00;'>minimize loss</span>
<ul class="org-ul">
<li>Linear combination computes weighted \(\sum^n_{i=1} x_i = Z\)</li>
</ul></li>
<li><span style='background-color: #FFFF00;'>Loss function</span> measures difference between prediction \( y \) and target \( t \)
<ul class="org-ul">
<li>Example: squared Euclidean loss</li>
</ul></li>
<li>Training = minimizing loss via optimization.
<ul class="org-ul">
<li>Adjust the weights of the network to move its output in the direction that minimizes the loss on training data.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgb7c5c3c" class="outline-3">
<h3 id="orgb7c5c3c"><span class="section-number-3">14.7.</span> Stochastic Gradient Descent (SGD)</h3>
<div class="outline-text-3" id="text-14-7">
<ul class="org-ul">
<li>Inputs:
<ol class="org-ol">
<li>training data \((x, t)\)</li>
<li>learning rate hyperparameter \(\eta\)</li>
</ol></li>

<li>Efficient method to train neurons</li>
<li>Procedure:
<ol class="org-ol">
<li>Initialize each weight \(w_i\) and bias \(b\) <span style='background-color: #FFFF00;'>randomly</span></li>
<li>For each example, until convergence:
<ul class="org-ul">
<li>Compute gradient of loss w.r.t. weights and bias</li>
<li>Update parameters weight vector and bias in the opposite direction of the gradient.</li>
<li>\(\eta\) can be set statically or updated dynamically.</li>
</ul></li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-orga61c776" class="outline-3">
<h3 id="orga61c776"><span class="section-number-3">14.8.</span> Forward Computation for a Neuron</h3>
<div class="outline-text-3" id="text-14-8">
<ul class="org-ul">
<li>Two-pass process:
<ol class="org-ol">
<li>forward to compute \( y \) and loss \(L = \frac{1}{2} \parallel y-t \parallel^2\)</li>
<li>backward for gradients</li>
</ol></li>
<li>Derivatives:
<ul class="org-ul">
<li>\( \frac{\partial z}{\partial w_i} = x_i \)</li>
<li>\( \frac{\partial y}{\partial z} = y(1 - y) \) (for sigmoid)</li>
</ul></li>
<li>Software often automates this process</li>
</ul>
</div>
</div>

<div id="outline-container-orge50fd23" class="outline-3">
<h3 id="orge50fd23"><span class="section-number-3">14.9.</span> Backward Computation for a Neuron</h3>
<div class="outline-text-3" id="text-14-9">
<ul class="org-ul">
<li>Find the derivatives of \(y\) and \(L\)</li>
<li>Use <b><b>chain rule</b></b> to compute gradients from output to input:
<ul class="org-ul">
<li>\( \frac{\partial L}{\partial w_i} = (y - t) \cdot y(1 - y) \cdot x_i \)</li>
<li>\( \frac{\partial L}{\partial b} = (y - t) \cdot y(1 - y) \)
<ul class="org-ul">
<li>\(\frac{\partial z}{\partial b}\) is constant and evaluates to 1 upon derivation.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org5a0f70b" class="outline-3">
<h3 id="org5a0f70b"><span class="section-number-3">14.10.</span> Multilayer Neural Network</h3>
<div class="outline-text-3" id="text-14-10">

<div id="orgc7143c4" class="figure">
<p><img src="./img/mlp.png" alt="mlp.png" />
</p>
</div>
<ul class="org-ul">
<li>Terms and definitions
<ol class="org-ol">
<li>Layer 1 is input,</li>
<li>hidden are layer 2,</li>
<li>Output layer (after activation) is layer 3</li>
</ol></li>
<li>\(w_{12}^{(3)}\):
<ol class="org-ol">
<li>output</li>
<li>input</li>
<li>layer number (coming from)</li>
</ol></li>

<li>Network Structure
<ul class="org-ul">
<li><b><b>Input Layer (Layer 1)</b></b>
<ul class="org-ul">
<li>Three input units: X₁, X₂, X₃</li>
<li>Includes a bias unit</li>
</ul></li>

<li><b><b>Hidden Layer (Layer 2)</b></b>
<ul class="org-ul">
<li>Three hidden units: H₁, H₂, H₃</li>
<li>Includes a bias unit</li>
<li>Called "hidden" because its <span style='background-color: #FFFF00;'>values are not observed</span> in the training data</li>
</ul></li>

<li><b><b>Output Layer (Layer 3)</b></b>
<ul class="org-ul">
<li>One output unit: \(y\) or \(a^{(3)}\)</li>
</ul></li>
</ul></li>

<li>Notation Importance</li>
<li>Subscripts and superscripts may seem messy but are crucial for clarity</li>
<li>Especially important for deeper neural networks</li>
</ul>
</div>
</div>
<div id="outline-container-orgbe6c77d" class="outline-3">
<h3 id="orgbe6c77d"><span class="section-number-3">14.11.</span> Train a Multilayer Neural Network</h3>
<div class="outline-text-3" id="text-14-11">
<ul class="org-ul">
<li>Similar process as single neuron</li>
<li>SGD updates weights and biases for each layer</li>
<li>Challenge: <span style='background-color: #FFFF00;'>computing gradients</span> for all layers</li>
</ul>
</div>
</div>

<div id="outline-container-orgc85fe6a" class="outline-3">
<h3 id="orgc85fe6a"><span class="section-number-3">14.12.</span> Forward Computation Part 1</h3>
<div class="outline-text-3" id="text-14-12">
<ul class="org-ul">
<li>Step-by-step example with 3 hidden units (h1, h2, h3) and 1 output</li>
<li>Each unit computes:
<ul class="org-ul">
<li>Linear combination: \( z \), e.g. \(z_1^{(2)} = \sum w_{1i}^{(1)} + b_1^{(1)}\)</li>
<li>Activation: \( a = g(z) \), e.g. \(a_1^{(2)} = g^{(2)} (z_i^{(2)})\)</li>
</ul></li>
<li>Final output is computed from hidden layer outputs</li>
</ul>
</div>
</div>

<div id="outline-container-org97ec294" class="outline-3">
<h3 id="org97ec294"><span class="section-number-3">14.13.</span> Forward Computation Part 2</h3>
<div class="outline-text-3" id="text-14-13">
<ul class="org-ul">
<li>Summary of previous computation</li>
<li>Network is fully connected (all layers are connected thru the neural network)</li>
<li>Shows the symmetry and modularity of neural networks</li>
</ul>
</div>
</div>

<div id="outline-container-org7218c07" class="outline-3">
<h3 id="org7218c07"><span class="section-number-3">14.14.</span> Forward Computation: Vector Form</h3>
<div class="outline-text-3" id="text-14-14">

<div id="org36a6111" class="figure">
<p><img src="./img/fc-vector-form.png" alt="fc-vector-form.png" />
</p>
</div>
<ul class="org-ul">
<li>Computation represented in vector/matrix form:
<ul class="org-ul">
<li>\( z = Wx + b \)</li>
<li>\( a = g(z) \)</li>
</ul></li>
<li>Activation applied element-wise to vectors</li>
</ul>
</div>
</div>

<div id="outline-container-org6c7ab6c" class="outline-3">
<h3 id="org6c7ab6c"><span class="section-number-3">14.15.</span> Forward Computation: More General Form</h3>
<div class="outline-text-3" id="text-14-15">
<ul class="org-ul">
<li>General forward pass for layer \( l \rightarrow l+1 \):
<ul class="org-ul">
<li>\( z^{(l+1)} = W^{(l)}a^{(l)} + b^{(l)} \)</li>
<li>\( a^{(l+1)} = g(z^{(l+1)}) \)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org8b63690" class="outline-3">
<h3 id="org8b63690"><span class="section-number-3">14.16.</span> Forward Computation: Summary</h3>
<div class="outline-text-3" id="text-14-16">
<ul class="org-ul">
<li>Computation can be expressed:
<ul class="org-ul">
<li>Unit-by-unit</li>
<li>Vectorized (preferred for efficiency)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orga4baea8" class="outline-3">
<h3 id="orga4baea8"><span class="section-number-3">14.17.</span> Gradient Descent for Neural Networks</h3>
<div class="outline-text-3" id="text-14-17">
<ul class="org-ul">
<li>Recap:
<ul class="org-ul">
<li>Initialize weights/biases</li>
<li>Compute gradients
<ul class="org-ul">
<li>Efficiently computing the gradients is the <span style='background-color: #FFFF00;'>key</span></li>
</ul></li>
<li>Apply updates</li>
</ul></li>
<li>Efficient gradient computation is critical → leads to backpropagation</li>
</ul>
</div>
</div>

<div id="outline-container-orgfa5b1a8" class="outline-3">
<h3 id="orgfa5b1a8"><span class="section-number-3">14.18.</span> Backward Propagation Part 1</h3>
<div class="outline-text-3" id="text-14-18">
<p>
\[
\frac{\partial L(W,b)}{ \partial w_{jl}^{(l)}}
\]
</p>
<ul class="org-ul">
<li>Gradient of loss w.r.t. \( w_{ji}^{(l)} \) is:
<ul class="org-ul">
<li>\( \delta_j^{(l)} \cdot a_i^{(l-1)} \)</li>
</ul></li>
<li>\( \delta_j^{(l)} \): error signal for unit j at layer \(l\)
<ul class="org-ul">
<li>\(=\frac{\partial L}{\partial z_j^{(l)}}\)</li>
<li>Measures how much of the node \(h_j\) of \(l\) -th layer was responsible for the final error</li>
</ul></li>
<li>Chain rule used to derive this</li>
</ul>
</div>
</div>

<div id="outline-container-org71f64e0" class="outline-3">
<h3 id="org71f64e0"><span class="section-number-3">14.19.</span> Backward Propagation Part 2</h3>
<div class="outline-text-3" id="text-14-19">
<ul class="org-ul">
<li>Gradient w.r.t. bias \( b_j^{(l)} = \delta_j^{(l)} \)</li>
<li>Bias derivatives are simpler (derivative of z w.r.t. bias = 1)</li>
</ul>
</div>
</div>

<div id="outline-container-org9d5636f" class="outline-3">
<h3 id="org9d5636f"><span class="section-number-3">14.20.</span> Backward Propagation Part 3</h3>
<div class="outline-text-3" id="text-14-20">
<ul class="org-ul">
<li>Need to compute all \( \delta_j^{(l)} \) efficiently</li>
<li>Done in backward pass from output to input layer</li>
<li>To compute the partial derivatives, we need all
\(\partial j^{(l)}\) which can be
computed from OUTPUT to INPUT layer in a backward fashion</li>
</ul>
</div>
</div>

<div id="outline-container-orgf62a5b9" class="outline-3">
<h3 id="orgf62a5b9"><span class="section-number-3">14.21.</span> Backward Propagation Part 4</h3>
<div class="outline-text-3" id="text-14-21">
<ul class="org-ul">
<li>Compute final layer delta:
<ul class="org-ul">
<li>\( \delta_k^{(L)} = \frac{\partial L}{\partial z_k^{(L)}} = y - t \)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org8dbb45d" class="outline-3">
<h3 id="org8dbb45d"><span class="section-number-3">14.22.</span> Backward Propagation Part 5</h3>
<div class="outline-text-3" id="text-14-22">
<ul class="org-ul">
<li>Compute delta for previous layer, 3:
<ul class="org-ul">
<li>Chain rule involving gradient of activation and next layer delta</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org4173b41" class="outline-3">
<h3 id="org4173b41"><span class="section-number-3">14.23.</span> Backward Propagation Part 6</h3>
<div class="outline-text-3" id="text-14-23">
<ul class="org-ul">
<li>For hidden layers:
<ul class="org-ul">
<li>Delta includes:
<ul class="org-ul">
<li>Sum over deltas from next layer</li>
<li>Corresponding weights</li>
<li>Derivative of activation at current layer</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org75cd254" class="outline-3">
<h3 id="org75cd254"><span class="section-number-3">14.24.</span> Backward Propagation Summary&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-14-24">
<ul class="org-ul">
<li>General form of delta:
\[
  \delta_j^{(l)} = \left[ \sum_{k=1}^{n} w_{kj}^{(l)} \delta_k^{(l+1)} \right] \cdot \left(g^{(l)}\right)'\left(z_j^{(l)}\right)
  \]</li>
<li>Backpropagation allows computing all gradients in <span style='background-color: #FFFF00;'>one pass</span></li>
</ul>
</div>
</div>
</div>


<div id="outline-container-orga1b1eaa" class="outline-2">
<h2 id="orga1b1eaa"><span class="section-number-2">15.</span> Convolutional Neural Network&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h2>
<div class="outline-text-2" id="text-15">
</div>
<div id="outline-container-org0eb6b42" class="outline-3">
<h3 id="org0eb6b42"><span class="section-number-3">15.1.</span> Convolution Local Networks</h3>
<div class="outline-text-3" id="text-15-1">
<ul class="org-ul">
<li>Feedforward networks in <a href="#org6f02143">previous chapter</a> connect <b><b>all</b></b> units between layers, causing high parameter counts for high-dimensional data.</li>
<li>Local connectivity can reduce parameters by limiting neuron connections to <span style='background-color: #FFFF00;'>adjacent units</span>.</li>
<li><span style='background-color: #FFFF00;'>Convolutional Neural Networks (CNNs)</span> utilize this local connectivity across layers.</li>
<li><b><b>Weight sharing</b></b>:
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Reuses the same parameters</span> across locations, further reducing total parameters.</li>
<li>Inspired by convolution in signal processing.</li>
<li>Can be considered as applying a <span style='background-color: #FFFF00;'>filter</span> or <span style='background-color: #FFFF00;'>kernel</span> to the input data</li>
<li>Example: Sharing weights reduces 6 parameters to 3 for two hidden units.</li>
</ul></li>
</ul>

<div id="org128e3f4" class="figure">
<p><img src="./img/local-wt-share.png" alt="local-wt-share.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org5743d1e" class="outline-3">
<h3 id="org5743d1e"><span class="section-number-3">15.2.</span> Pooling Handling Distortion</h3>
<div class="outline-text-3" id="text-15-2">
<ul class="org-ul">
<li>Pooling layers add <span style='background-color: #FFFF00;'>translational invariance</span>, crucial for images and time series.</li>
<li><span style='background-color: #FFFF00;'>Max pooling</span> extracts maximum values, aiding stability under input shifts.</li>
<li>Example: Two shifted inputs can yield the same output after convolution + pooling.</li>
<li>This robustness is desirable for real-world applications where input variance is common.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb6dae34" class="outline-3">
<h3 id="orgb6dae34"><span class="section-number-3">15.3.</span> Convolutional Neural Networks</h3>
<div class="outline-text-3" id="text-15-3">
<ul class="org-ul">
<li>CNNs are effective for <span style='background-color: #FFFF00;'>grid</span>-like data (e.g., images and waveforms).</li>
<li>Advantages:
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Sparse</span> interconnections.</li>
<li><span style='background-color: #FFFF00;'>Parameter sharing</span>.</li>
<li>Supports translational invariance.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org8d5479e" class="outline-3">
<h3 id="org8d5479e"><span class="section-number-3">15.4.</span> Key Stages of CNN</h3>
<div class="outline-text-3" id="text-15-4">
<ul class="org-ul">
<li>A typical CNN architecture consists of:
<ul class="org-ul">
<li>Convolution layers</li>
<li>Pooling layers</li>
<li>Fully connected layers to generate final output</li>
</ul></li>
<li>Example architecture:
<ul class="org-ul">
<li>Conv → Max Pool → Conv → Max Pool → 3×Conv → Pool → 3×Fully Connected</li>
</ul></li>
<li>More detail on design choices to follow.</li>
</ul>


<div id="org043e63a" class="figure">
<p><img src="./img/exp-cnn.png" alt="exp-cnn.png" />
</p>
<p><span class="figure-number">Figure 1: </span>Example CNN architecture</p>
</div>
</div>
</div>

<div id="outline-container-org6ce2e9c" class="outline-3">
<h3 id="org6ce2e9c"><span class="section-number-3">15.5.</span> 1-D Convolution</h3>
<div class="outline-text-3" id="text-15-5">
<ul class="org-ul">
<li>Illustrates convolution with 1D input: \([1, 2, -1, 1, -3]\) and kernel \([1, 0, -1]\) (i.e., filter).</li>
<li>Output computed via inner product of sliding window (the filter) and the input sequence.</li>
<li>Padding used at edges (zer o-padding).
<ul class="org-ul">
<li>Expressed as functions:
<dl class="org-dl">
<dt>input sequence</dt><dd>\(f[t]\)</dd>
<dt>filter</dt><dd>\(g(t)\)</dd>
<dt>output</dt><dd>\((f * g) (t)\)</dd>
</dl></li>
</ul></li>
<li><p>
The sliding window operation is the convolution operation.
</p>

<div id="orgf81e4da" class="figure">
<p><img src="./img/1d-conv.png" alt="1d-conv.png" />
</p>
<p><span class="figure-number">Figure 2: </span>1-D Convolution examples</p>
</div></li>
<li>Introduces concept of <b><b>stride</b></b> (spacing between when the kernel is applied).</li>
<li>Computationally intensive but highly parallelizable on GPUs.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd2c8d63" class="outline-3">
<h3 id="orgd2c8d63"><span class="section-number-3">15.6.</span> Neural Network for 1-D Convolution</h3>
<div class="outline-text-3" id="text-15-6">
<ul class="org-ul">
<li>Convolution operation visualized as a neural network:
<ul class="org-ul">
<li>Applies shared weights across sliding input windows.</li>
<li>Two outputs H1 and H2 for two positions of the kernel.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org7544831" class="outline-3">
<h3 id="org7544831"><span class="section-number-3">15.7.</span> 2-D Convolution Operation</h3>
<div class="outline-text-3" id="text-15-7">
<ul class="org-ul">
<li>Generalization of 1D convolution to 2D:
<ul class="org-ul">
<li>Inputs and outputs are two-dimensional matrices.</li>
<li>The output is called a <b>feature map</b>.</li>
</ul></li>
</ul>


<div id="org8259248" class="figure">
<p><img src="./img/2d-conv.png" alt="2d-conv.png" />
</p>
<p><span class="figure-number">Figure 3: </span>2-D Convolution examples</p>
</div>

<ul class="org-ul">
<li>Filter (or kernel) details:
<ul class="org-ul">
<li>Weight matrix (filter) is generally a  \(k \times k\) matrix.</li>
<li>This filter slides over the input matrix.</li>
<li>At each position, perform element-wise multiplication between the filter and the corresponding input patch.</li>
<li>Sum the result to produce one element in the output feature map.</li>
</ul></li>
<li>Multi-channel input:
<ul class="org-ul">
<li>Example: Color images with RGB channels → 3 input channels.</li>
<li>In the explained case: 2-channel input
<ul class="org-ul">
<li>Input matrices: \(I(:,:,1)\), \(I(:,:,2)\)</li>
<li>Corresponding filters: \(K(:,:,1)\), \(K(:,:,2)\)</li>
</ul></li>
</ul></li>

<li>Convolution in multi-channel input:
<ul class="org-ul">
<li>Each filter is applied to its corresponding input channel.</li>
<li>Element-wise multiplication is performed per channel.</li>
<li>Results from all channels are <span style='background-color: #FFFF00;'>summed</span> to get a single output value at a location in the output feature map.</li>
</ul></li>

<li>Important points:
<ul class="org-ul">
<li>Despite multi-channel input and multiple filters, output is still a <b><b>single matrix</b></b>.</li>
<li>Formula for computing output is similar to single-channel convolution:
<ul class="org-ul">
<li>Adds an outer summation to account for all channels.</li>
<li>Essentially, a triple loop: over output dimensions and input channels.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org8ed8d24" class="outline-3">
<h3 id="org8ed8d24"><span class="section-number-3">15.8.</span> Convolution Layers</h3>
<div class="outline-text-3" id="text-15-8">
<ul class="org-ul">
<li>After convolution, <b><b>nonlinear activations</b></b> (e.g., ReLU) are applied.</li>
<li>Multiple filters (kernels) are often used to capture different patterns.</li>
<li>Output becomes a 3D tensor: height × width × number of filters.</li>
<li>Filters may extract features like average values or edges.</li>
</ul>
</div>
</div>

<div id="outline-container-orgcb0836a" class="outline-3">
<h3 id="orgcb0836a"><span class="section-number-3">15.9.</span> Pooling Layers&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-15-9">
<ul class="org-ul">
<li>Pooling reduces spatial size of feature maps, e.g. a smart downsample.</li>
<li>Types: Max pooling (most common), average pooling, sum pooling.</li>
<li>Example: 2×2 max pooling reduces 4D input to 2D output by taking max in each region.</li>
<li><span style='background-color: #FFFF00;'>Max pooling</span> works well and is most popular.</li>
</ul>
</div>
</div>

<div id="outline-container-org19252e1" class="outline-3">
<h3 id="org19252e1"><span class="section-number-3">15.10.</span> Dimension Calculation of Convolution Layers&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-15-10">
<ul class="org-ul">
<li>Hyperparameters
<dl class="org-dl">
<dt>K</dt><dd>number of filters</dd>
<dt>F</dt><dd>spatial extent</dd>
<dt>S</dt><dd>stride</dd>
<dt>P</dt><dd>number of paddings</dd>
</dl></li>
<li>Input: \(W_1 × H_1 × D_1\)</li>
<li>Output: \(W_2 × H_2 × D_2\)
<ul class="org-ul">
<li>\(W_2 = (W_1 - F + 2P) / S + 1\)</li>
<li>\(H_2 = (W_1 - F + 2P) / S + 1\)</li>
<li>\(D_2 = K\) (number of filters)</li>
</ul></li>
<li>Illustrated with example: input \(227×227×3\), filter size \(11×11\), stride \(4\), output \(55×55×96\).</li>
</ul>
</div>
</div>

<div id="outline-container-org58ceded" class="outline-3">
<h3 id="org58ceded"><span class="section-number-3">15.11.</span> Dimension Calculation of Pooling Layer</h3>
<div class="outline-text-3" id="text-15-11">
<ul class="org-ul">
<li>Similar to convolution but <span style='background-color: #FFFF00;'>without padding</span>.</li>
<li>Hyperparameters:
<dl class="org-dl">
<dt>F</dt><dd>spatial extent</dd>
<dt>S</dt><dd>stride</dd>
</dl></li>
<li>Output size:
<ul class="org-ul">
<li>\(W_2 = (W_1 - F) / S + 1\)</li>
<li>\(H_2 = (H_1 - F) / S + 1\)</li>
<li>\(D_2 = D_1\) (depth remains the same)</li>
</ul></li>
<li>Example: pooling \(3×3\) on input \(55×55×96\) with stride 2 → output \(27×27×96\).</li>
</ul>
</div>
</div>

<div id="outline-container-orgb512387" class="outline-3">
<h3 id="orgb512387"><span class="section-number-3">15.12.</span> Parameter Count</h3>
<div class="outline-text-3" id="text-15-12">

<div id="org615fe15" class="figure">
<p><img src="./img/param-count.png" alt="param-count.png" />
</p>
<p><span class="figure-number">Figure 4: </span>Parameter count</p>
</div>
<ul class="org-ul">
<li><span style='background-color: #FFFF00;'>Convolution layers</span> often dominate the depth but not the parameter count.</li>
<li><span style='background-color: #FFFF00;'>Fully connected layers</span> still have the most parameters.</li>
<li>Example:
<ul class="org-ul">
<li>Conv layers: 3.7M parameters.</li>
<li>Final 3 FC layers: 58.6M parameters.</li>
</ul></li>
<li>Highlights <span style='background-color: #FFFF00;'>computational efficiency</span> of convolution layers.</li>
</ul>
</div>
</div>

<div id="outline-container-org859e4e8" class="outline-3">
<h3 id="org859e4e8"><span class="section-number-3">15.13.</span> Forward Calculation of Convolution</h3>
<div class="outline-text-3" id="text-15-13">
<ul class="org-ul">
<li>Number of computations = output size × filter size.</li>
<li>Formula: \(W2 × H2 × D2 × F × F × D1\)</li>
<li>Necessary to estimate computational cost.</li>
</ul>
</div>
</div>

<div id="outline-container-org4ac5ee0" class="outline-3">
<h3 id="org4ac5ee0"><span class="section-number-3">15.14.</span> Forward Calculation of Pooling Layers</h3>
<div class="outline-text-3" id="text-15-14">
<ul class="org-ul">
<li>Follows similar computation logic as convolution.</li>
<li>Number of operations = output size + filter size.</li>
</ul>
</div>
</div>

<div id="outline-container-orge8985bc" class="outline-3">
<h3 id="orge8985bc"><span class="section-number-3">15.15.</span> Forward Calculation of Fully-Connected Layers</h3>
<div class="outline-text-3" id="text-15-15">
<ul class="org-ul">
<li>Computation = input size × output size.</li>
<li>Converts 3D input tensor to a vector before FC layer.</li>
</ul>
</div>
</div>

<div id="outline-container-org040c9b7" class="outline-3">
<h3 id="org040c9b7"><span class="section-number-3">15.16.</span> Operation Count</h3>
<div class="outline-text-3" id="text-15-16">
<ul class="org-ul">
<li>Calculation comparison across different layers:
<ul class="org-ul">
<li>Total operations in convolution and pooling layers: 1.08 billion</li>
<li>Total operations in fully connected (FC) layer: 56.6 million</li>
</ul></li>

<li>Insight:
<ul class="org-ul">
<li><b><b>Convolution and pooling layers</b></b> dominate in <b><b>computational cost</b></b>.</li>
<li><b><b>Fully connected layers</b></b> contain most of the <b><b>parameters</b></b>, despite having fewer operations.</li>
</ul></li>

<li>Summary:
<ul class="org-ul">
<li>In Convolutional Neural Networks (CNNs):
<ul class="org-ul">
<li><b><b>Most calculations</b></b> occur in the convolutional layers.</li>
<li><b><b>Most parameters</b></b> reside in the fully connected layers.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgedcf3c5" class="outline-3">
<h3 id="orgedcf3c5"><span class="section-number-3">15.17.</span> CNN Architectures and Healthcare Applications</h3>
<div class="outline-text-3" id="text-15-17">
<ul class="org-ul">
<li>Discusses famous CNNs:
<ul class="org-ul">
<li>AlexNet: Large improvement in image classification (2012).</li>
<li>Inception: Deeper with parallel paths.</li>
<li>ResNet: Introduced skip connections, mitigates vanishing gradients.</li>
</ul></li>
<li>Performance on ImageNet:
<ul class="org-ul">
<li>ResNet achieves &lt;4% error, near human-level.</li>
</ul></li>
<li>Important design traits:
<ul class="org-ul">
<li>Deeper networks.</li>
<li>Parallel paths and residual learning.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org42fa350" class="outline-3">
<h3 id="org42fa350"><span class="section-number-3">15.18.</span> Diabetic Retinopathy Diagnosis</h3>
<div class="outline-text-3" id="text-15-18">
<ul class="org-ul">
<li>CNNs applied to eye images for diabetic retinopathy detection.</li>
<li>Published in JAMA.</li>
<li>Achieved performance on par with domain experts.</li>
<li>ROC curve shows CNNs matching or exceeding doctors.</li>
</ul>
</div>
</div>

<div id="outline-container-orgf632e13" class="outline-3">
<h3 id="orgf632e13"><span class="section-number-3">15.19.</span> Dermatologist Classification of Skin Cancer with DNN</h3>
<div class="outline-text-3" id="text-15-19">
<ul class="org-ul">
<li>CNNs used to classify skin lesions (benign vs. malignant).</li>
<li>Published in Nature.</li>
<li>CNN performance comparable or superior to dermatologists.</li>
<li>Visualization: algorithm ROC curve often exceeds human expert dots.</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org1821b7a" class="outline-2">
<h2 id="org1821b7a"><span class="section-number-2">16.</span> Recurrent Neural Network</h2>
<div class="outline-text-2" id="text-16">
</div>
<div id="outline-container-org049eb0a" class="outline-3">
<h3 id="org049eb0a"><span class="section-number-3">16.1.</span> Basic Concepts of RNN</h3>
<div class="outline-text-3" id="text-16-1">

<div id="orgdb713f9" class="figure">
<p><img src="./img/rnn-vs-f-nn.png" alt="rnn-vs-f-nn.png" />
</p>
<p><span class="figure-number">Figure 5: </span>RNN vs feedforward NN</p>
</div>
<ul class="org-ul">
<li>Feedforward neural networks (FFNN):
<ul class="org-ul">
<li>Map input vector X → hidden state H → output Ŷ.</li>
<li>X can be a multi-hot vector of patient diseases.</li>
<li>H represents patient embedding; Ŷ is prediction (e.g. heart failure).</li>
</ul></li>
<li>Recurrent Neural Networks (RNN):
<ul class="org-ul">
<li>Similar structure to FFNN, with key difference: recursion in hidden state.</li>
<li>Hidden state H = function of input X and previous hidden state H.</li>
<li>Components:
<ul class="org-ul">
<li>U: weights from input to hidden</li>
<li>W: weights from previous hidden to current hidden</li>
<li>V: weights from hidden to output</li>
<li>f, g: activation functions</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org93d7c50" class="outline-3">
<h3 id="org93d7c50"><span class="section-number-3">16.2.</span> Basic RNN Structure&#xa0;&#xa0;&#xa0;<span class="tag"><span class="exam">exam</span></span></h3>
<div class="outline-text-3" id="text-16-2">
<ul class="org-ul">
<li>Unfolding RNN over time steps (t-1, t, t+1).</li>
<li>Each time step:
<ul class="org-ul">
<li>Input: Xₜ</li>
<li>Hidden state: \(h^{(t)} = f(Ux^{(t)}+ Wh^{(t-1)} + b_1)\)</li>
<li>"Pre activation" \(o^{(t)} = Vh^{(t)} + b_2\)</li>
<li>Output: \(\widehat{y}^{(t)} = g(o^{(t)})\)</li>
</ul></li>
<li>Parameters (U, W, V) shared across time steps.</li>
<li>Common RNN architectures:
<dl class="org-dl">
<dt>One-to-many</dt><dd>e.g., image to text (image captioning)</dd>
<dt>Many-to-one</dt><dd>e.g., sequential disease classification from clinical notes.</dd>
<dt>Many-to-many (seq-to-seq)</dt><dd>e.g., machine translation.</dd>
<dt>Many-to-many (time-aligned)</dt><dd>e.g., sequential disease prediction.</dd>
</dl></li>
</ul>


<div id="orgde85652" class="figure">
<p><img src="./img/rnn-structures.png" alt="rnn-structures.png" />
</p>
<p><span class="figure-number">Figure 6: </span>RNN structures</p>
</div>
</div>
</div>

<div id="outline-container-orga27b989" class="outline-3">
<h3 id="orga27b989"><span class="section-number-3">16.3.</span> Forward Computation</h3>
<div class="outline-text-3" id="text-16-3">
<p>
Backprogation through time (BPTT) algorithm
</p>
<ul class="org-ul">
<li>Forward pass in training:
<ol class="org-ol">
<li>Compute \(z^{(t)} = Ux^{(t)} + Wh^{(t-1)} + b_1\)</li>
<li>\(h^{(t)} = f(z^{(t)})\)</li>
<li>\(o^{(t)} = Vh^{(t)} + b_2\)</li>
<li>\(\widehat{y}^{(t)} = g(o^{(t)})\)</li>
</ol></li>
<li>Loss function:
<ul class="org-ul">
<li>Negative log likelihood (NLL) for sequence output.</li>
<li>f: e.g., tanh; g: e.g., softmax.</li>
<li>Total loss = sum over time steps.</li>
<li>For binary classification, simplified loss form shown.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org6dc96d1" class="outline-3">
<h3 id="org6dc96d1"><span class="section-number-3">16.4.</span> Backpropagation Through Time</h3>
<div class="outline-text-3" id="text-16-4">
<ul class="org-ul">
<li>Backward pass (BPTT):
<ul class="org-ul">
<li>Compute ∂L/∂oₜ, then ∂L/∂Hₜ.</li>
<li>Last time step: ∂L/∂Hₜ = Vᵀ ∂L/∂oₜ</li>
<li>Earlier steps: ∂L/∂Hₜ includes gradient through both oₜ and Hₜ₊₁.</li>
</ul></li>
<li>Parameter updates:
<ul class="org-ul">
<li>Gradients used to update U, W, V, b₁, b₂.</li>
</ul></li>
<li>Practical note:
<ul class="org-ul">
<li>Most modern libraries automate this.</li>
</ul></li>
<li>Vanishing gradient problem:
<ul class="org-ul">
<li>Gradients diminish through long sequences.</li>
<li>Makes learning long-term dependencies difficult since standard RNN have difficulty remembering state from earlier epochs</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgd6c447e" class="outline-3">
<h3 id="orgd6c447e"><span class="section-number-3">16.5.</span> Standard RNN</h3>
<div class="outline-text-3" id="text-16-5">
<ul class="org-ul">
<li>Standard RNN cell:
<ul class="org-ul">
<li>Hₜ = tanh(WXₜ + UHₜ₋₁ + b)</li>
</ul></li>
<li>Suffers from vanishing gradient problem on long sequences.</li>
<li>Motivation for improved architectures like LSTM and GRU.</li>
</ul>
</div>
</div>

<div id="outline-container-org6e82bdb" class="outline-3">
<h3 id="org6e82bdb"><span class="section-number-3">16.6.</span> Long Short Term Memory Networks</h3>
<div class="outline-text-3" id="text-16-6">
<ul class="org-ul">
<li>Overview
<ul class="org-ul">
<li>LSTM (Long Short-Term Memory) is an advanced RNN cell that addresses the <b><b>vanishing gradient</b></b> problem.</li>
<li>Compared to standard RNNs, LSTMs:
<ul class="org-ul">
<li>Maintain more complex internal structure.</li>
<li>Include an additional input/output: the <b><b>cell state (c)</b></b>.</li>
</ul></li>
</ul></li>

<li>Inputs and Outputs
<ul class="org-ul">
<li>Inputs:
<dl class="org-dl">
<dt>Current input</dt><dd>\(x^{(t)}\)</dd>
<dt>Previous hidden state</dt><dd>\(h^{(t-1)}\)</dd>
<dt>Previous cell state</dt><dd>\(c^{(t-1)}\)</dd>
</dl></li>
<li>Outputs:
<dl class="org-dl">
<dt>Current hidden state</dt><dd>\(h^{(t)}\)</dd>
<dt>Current cell state</dt><dd>\(c^{(t)}\)</dd>
</dl></li>
</ul></li>

<li>LSTM: Cell state
<ul class="org-ul">
<li>Gates control information flow through the cell.</li>
<li>Types of gates:
<dl class="org-dl">
<dt><b><b>Forget gate</b></b> \(f^{(t)}\)</dt><dd>decides what to remove from \(c^{(t-1)}\)</dd>
<dt><b><b>Input gate</b></b> \(i^{(t)}\)</dt><dd>decides how much new information to add</dd>
<dt>Input gate \(\widetilde{c}^{(t)}\)</dt><dd>decides what new information to add</dd>
<dt><b><b>Output gate</b></b> \(o_t\)</dt><dd>decides what to output as \(h_t\)</dd>
</dl></li>
<li>Gate values are computed using <b><b>sigmoid functions</b></b> (values between 0 and 1).</li>
</ul></li>

<li>LSTM: update cell state
\[
  c^{(t)} = f^{(t)} \odot c^{(t-1)} + i^{(t)} \odot \widetilde{c}^{(t)}
  \]</li>

<li>LSTM: Output gate
<ul class="org-ul">
<li>Updated as: \(h^{(t)} = o^{(t)} \odot tanh(c^{(t)})\)</li>
<li>Involves:
<ul class="org-ul">
<li>Applying \(tanh\) to cell state \(c_t\)</li>
<li>Element-wise multiplying with output gate \(o_t\)</li>
</ul></li>
</ul></li>

<li>Example Use Case</li>
<li>In healthcare (e.g., patient visit records):
<ul class="org-ul">
<li>One element of \(c^{(t)}\) might represent <b><b>mortality risk score</b></b></li>
<li>Forget gate may decide to forget or retain this score</li>
<li>Input gate may update with a new score</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org1d8daee" class="outline-3">
<h3 id="org1d8daee"><span class="section-number-3">16.7.</span> Gated Recurred Unit</h3>
<div class="outline-text-3" id="text-16-7">

<div id="orgb5aeaff" class="figure">
<p><img src="./img/gru1.png" alt="gru1.png" />
</p>
</div>
<ul class="org-ul">
<li>Inputs:
<ol class="org-ol">
<li>Hidden state \(h^{(t-1)}\) from previous run</li>
<li>Input state \(x^{(t)}\)</li>
</ol></li>
<li>GRU: simpler alternative to LSTM with good performance.
<ul class="org-ul">
<li>gets rid of cell state; \(h\) hidden state serves as cell state.</li>
<li>combines forget gate and input gate in the <b><b>update gate</b></b>.</li>
</ul></li>
<li>Key components:
<dl class="org-dl">
<dt><b><b>Update gate</b></b> \(z^{(t)}\)</dt><dd><span style='background-color: #FFFF00;'>(weighted) control over how much to keep from old H</span>.
<ul class="org-ul">
<li>Update gate is a <b><b>sigmoid activation function</b></b> applied on input and previous cell state.</li>
</ul></dd>
<dt><b><b>Reset gate</b></b> \(r^{(t)}\)</dt><dd>controls influence of \(h^{(t-1)}\) on candidate state.</dd>
</dl></li>
<li>Hidden state update:
<ul class="org-ul">
<li>New Hₜ = (1 - Zₜ) ∘ Hₜ₋₁ + Zₜ ∘ H̃ₜ</li>
</ul></li>
<li>Uses fewer parameters than LSTM, performs comparably in practice.</li>
</ul>
</div>
</div>

<div id="outline-container-org5d72bac" class="outline-3">
<h3 id="org5d72bac"><span class="section-number-3">16.8.</span> Bidirectional RNN</h3>
<div class="outline-text-3" id="text-16-8">
<ul class="org-ul">
<li>BiRNN = two RNNs:
<ul class="org-ul">
<li>One reads sequence <b>forward</b>, other <b>backward</b>.</li>
<li>Outputs are <b>concatenated</b> for each time step.</li>
</ul></li>
<li>Benefits:
<ul class="org-ul">
<li>Provides full <span style='background-color: #FFFF00;'>context</span> from both past and future.</li>
<li>Especially useful in <span style='background-color: #FFFF00;'>NLP</span> (e.g., semantic understanding).</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb3cae1a" class="outline-3">
<h3 id="orgb3cae1a"><span class="section-number-3">16.9.</span> Sequence to Sequence RNN</h3>
<div class="outline-text-3" id="text-16-9">
</div>
<div id="outline-container-orgb9de697" class="outline-4">
<h4 id="orgb9de697"><span class="section-number-4">16.9.1.</span> Overview</h4>
<div class="outline-text-4" id="text-16-9-1">
<ul class="org-ul">
<li>The Seq2Seq model has two main phases:
<ol class="org-ol">
<li>Encoding phase</li>
<li>Decoding phase</li>
</ol></li>
<li>Commonly used in tasks like machine translation.</li>
</ul>
</div>
</div>

<div id="outline-container-org8d8fd82" class="outline-4">
<h4 id="org8d8fd82"><span class="section-number-4">16.9.2.</span> Encoding Phase</h4>
<div class="outline-text-4" id="text-16-9-2">
<ul class="org-ul">
<li>Functions like a standard RNN:
<ul class="org-ul">
<li>Takes input sequence (e.g., a sentence).</li>
<li>Converts it into a sequence of hidden (latent) states.</li>
<li>Final hidden state represents a compressed representation of the entire input (context vector).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgc27599b" class="outline-4">
<h4 id="orgc27599b"><span class="section-number-4">16.9.3.</span> Decoding Phase</h4>
<div class="outline-text-4" id="text-16-9-3">
<ul class="org-ul">
<li>Begins after encoding is complete:
<ul class="org-ul">
<li>Takes the final latent state from the encoder as the initial input.</li>
<li>Generates the output sequence one token at a time.</li>
<li>Each generated output is fed into the next time step as input (auto-regressive decoding).</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgc8caf31" class="outline-4">
<h4 id="orgc8caf31"><span class="section-number-4">16.9.4.</span> Applications</h4>
<div class="outline-text-4" id="text-16-9-4">
<ul class="org-ul">
<li>Machine Translation:
<ul class="org-ul">
<li>Input: a sentence in source language (e.g., Chinese).</li>
<li>Output: translation in target language (e.g., English).</li>
<li>Important to fully process the input sentence first to handle language-specific variations in word order and grammar.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org48178fb" class="outline-4">
<h4 id="org48178fb"><span class="section-number-4">16.9.5.</span> Key Insight</h4>
<div class="outline-text-4" id="text-16-9-5">
<ul class="org-ul">
<li>Seq2seq architecture supports:
<ul class="org-ul">
<li>Handling <span style='background-color: #FFFF00;'>variable-length inputs and outputs</span></li>
<li>Maintaining semantic meaning across different languages</li>
<li>Flexible generation based on <span style='background-color: #FFFF00;'>entire input context</span></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga4f119e" class="outline-3">
<h3 id="orga4f119e"><span class="section-number-3">16.10.</span> Healthcare Applications</h3>
<div class="outline-text-3" id="text-16-10">
<ul class="org-ul">
<li>Application: Doctor AI (2016)
<ul class="org-ul">
<li>Predicts future patient events using RNNs.</li>
<li>Input: sequence of clinical visits (multi-hot encoded).</li>
<li>Output: next visit’s diagnosis codes.</li>
</ul></li>
<li>Dataset: 260,000 patients, 10 years of data, 38k unique codes.
<ul class="org-ul">
<li>Sparse input vectors; ~10–15 nonzero values per visit.</li>
<li>Output space: 1183 diagnosis codes.</li>
</ul></li>
<li>Evaluation:
<ul class="org-ul">
<li><b>Top-k recall</b>: measures how many true labels are in top-k predictions.</li>
<li>RNN outperformed baselines (heuristics, logistic regression).</li>
</ul></li>
<li>Transfer learning:
<ul class="org-ul">
<li>Pretrained RNNs on large datasets can improve performance on smaller hospital datasets.
<ul class="org-ul">
<li>Warm-start initialization leads to better generalization.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org40651ca" class="outline-2">
<h2 id="org40651ca"><span class="section-number-2">17.</span> Focus</h2>
<div class="outline-text-2" id="text-17">
<blockquote>
<p>
Concepts, ideas, and algorithms mentioned in lectures, labs, and assignments.
</p>

<p>
Mostly conceptual level questions, the remaining = simple computation/coding syntax/complexity questions.
</p>

<p>
Likely topics: MapReduce, Hadoop, Spark, Scala, KNN, Kmeans, random forest, EM, CNN, linear regression, logistics regression.
</p>
</blockquote>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: W</p>
<p class="date">Created: 2025-04-08 Tue 19:16</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
