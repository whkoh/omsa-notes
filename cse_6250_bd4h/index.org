#+AUTHOR: W
#+SETUPFILE:/Users/whkoh/git-repos/org-html-themes/org/theme-readtheorg-local-parent.setup
#+TITLE: BD4H
* Introduction to Big Data
** Introduction
   - Course: Big Data Analytics for Healthcare (BDAH)
   - Instructor: Jimeng Sun, associate professor at Georgia Tech
   - Background: Expertise in healthcare analytics and data mining, previous work at IBM TJ Watson Research Center
   - Course focus: What students will learn and why it matters

** About BDAH
   - Intersection of healthcare and big data
   - Covers healthcare applications, data, analytics, and big data processing
   - Focus on how data science is applied to healthcare

** Learning Goals
   - Understand healthcare data
   - Learn analytics algorithms
   - Work with big data systems
   - Application: Build models for disease risk prediction, treatment recommendation, patient clustering, and similarity analysis
   - Assessments: Homework using big data tools, project with system building, report writing, and presentations

** Current Problems in Healthcare
   - High costs: $3.8 trillion/year in the U.S.
   - Massive waste: $765 billion/year
   - Poor quality: 200,000-400,000 preventable deaths annually
   - Preventable deaths ranked as the third leading cause of death
   - Hope: Big data can improve care and reduce costs

** The Four Vs
   - Volume: Large healthcare data amounts
   - Variety: Different types of healthcare data sources
   - Velocity: Real-time data processing needs
   - Veracity: Issues with data quality (noise, missing data, errors)

** More About The Four Vs
   - Examples of data volume:
     - Genomic data: 200 GB per genome
     - fMRI scan: ~300 GB per scan
     - US medical imaging data per year: ~100 petabytes
   - Data variety:
     - Clinical (demographics, diagnosis, procedures, etc.)
     - Patient-generated (wearables, sensors)
     - Real-time (ICU monitoring data)
   - Focus on managing diverse data types in the course

** Data Science is Sexy
   - Data science is a critical field
   - Harvard Business Review: "Data Scientist, The Sexiest Job in the 21st Century"
   - Data scientists:
     - Capitalize on big data
     - Overcome technical limitations
     - Develop key tools like Hadoop and Spark

** BDAH Quiz 1 Question
   - True/False: A graduate-level degree is necessary to become a data scientist.

** BDAH Quiz 1 Solution
   - Answer: True

** BDAH Quiz 2 Question
   - Question: What is the average salary of a data scientist?

** BDAH Quiz 2 Solution
   - Answer: $120,000 per year (experienced data scientists earn over $150,000)

** BDAH Quiz 3 Question
   - Question: What skills do data scientists need?

** BDAH Quiz 3 Solution
   - Answer:
     - Math and statistics
     - Domain knowledge
     - Programming and databases
     - Communication and visualization

* Big Data Course Overview
** Introduction to Course Overview
   - Overview of big data analytics for healthcare.
   - Topics covered:
     - Healthcare applications of big data.
     - Algorithms used in applications.
     - Software systems for implementation.
   - Course structure alternates among these topics.

** Big Data Big Picture
   - Course focuses on three key areas:
     - Big data systems.
     - Scalable machine learning algorithms.
     - Healthcare applications.
   - Integration of these elements to solve healthcare problems.

** Healthcare Applications
   - Three types of healthcare applications:
     1. **Predictive Modeling**: Uses historical data to predict future outcomes.
     2. **Computational Phenotyping**: Converts electronic health records (EHRs) into meaningful clinical concepts.
     3. **Patient Similarity**: Identifies groups of patients with similar characteristics.
   - Starts with predictive modeling.

** Predictive Modeling Quiz Question
   - Predictive modeling example: predicting treatment effectiveness for epilepsy patients.
   - Quiz: Estimate percentage of patients responding to different treatments.

** Predictive Modeling Quiz Solution
   - Solution breakdown:
     - **Group A** (responded within 2 years): 32%.
     - **Group B** (responded between 2-5 years): 24%.
     - **Group C** (did not respond after 5 years): 44%.
   - Goal of predictive modeling:
     - Improve early response rates.
     - Identify non-responders for alternative treatments.

** Predictive Modeling Challenges
   - Challenges in predictive modeling:
     - Handling large patient datasets with various types of data.
     - Managing multiple models in a complex computational pipeline.
     - Evaluating and comparing multiple predictive pipelines.

** Computational Phenotyping
   - Converts raw patient data (e.g., demographics, diagnoses, medications, procedures, lab tests, clinical notes) into clinical concepts or phenotypes.

** Computational Phenotyping Quiz Question
   - Identifying data issues in phenotyping.
   - Quiz: List potential "waste products" in raw data.

** Computational Phenotyping Quiz Solution
   - Common data issues:
     - **Missing values**: Some important data may be absent.
     - **Duplicates**: Patient records may appear multiple times.
     - **Irrelevant data**: Not all raw information is useful.
     - **Redundant information**: Different records may indicate the same condition (e.g., diagnosis and medication for diabetes).

** Phenotyping Algorithm
   - Example: Identifying Type 2 Diabetes from EHR data.
   - Decision process:
     - Check for Type 1 Diabetes diagnosis.
     - Check for Type 2 Diabetes diagnosis.
     - Verify medication records and abnormal lab results.
   - Importance:
     - EHR data is often unreliable.
     - Multiple data sources improve diagnostic accuracy.

** Patient Similarity Quiz Question
   - Different types of reasoning doctors use:
     - Flowchart-based reasoning (like phenotyping algorithms).
     - Instinct and intuition.
     - Case-based reasoning (comparing patients to past cases).

** Patient Similarity Quiz Solution
   - Correct answer: **Case-based reasoning**.
   - Doctors often compare current patients to previous similar cases.

** Patient Similarity
   - Simulating case-based reasoning using algorithms.
   - Process:
     - Search for similar patients in a database.
     - Identify treatment outcomes for similar cases.
     - Recommend best treatment based on historical data.
   - Objective: Utilize full database knowledge instead of relying on a single doctor's experience.

** Algorithms
   - Introduction to machine learning algorithms in healthcare.
   - Covered topics:
     1. **Classification**: Mapping patient data to target variables (e.g., predicting heart attack risk).
     2. **Clustering**: Grouping similar patients based on health conditions.
     3. **Dimensionality Reduction**: Reducing large patient datasets to essential features.
     4. **Graph Analysis**: Analyzing relationships between patients and diseases.

** Systems
   - Introduction to big data systems for healthcare applications.
   - Covered systems:
     - **Hadoop**: Disk-based distributed system.
     - **Spark**: In-memory distributed system (faster than Hadoop).
   - Topics include:
     - Hadoop infrastructure (MapReduce, HDFS, Pig, Hive, HBase).
     - Spark infrastructure (Spark SQL, Spark Streaming, MLlib, GraphX).

** Summary
   - Recap of three key areas:
     - Healthcare applications.
     - Machine learning algorithms.
     - Big data systems.
   - Course integrates these areas:
     - Example: Using logistic regression on Hadoop to predict heart failure.
   - Next step: Begin applying concepts.

* Predictive Modeling
** Introduction to Predictive Modeling
  - Predictive modeling ::  using historical data to predict future events.

    - Example: Using electronic health records (EHR) to model heart failure
    - Key Goal: Develop a good predictive model using EHR efficiently.

** Predictive Modeling vs EHR
  - Importance: Increased research interest in using EHR for clinical predictive modeling.
  - Data Sources: EHR has become a major source for predictive modeling research.

** Predictive Modeling Pipeline
  - Predictive modeling is a multi-step computational process:
    1. Define the prediction target.
    2. Construct the relevant patient cohort.
    3. Identify potentially relevant features.
    4. Select the most relevant features.
    5. Compute the predictive model.
    6. Evaluate the predictive model.
  - Iterative process until a satisfactory model is obtained.

** Prediction Target
  - Investigators may have many targets, but only some are feasible.
  - Selection criteria: The target should be interesting and possible with the available data.
  - Example: Predicting the onset of heart failure.

** Heart Failure Quiz
  - Question: How many new heart failure cases occur annually in the U.S.?
  - Options: 17,000; 260,000; 550,000; 1,250,000.
  - Answer: 550,000 cases per year.

** Motivations for Early Detection
  - Heart failure is complex with diverse symptoms and subsets.
  - Early detection can:
    - Reduce hospitalization costs.
    - Introduce early interventions to slow progression.
    - Improve clinical guidelines for heart failure prevention.

** Cohort Construction
  - Defines the study population for predictive modeling.
  - Study population is a subset of all patients.
  - Four study designs based on two axes:
    - Prospective vs. Retrospective studies.
    - Cohort vs. Case-Control studies.

** Prospective vs. Retrospective Studies
  - **Prospective Study**: Define cohort first, then collect data.
  - **Retrospective Study**: Use existing data from past records.

** Prospective vs. Retrospective Quiz
  - Comparison of study properties:
    - Retrospective studies have more noise.
    - Prospective studies are more expensive and time-consuming.
    - Retrospective studies can handle larger datasets.

** Cohort Study
  - Includes patients exposed to a particular risk (e.g., heart failure readmission).
  - Defines inclusion and exclusion criteria.

** Case-Control Study
  - Compares patients with a condition (cases) to similar patients without it (controls).
  - Matching criteria: Age, gender, clinic visits.
  - Cases are rarer than controls in real-world data.

** Feature Construction
  - Defines patient features for predicting outcomes.
  - Data sequences from EHR:
    - Events (diagnoses, medications, lab results).
    - Observation window (used for feature extraction).
    - Prediction window (future period to predict).
  - Impact of window sizes on model accuracy.

** Feature Construction Quizzes
  - Quiz 1: Best timeline for modeling → Large observation, small prediction window.
  - Quiz 2: Most useful model → Small observation, large prediction window (ideal but difficult).

** Prediction Performance on Windows
  - **Prediction Window**: Longer window reduces accuracy.
  - **Observation Window**: Longer window improves model performance until plateau.

** Feature Selection
  - Identifies relevant features from EHR data.
  - EHR provides a large number of potential features (e.g., demographics, vitals).
  - Different targets require different feature subsets.

** Predictive Model
  - Maps input features to predicted outcomes.
  - Regression models for continuous targets (e.g., healthcare costs).
  - Classification models for categorical targets (e.g., heart failure).
  - Common methods: Logistic regression, decision trees, random forests.

** Performance Evaluation
  - Key metric: Testing error (not training error).
  - Models must generalize to unseen data.

** Cross-Validation
  - Splits data into training and validation sets.
  - Common methods:
    - Leave-One-Out Cross-Validation.
    - K-Fold Cross-Validation.
    - Randomized Cross-Validation.

** Conclusion
  - Summary of the predictive modeling pipeline:
    - Define the prediction target.
    - Construct the patient cohort.
    - Generate relevant features.
    - Select important features.
    - Train the predictive model.
    - Evaluate model performance.
  - Goal: Design high-level predictive modeling studies using EHR data.

* MapReduce
** Introduction to MapReduce
- Overview of MapReduce as a big data processing tool.
- Utilizes distributed computation and storage.
- Covers:
  - What MapReduce is
  - Fault tolerance in distributed environments
  - Analytical use cases and limitations

** What is MapReduce
- Hadoop/MapReduce is:
  - A programming model for parallel computation
  - An execution environment (Hadoop with HDFS)
  - A software package with various tools
- Capabilities:
  - Distributed storage via HDFS
  - Distributed computation via MapReduce
  - Built-in fault tolerance

** Computational Process
- Originated at Google (2004), open-sourced via Apache Hadoop.
- Java-based platform.
- Programming constrained to Map and Reduce functions for scalability.
- Designed for parallel, fault-tolerant processing.
- Emphasis on mastering computational patterns for analytics.

** Learning Via Aggregation Statistics
- Core design: express ML algorithms as aggregation tasks.
- Example: Heart failure risk factor frequency analysis.
- Map: extract risk factors per patient.
- Reduce: aggregate frequencies across population.
- Leads into deeper abstraction needs and trade-offs.

** MapReduce Abstraction
- Example task: count disease cases from patient records.
- Map:
  - Emit (disease, 1) for each mention
- Shuffle:
  - Group by disease
- Reduce:
  - Sum values for each disease
- Emphasizes two-phase logic for scalability.

** MapReduce System
- Real-world data is too large for single machines.
- Data is partitioned and processed by multiple mappers.
- Intermediate results are shuffled and passed to reducers.
- Final results computed from reduce function.
- Three stages:
  - Map
  - Shuffle
  - Reduce

** MapReduce Fault Recovery
- Fault tolerance is a built-in system feature.
- On failure:
  - Mappers/reducers are restarted with minimal recomputation.
- Goal: Only failed components are recomputed.
- System handles all failure recovery.

** Distributed File Systems
- HDFS: Hadoop's storage system.
- Splits large files into partitions.
- Partitions stored on multiple machines with redundancy.
- Benefits:
  - Faster concurrent access
  - Fault tolerance (recover from worker failures)

** MapReduce Design Choice
- Design principle: minimal functionality for reliability and scalability.
- Restricted computation model (e.g., aggregation queries).
- Map: operate on individual records
- Reduce: aggregate results
- Supports straggler mitigation (slow mappers duplicated)

** Analytics with MapReduce
- Application examples:
  - K-Nearest Neighbors (KNN)
  - Linear Regression

** MapReduce KNN
- KNN implementation:
  - Map:
    - Find K nearest neighbors per partition
  - Reduce:
    - Combine local results to find global nearest neighbors
- Patient data partitioned, processed in parallel

** Linear Regression
- Goal: map patient features to heart disease risk
- Normal equation:
  - β = (XᵗX)⁻¹Xᵗy
- MapReduce:
  - Map f1: compute xi * xiᵗ
  - Map f2: compute xi * yi
  - Reduce: aggregate sums

** MapReduce for Linear Regression Quiz Question
- Quiz: specify map/reduce pseudo code for computing Xᵗy

** MapReduce for Linear Regression Quiz Solution
- Solution:
  - Map: compute xi * yi
  - Reduce: aggregate results

** Limitations of MapReduce
- Example: Logistic Regression via Gradient Descent
- Challenge: Requires iterative computation
  - Each iteration loads data twice
- MapReduce not efficient for:
  - Iterative, multi-stage computation

** MapReduce Summary Quiz Question
- Quiz on ideal conditions for MapReduce:
  - Single vs. multiple passes
  - Skewed vs. uniform key distribution
  - Synchronization needs

** MapReduce Summary Quiz Solution
- Best suited for:
  - Single-pass jobs (e.g., histograms)
  - Both skewed and uniform key distributions
  - Minimal synchronization (only between Map and Reduce phases)
* Classification Model Metrics
** Predictive Model review
- Predictive model :: mapping function between model inputs and outputs (pred's)
- Model metrics :: needed to know how well they're performing
** Confusion matrix
- True positive/negative also known as "Condition" positive/negative
- Predicted positive/negative also known as "Prediction Outcome" positive/negative
** Accuracy metrics
All divided by ground truth values.
- Accuracy :: (TP+TN)/TP. Not most useful for imbalanced class
- True positive rate :: TP/CP (Sensitivity, Recall)
- False positive rate :: FP/CN
- False negative :: FN/CP
- True negative rate :: TN/CN (Specificity)
*** Other notes
- FP is a type I error.
- FN is a type II error.
- Hard to perform well on all metrics
- Important to choose the right metrics
** Predictive metrics
All divided by prediction outcomes.
- Prevalence :: CP/Total population. How likely disease occurs in population
- Positive predictive value (Precision) :: TP/Pred outcome positive.
- False discovery rate :: FP/Pred outcome positive
- Negative predictive value :: TN/Pred outcome negative
- False omission rate :: FN/Pred outcome negative
** F1 score
Harmonic mean of PPV and TPR
$$
F_1 = 2 \times \frac{PPV \times TPR}{PPV + TPR}
$$
** Classifier quiz
Which is the best classifier?
- Highest F1, PPV and Accuracy is the best classifier
** Reversing predictions
It's always possible to reverse the predictions so 0.21 might perform better than 0.69/0.50.
** Receiver operating characteristic
- Predictive models generally output continuous score.
- Threshold is needed as precision bound to force to a certain category
- ROC provides a way to compare performance of classifiers as the decision boundary is varied
- ROC curve is the plot of TP rate vs FP rate at various threshold values
  - We sort by prediction score (highest first)
  - Use prediction score as threshold values
  - Plot on the chart and see how many are misclassified (needs True value to be known)
- AUROC does not depend on the choice of threshold.
- AUROC is the most popular metric for classification
** "Best classifier threshold" quiz
- There isn't a standard answer, it depends on whether TP, TN or other metric is prioritized
** Regression metrics
- MAE :: average of absolute errors, harder to work with since the absolute value is not differentiable
- MSE :: average of squared errors, easier to work with as the derivative of squared term is linear. Increases a lot faster than MAE
- $R^2$ :: bounded by $(-\infty,1)$. AKA coefficient of determination.
*** $R^2$
$$
R^2 = 1-\frac{\sum_i (y_i - \hat{y}_i)^2}{\sum_i(y_i - \bar{y})^2}
$$
i.e. 1-MSE/Variance

Negative $R^2$ values means they perform worse than a simple average of raw data.
As noise increases, $R^2$ decreases.
* Ensemble methods
** Gradient Descent Method (GDM) for Linear Regression
- Illustrates gradient descent using linear regression.
- Dataset: each row = patient; features in X, outcome Y (e.g., hospital cost).
- Objective: learn linear mapping from features X to outcome Y.
- Assumes Gaussian distribution → log-likelihood leads to squared error minimization.
- Gradient: derived by taking derivative of log-likelihood w.r.t. coefficients β.
- Update rule: move β in direction of gradient with step size η.
- Requires multiple iterations over full dataset → computationally expensive.

** Stochastic Gradient Descent (SGD) Method
- SGD is a scalable variant of gradient descent for large datasets.
- Instead of using full dataset, computes gradients on random subsets (mini-batches).
- One-point update = SGD; larger batches = mini-batch gradient descent.
- Faster per-iteration updates compared to full batch gradient descent.

** SGD for Linear Regression
- Applies SGD to same regression problem.
- Each update uses one patient:
  - Compute individual log-likelihood and gradient.
  - Update β using gradient.
- More efficient than full gradient computation.
- Key idea: updates based on single or small group of samples.

** Ensemble Method Pt 1
- Ensemble methods combine multiple models for improved performance.
- Can use same (e.g., Random Forest) or different base models.
- Real-world example: Netflix Prize → ensemble models won.
- Many teams merged, forming more powerful ensembles.

** Ensemble Method Pt 2
- General ensemble steps:
  1. Generate multiple datasets (via bagging or boosting).
  2. Train separate models on each.
  3. Aggregate outputs using functions like averaging or weighted sum.
- Outcome: different ensemble strategies.

** Bias Variance Tradeoff
- Key insight: model error = bias² + variance.
- Bias: error from wrong assumptions (e.g., assuming linear when it's not).
- Variance: error from sensitivity to training data.
- Ideal model: low bias and low variance.
- Graphical example: dartboard showing different combinations.
- As model complexity increases:
  - Bias ↓
  - Variance ↑
  - Total error = minimum at an optimal complexity.

** Bias Variance Tradeoff Quiz Question
- Task: rank four models (flat, linear, smooth curve, wiggly) by complexity.
- A → D: D (flat) < A (linear) < B (curve) < C (wiggly)

** Bias Variance Tradeoff Quiz Solution
- Explanation:
  - D: lowest complexity (flat line).
  - A: next, simple linear model.
  - B: more complex curve.
  - C: most complex (wiggly).

** Bias Variance Tradeoff Quiz 2 Question
- Given same models, asked which best fits data.

** Bias Variance Tradeoff Quiz 2 Solution
- Answer: B (smooth curve)
- Balances bias and variance well.

** Bagging
- Bagging = Bootstrap Aggregation.
- Method:
  - Sample data with replacement.
  - Train models on each sample.
  - Combine predictions via majority vote or averaging.
- Reduces variance of the final model.

** Random Forest
- Special case of bagging with decision trees.
- Steps:
  - Randomly sample both rows (patients) and columns (features).
  - Train simple decision trees on these subsets.
- Final prediction = average of all trees.
- Simple trees help maintain diversity and lower computation.

** Why Bagging Works
- Reduces variance without increasing bias.
- Variance reduction from averaging independent model predictions.
- Based on statistical principle: variance of mean = variance / T for T models.

** Boosting
- Builds models sequentially.
- Each new model focuses on mistakes of previous ones.
- Final model = weighted combination of all models.
- Pros: better accuracy.
- Cons: prone to overfitting.
- Example: AdaBoost is most popular.

** Bagging vs Boosting Quiz Question
- Quiz to compare characteristics:
  - Combination method (simple vs weighted average)
  - Parallelism
  - Noise sensitivity
  - Accuracy

** Bagging vs Boosting Quiz Solution
- Bagging:
  - Simple average, parallel-friendly, less sensitive to noise, reliable.
- Boosting:
  - Weighted average, sequential (hard to parallelize), sensitive to noise, potentially higher accuracy but less reliable.
- Analogy:
  - Bagging = reliable Japanese car.
  - Boosting = high-performance but risky sports car.

** Summary for Ensemble Methods
- Pros:
  - Simple, flexible, few parameters, theoretical backing.
- Cons:
  - Computational cost (training + inference).
  - Harder interpretation (due to model complexity).

** Introduction to Ensemble Method
- Sets the stage:
  - Recap on model evaluation.
  - Overview: SGD, ensemble methods, bias-variance tradeoff, bagging & boosting.

** Gradient Descent Method
- General overview of gradient descent for optimization.
- Applies to regression/classification.
- Process:
  1. Define likelihood (or log-likelihood).
  2. Compute gradient w.r.t. parameters.
  3. Update parameters iteratively using gradient.
- Requires step size (learning rate).
- Can be extended using more advanced techniques (e.g., conjugate gradient).


* Computational Phenotyping
** Introduction to Phenotyping
- Introduction to clustering in healthcare, specifically "phenotyping."
- Phenotypes refer to diseases or conditions; known phenotypes exist, but many more are undiscovered.
- Computational phenotyping helps discover novel phenotypes using available data.
- Applications include disease diagnosis, cost prediction, readmission risk, and genomic studies.

** Computational Phenotyping
- Converts raw EHR data into meaningful phenotypes using algorithms.
- EHR data includes demographics, diagnosis codes, medications, procedures, labs, notes.
- Challenges:
  - Noisy and incomplete data.
  - Primarily designed for clinical use, not research.
  - Redundancy across data sources.
- Goal: derive research-grade phenotypes from raw clinical data.

** Phenotyping Algorithm
- Example: Type 2 diabetes phenotyping algorithm.
- Sequential logic:
  1. Exclude Type 1 diagnosis.
  2. Check for Type 2 diagnosis.
  3. Check medication and lab results.
- Multiple confirmation paths possible.
- Developed manually by clinical experts.

** Applications of Phenotyping
- Genomic studies: link genomic and phenotypic data.
- Clinical predictive modeling: forecast disease onset, hospitalizations.
- Pragmatic clinical trials: assess treatment effectiveness in real-world settings.
- Healthcare quality measurement: compare care quality across institutions.
- All rely on robust phenotyping algorithms.

** Genomic Wide Association Study
- GWAS scans SNPs to associate genetic variations with diseases.
- Steps:
  1. Identify phenotypes.
  2. Divide subjects into cases/controls.
  3. Collect DNA and scan for SNPs.
  4. Calculate odds ratios and p-values.
- Statistically significant SNPs may indicate disease relevance.
- High-quality phenotyping critical for accurate GWAS.

** Why Do We Care About Phenotyping
- Genomic data is rapidly becoming cheaper and more abundant.
- Phenotypic data remains complex and costly to acquire.
- Demand for better phenotyping algorithms to support scalable, high-quality genomic research.

** Clinical Predictive Modeling
- Predictive modeling using raw EHR data is problematic (noise, complexity, lack of portability).
- Phenotyping transforms raw data into simpler, meaningful concepts.
- Benefits:
  - Better model accuracy.
  - Easier interpretation.
  - Generalizability across hospitals.

** Pragmatic Clinical Trials
- Traditional vs. pragmatic trials:
  - Traditional: controlled, single condition/drug, strict selection, randomized.
  - Pragmatic: real-world, multiple conditions/drugs, minimal selection, often not randomized.
- High-quality phenotyping essential for identifying patient conditions and treatments in pragmatic settings.

** Healthcare Quality Measurement
- Challenge: hospitals use diverse EHR formats.
- Centralized processing of raw data is complex.
- Solution: local phenotyping at hospitals → send standardized phenotype data to central site.
- Enables scalable and fair quality comparison across institutions.

** Phenotyping Methods Part 1
- Two main approaches:
  - Supervised learning: uses labeled data (function approximation).
  - Unsupervised learning: identifies patterns/structures without labels (description/summarization).
- Illustrative examples and playful dialogue explore these ideas in depth.

** Phenotyping Methods Part 2
- Supervised: expert-defined rules (Boolean logic, decision trees), or machine learning classifiers.
  - Pros: interpretable, low validation effort.
  - Cons: high development cost, not good for unknown phenotypes, potential poor transferability.
- Unsupervised: clustering, dimensionality reduction.
  - Pros: less manual effort, no need for labels.
  - Cons: hard to validate, large data requirements.

** Phenotyping Quiz Question
- Quiz:
  - Which approach requires more human effort during evaluation?
  - Which is easier to interpret?
  - Choices: expert-defined rules vs. classification models.

** Phenotyping Quiz Solution
- Answer:
  - Classification models require more evaluation effort (need more labeled data).
  - Expert-defined rules are easier to interpret (clinician-derived, intuitive).


* Clustering

** Introduction to Clustering
- Introduction of clustering as a method distinct from classification.
- Classification: Grouping by known labels.
- Clustering: Discovering groups from raw data.
- Topics covered:
  - Definition of clustering.
  - Algorithms: K-means, Gaussian Mixture Models (GMM).
  - Scalable algorithms for large datasets.
  - Applications in healthcare.

** Healthcare Applications
- Clustering in healthcare:
  - Patient stratification: group patients with similar characteristics.
  - Disease hierarchy discovery: learn structure/relationships among diseases.
  - Phenotyping: convert raw data into meaningful phenotypes (clinical concepts).
  - Phenotypes = clusters of similar patients.

** What is Clustering
- Clustering explained via patient-disease matrix:
  - Rows = patients, Columns = diseases.
  - Apply clustering to rows → patient clusters (e.g., P1, P2, P3).
  - Apply clustering to columns → disease clusters (e.g., D1, D2, D3).
  - Supports applications like phenotyping and disease discovery.

** Algorithm Overview
- Two categories of clustering algorithms:
  - Classical: K-means, Hierarchical, Gaussian Mixture Model.
  - Scalable: Mini-batch K-means, DBSCAN.

** K Means
- Inputs: data points X₁ to Xₙ, number of clusters K.
- Outputs: K clusters S₁ to Sₖ.
- Objective: Minimize distance of data points to cluster centers (µᵢ).
- Algorithm steps:
  1. Initialize K centers.
  2. Assign points to nearest center.
  3. Update centers based on mean of assigned points.
  4. Repeat until convergence.
- Example illustrated using K=2.

** K Means Quiz Question
- Quiz: Given n, k, d (dimensions), i (iterations), what's the complexity?

** K Means Quiz Solution
- Complexity: O(n × k × d × i)
  - Cost driven by assignment and update operations.

** Hierarchical Clustering
- Builds a hierarchy of data points.
- Two approaches:
  - Agglomerative (bottom-up): Merge smallest clusters until one remains.
  - Divisive (top-down): Split one big cluster into smaller ones.
- Agglomerative more commonly used.

** Agglomerative Clustering
- Steps:
  1. Compute n×n distance matrix.
  2. Initialize each point as its own cluster.
  3. Iteratively merge closest clusters and update distance matrix.
  4. Stop when one cluster remains (produces a hierarchy).

** Gaussian Mixture Model
- Soft clustering: points belong to multiple clusters with probabilities.
- Each cluster is a Gaussian (normal distribution).
- Parameters: mean (µₖ), variance (σₖ), mixing coefficient (πₖ).
- Goal: Estimate GMM parameters from data.

** GMM Expectation Maximization
- Uses Expectation-Maximization (EM) algorithm:
  - Initialize parameters.
  - E-step: Compute assignment scores (γₙₖ).
  - M-step: Update parameters using γₙₖ.
  - Iterate until convergence.

** GMM Steps
- Details of EM:
  - Initialization: K-means can be used for better results.
  - E-step: Compute γₙₖ using cluster probabilities.
  - M-step:
    - Compute cluster size (Nₖ), mean (µₖ), covariance (σₖ), mixing coefficient (πₖ).

** GMM Visual Illustration
- Visual demo of GMM clustering.
- Iteratively updates Gaussians until convergence.
- Final model reflects soft cluster assignments.

** K Means Vs GMM
- Comparison:
  - K-means: hard assignment, single center (µₖ).
  - GMM: soft assignment, parameters include µₖ, σₖ, πₖ.
  - Both use iterative updates.

** Mini Batch K Means
- Scalable version of K-means.
- Works with small batches (M) instead of full dataset.
- Updates centers incrementally.
- Reduces computational cost for large data.

** Mini Batch K Means Quiz Question
- Quiz: Given k, t (iterations), b (batch size), d (dimensionality), compute complexity.

** Mini Batch K Means Quiz Solution
- Complexity: O(t × b × k × d)

** DBScan
- Density-Based Spatial Clustering.
- Clusters = dense areas, separated by sparse regions.
- Can identify clusters of arbitrary shape.
- Effective for noisy data.

** DBScan Key Concepts
- Density = number of points within ε-distance.
- Key concepts:
  - Core points: high-density.
  - Border points: near core points.
  - Noise: not in dense region.

** DBScan Algorithm
- Steps:
  1. Build graph connecting core points to neighbors.
  2. Identify connected components as clusters.
  3. Remove clustered points and repeat.

** DBScan Example
- Visual example: finds 6 clusters, some noise points remain.

** DBScan Quiz Question
- Quiz: How many clusters can a point belong to in DBSCAN?

** DBScan Quiz Solution
- Answer: 0 or 1 (noise = 0, core/border = 1)

** Clustering Evaluation Metrics
- Metrics:
  - Rand Index (RI)
  - Mutual Information (MI)
  - Silhouette Coefficient

** Rand Index
- Measures agreement between predicted and true clusters.
- RI = (number of correct pairs) / (total pairs)
- Value between 0 (bad) and 1 (perfect).

** Mutual Information
- From information theory: measures shared info between predicted and true clusters.
- Normalized Mutual Information (NMI) between 0 and 1.

** Summary of RI and MI
- Pros:
  - Bounded values, interpretable.
  - No assumptions about cluster shapes.
- Cons:
  - Require ground truth, which may be unavailable.

** Silhouette Coefficient
- Measures how similar a point is to its own cluster vs. others.
- Formula: (b - a) / max(a, b)
- Does not require ground truth.

** Silhouette Coefficient Pros and Cons
- Range: -1 (bad) to 1 (good), 0 = overlapping clusters.
- Assumes spherical clusters → less effective for complex shapes (e.g. DBSCAN).


* Spark

** Introduction to Spark
- Spark is introduced as an alternative to MapReduce, better suited for iterative workloads.
- Leverages distributed memory across machines.
- Core concept: Resilient Distributed Dataset (RDD).
- Promotes efficiency for machine learning and healthcare applications.

** Environment
- Big data analytics typically run in data centers or cloud platforms like AWS, GCP, Azure.
- Environment includes interconnected racks of servers.
- Context set to understand the need for systems like Spark.

** Motivation
- Hadoop & MapReduce explained with acyclic data flow using stable storage.
- Strength: fault-tolerance via disk storage.
- Weakness: inefficiency with iterative or interactive workloads (e.g. ML, graph analysis).
- Need for in-memory computation system like Spark.

** Iteration in Map Reduce
- Machine learning models need repeated computation.
- Hadoop repeatedly reads/writes from disk, causing inefficiency.
- Highlights the need for in-memory operations.

** Workload Illustration
- Iterative workloads: same computation on same data (e.g., model training).
- Interactive workloads: varying computations on evolving data (e.g., data exploration).
- Key: keep working sets in memory for speed.

** Challenge
- Challenge: memory is not fault-tolerant.
- Existing storage abstractions rely on fine-grained updates, which are expensive to track.
- Need for a better balance between efficiency and fault tolerance.

** Solution  RDDs
- Spark uses RDDs to balance fault-tolerance and efficiency.
- RDDs support coarse-grained transformations (e.g., map, group-by, join).
- Lineage tracking enables fault recovery without excessive replication.

** RDD Recovery
- Recovery through recomputation based on lineage.
- Interactive: rerun only failed iterations.
- Iterative: reload or recompute chunks from previous iterations.

** Spark Stack
- Core: scheduling, memory management, fault recovery.
- APIs: Spark SQL, Streaming, MLib (ML), GraphX.
- Compatible with YARN, Mesos, or standalone.

** Spark Programming Interface
- Interfaces: Scala, Python, Java.
- RDD operations: transformations and actions.
- Support for shared variables (broadcast, accumulator).

** RDD Transformations
- Examples: map vs flatMap, distinct, union, intersection, subtract.
- flatMap flattens nested lists from map.
- Intersection and subtract are more costly due to set operations.

** RDD Transformations Quiz Question
- Quiz: Apply map and filter on input RDD to understand transformation output.

** RDD Transformations Quiz Solution
- Map squares each number: [1, 4, 9, 16].
- Filter excludes ‘1’: resulting in [2, 3, 4].

** Spark Operations
- Transformations: map, filter, groupByKey, etc.
- Actions: reduce, collect, count, etc.
- Broader set than Hadoop MapReduce.

** Shared Variable
- Broadcast variables: efficient read-only shared data.
- Example Spark job with clinical notes:
  - Load data → filter → split → cache.
  - Perform actions like counting specific symptoms (e.g., fever, cough).
  - Benefits from caching and distributed execution.

** Fault Tolerance
- RDD tracks transformations (lineage).
- Lost partitions can be recomputed using lineage.
- Visuals: sequence of filters and maps reconstruct lost data.

** Example  Logistic Regression
- Spark efficiently supports logistic regression via iteration.
- Data cached in memory → quick updates.
- Uses map + reduce to compute gradient.
- Comparison: Spark (6s/iter) vs Hadoop (127s/iter).

** Example  Disease Risk Prediction
- Predict patient disease risks using collaborative filtering.
- Matrix R = patient × disease.
- ALS algorithm: alternates updating patient and disease features.

** Serial ALS
- Serial implementation of ALS.
- Iterative updates of A (patient) and B (disease) matrices.
- Uses map functions over patient/disease ranges.

** Naive Spark ALS
- Parallel ALS using `spark.parallelize`.
- Broadcast used for efficient data sharing.
- Broadcast improves performance 3× over naive version.

* Medical Ontology
** Introduction to Medical Ontology
- Healthcare benefits from structured medical knowledge.
- Ontologies and knowledge graphs are common in this domain.
- Historically, healthcare has developed ontologies for:
  - Diseases
  - Medical procedures
  - Medications
  - Lab tests
- Ontologies aid understanding of healthcare data and validate data models.
- The lesson discusses various ontologies and their role in analytics.

** Health Data Standards
- Overview of major health data standards:
  - LOINC: Lab test codes
  - ICD: Diagnostic codes
  - CPT: Procedure codes
  - NDC: Medication codes
- SNOMED: A comprehensive ontology integrating all the above.
- UMLS: Software system that accesses integrated medical knowledge.
- Use case: Patient encounter example illustrating all standard usages.
- Importance:
  - Insurance claim processing
  - Research and data analysis
- Preview of upcoming detailed discussions on individual standards.

** ICD
- ICD = International Classification of Diseases.
- Developed by WHO, categorizes diseases.
- ICD-9: 17,000+ codes; 3-5 digits; includes main and supplementary categories (e.g., E, V codes).
- ICD-10: 141,000+ codes; 7-character alphanumeric structure.
- Detailed coding for category, etiology, body part, severity, and extension.
- Examples:
  - ICD-9: 250.01 = Type 1 diabetes, no complications
  - ICD-10: M1A.31X2 = Chronic gout with renal impairment in left shoulder, no tophus

** ICD 9 to ICD 10 Mapping
- Mapping is mostly one-to-many due to ICD-10's higher specificity.
- Some mappings are one-to-one (e.g., Tietze's Syndrome).
- Complicated mappings: e.g., ICD-9 code maps to 2,530 ICD-10 codes.
- Complexity highlights the increased detail of ICD-10.

** ICD 9 Quiz Question
- Identifies valid and invalid ICD-9 codes.

** ICD 9 Quiz Solution
- Valid: 501, 802.3, V70, E820.0
- Invalid: U80.1, 5A0.01

** ICD Code Quiz Question
- Task: Find ICD-9 and ICD-10 codes for Influenza.

** ICD Code Quiz Solution
- ICD-9: 487.1
- ICD-10: J11.1

** CPT
- CPT = Current Procedural Terminology (US standard).
- Used for medical, surgical, diagnostic procedures.
- Maintained by the AMA.
- Key in insurance reimbursement.
- Categories:
  - Category 1: Common procedures (e.g., surgery, radiology)
  - Category 2: Quality metrics
  - Category 3: Experimental procedures (e.g., codes ending in T)

** CPT Code Quiz Question
- Task: Find CPT code for detailed office visit.

** CPT Code Quiz Solution
- Office visit range: 99201–99205
- Time-based codes (e.g., 99201 = 10 mins, 99205 = 1 hour)

** LOINC
- LOINC = Logical Observation Identifiers Names and Codes.
- Created by Regenstrief Institute.
- Standard for lab tests and clinical observations.
- Example: 2865-4 = a specific lab test
- Attributes:
  - Component
  - Property
  - Time aspect (e.g., Pt = point in time)
  - Sample type
  - Scale (quantitative, ordinal, etc.)
  - Method

** LOINC Code Quiz Question
- Task: Find LOINC code for Creatinine lab test.

** LOINC Code Quiz Solution
- Answer: 2160-0

** NDC
- NDC = National Drug Code (for medications).
- Maintained by the FDA.
- Structure: 3 segments
  - Labeler code (company)
  - Product code (drug type)
  - Package code (package details)
- Different digit combinations exist but total is 10 digits.

** NDC Code Quiz Question
- Task: Find NDC code for metformin hydrochloride, 500mg.

** NDC Code Quiz Solution
- Example code: 0093-7214-01 (labeler-dependent)

** SNOMED
- SNOMED = Systematized Nomenclature of Medicine.
- Maintained by IHTSDO (Denmark).
- Supports clinical documentation and semantic interoperability.
- National editions and implementation subsets exist.
- Broad user base: clinicians, researchers, analysts.

** Logical Model of SNOMED CT
- Core components:
  - Concepts (with unique ID)
  - Descriptions (FSN and synonyms)
  - Relationships (e.g., “is a”, attributes)

** SNOMED Example
- Example concept: 22298006 = Myocardial infarction disorder
- Multiple descriptions including synonyms
- Preferred vs. acceptable terms are defined by reference sets.

** SNOMED Relationships
- “Is a” relationship creates concept hierarchies.
- Example: Cellulitis of foot “is a” cellulitis, and “is a” disorder of foot.
- Relationships are directional and acyclic.

** SNOMED Design
- 19-level hierarchy of concepts.
- Concepts range from general to highly specific.
- Relationships include “is a” and others with attributes.
- Each concept has a unique ID and descriptions.

** SNOMED Code Quiz Question
- Task: Find SNOMED code for chronic gouty arthritis.

** SNOMED Code Quiz Solution
- Answer: 68451005

** SNOMED Quiz Question
- Question: What is the structure of "is a" relationships in SNOMED?

** SNOMED Quiz Solution
- Answer: Directed acyclic graph (not a tree).

** UMLS
- UMLS = Unified Medical Language System.
- Maintained by US National Library of Medicine.
- Integrates multiple standards into a unified system.
- Components:
  - Metathesaurus
  - Semantic network
  - Specialist lexicon and tools

** Metathesaurus Concepts
- Concept hierarchy:
  - Atom (AUI) → String (SUI) → Term (LUI) → Concept (CUI)
- Multiple ontologies/sources integrated.

** Semantic Network
- 135+ semantic types (e.g., diseases, drugs)
- 54+ semantic relationships (e.g., cause, treat)
- Organizes concepts and their interrelations.

** Specialist Lexicon
- Lexicon of 300,000+ biomedical terms.
- Includes syntax, morphology, orthography.
- Used in NLP tools like MetaMap and MMTx.


* Graph Analysis
** Introduction to Graph Analysis
- Overview of graph analysis and its applications.
- Used in search engines, social networks, and healthcare.
- Identifies clusters of related entities (webpages, patients, conditions).
- Will cover similarity graphs and spectral clustering.

** Agenda
- Two main graph-based algorithms introduced:
  - PageRank: Ranks nodes in a directed graph based on importance.
  - Spectral Clustering: A graph partitioning-based clustering algorithm.

** PageRank
- Developed by Google co-founders for webpage ranking.
- Traditional content-based ranking is prone to spam.
- PageRank relies on the graph structure (links between pages).
- Intuition: More high-quality pages linking to a page → higher rank.
- Represent graph using an adjacency matrix:
  - Normalize matrix rows to represent transition probabilities.
  - PageRank computed using recursion: browsing + teleporting.
  - Browsing redistributes rank via adjacency matrix; teleporting randomly jumps.
  - Equation: `q = cAq + (1 - c)e/N`, where `c` is damping factor (e.g., 0.85).
- Next steps: Implement PageRank using big data systems like Hadoop MapReduce.

** MapReduce  PageRank
- Implementation of PageRank in MapReduce:
  - **Map Phase**:
    - Emit current page and its PageRank.
    - Distribute PageRank to each outgoing link equally.
  - **Reduce Phase**:
    - Aggregate partial PageRanks from map phase.
    - Add teleporting component.
    - Emit updated PageRank.
  - Hadoop shuffles partial sums to reducers.
  - Iterative process: repeat map-reduce steps to converge.

** PageRank Quiz Question
- Quiz: Rank webpages in a directed graph by PageRank (based on structure).

** PageRank Quiz Solution
- Highest: YouTube (3 incoming links).
- Lowest: Google (no incoming links).
- Recursive PageRank shows differences despite similar local structures.
- Amazon > Wikipedia > Facebook in mid-tier due to recursion effects.

** Spectral Clustering
- Spectral Clustering vs Traditional Clustering:
  - Uses similarity graph of patients based on features.
  - Steps:
    1. Construct similarity graph (nodes = patients, edges = similarity).
    2. Convert graph to adjacency matrix.
    3. Compute top-k eigenvectors of the matrix.
    4. Cluster eigenvectors into groups.
  - Effective for high-dimensional or noisy data.

** Similarity Graph Construction
- Several ways to construct similarity graphs:
  - Epsilon-neighborhood.
  - K-nearest neighbors.
  - Fully connected with edge weights (e.g., Gaussian kernel).
- Purpose: capture local similarity between patients.

** E Neighborhood Graph
- Connect nodes within ε distance.
- No edge if distance > ε.
- Defines sparsity based on ε.

** K Nearest Neighbor Graph
- Each node connects to its k-nearest neighbors (directed).
- Results in sparse graphs for small k.
- Variants: binary edges vs weighted edges based on distance.

** Fully Connected Graph
- Every node connected to every other.
- Edge weights determined by similarity (e.g., Gaussian kernel).
- Most dense graph representation.

** E Neighborhood Graph Quiz Question
- Quiz: Select best ε value to reflect clustering structure in 2D patient data.

** E Neighborhood Graph Quiz Solution
- Small ε: too many disconnected clusters.
- Large ε: single cluster.
- Optimal ε (e.g., B or C) reveals natural clusters in data.

** Spectral Clustering Algorithm
- Variations exist:
  - Unnormalized vs Normalized Spectral Clustering.
- Example: simplest uses eigenvectors + k-means.
- Spectral clustering transforms data to eigenspace where clusters are clearer.
- Recommended reading for theoretical underpinnings.

** Big Data Conclusion
- Wrap-up of the video series.
- Presenter: Jimmy Son.
