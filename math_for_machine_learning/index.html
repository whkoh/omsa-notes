<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-07-21 Sun 17:01 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Linear Algebra for Machine Learning (Luis Serrano)</title>
<meta name="author" content="W" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../src/readtheorg_theme/css/readtheorg.css"/>
<script type="text/javascript" src="../src/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="../src/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="../src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Linear Algebra for Machine Learning (Luis Serrano)</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgad6d57c">1. Specialization introduction</a></li>
<li><a href="#org5fd3c82">2. Course introduction</a></li>
<li><a href="#org7d9ff2b">3. Week 1: what to expect and how to succeed</a></li>
<li><a href="#orgbec512f">4. Week 1: Programming experience</a></li>
<li><a href="#org7dd2f87">5. Week 1: Linear Algebra Applied I</a>
<ul>
<li><a href="#org3fe2237">5.1. Systems of linear equations</a>
<ul>
<li><a href="#orgd9b4aa5">5.1.1. Including multiple variables</a></li>
<li><a href="#orgea0d9a0">5.1.2. Real data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgeaf3e45">6. Week 1: Linear Algebra Applied II</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgad6d57c" class="outline-2">
<h2 id="orgad6d57c"><span class="section-number-2">1.</span> Specialization introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
3 courses:
</p>
<ol class="org-ol">
<li>Linear algebra</li>
<li>Calculus</li>
<li>Probability and statistics</li>
</ol>
</div>
</div>
<div id="outline-container-org5fd3c82" class="outline-2">
<h2 id="org5fd3c82"><span class="section-number-2">2.</span> Course introduction</h2>
<div class="outline-text-2" id="text-2">
<p>
4 weeks:
</p>
<ol class="org-ol">
<li>Systems of equations and matrix representation. Singularity, linear independence. Calculate determinant, row operations</li>
<li>Solve 2x2 and 3x3 matrices</li>
<li>Vectors in depth. How matrices transform one vector to another.</li>
<li>Eigenvalues and eigenvectors</li>
</ol>
</div>
</div>
<div id="outline-container-org7d9ff2b" class="outline-2">
<h2 id="org7d9ff2b"><span class="section-number-2">3.</span> Week 1: what to expect and how to succeed</h2>
<div class="outline-text-2" id="text-3">
<p>
Prerequisites:
</p>
<ol class="org-ol">
<li>Solving simple equation with 1 unknown variable</li>
<li>Construct simple plots in coordinate system</li>
</ol>
</div>
</div>
<div id="outline-container-orgbec512f" class="outline-2">
<h2 id="orgbec512f"><span class="section-number-2">4.</span> Week 1: Programming experience</h2>
<div class="outline-text-2" id="text-4">
<p>
Course includes both graded programming assignments and ungraded programming labs.
</p>

<p>
Suggested:
</p>
<ul class="org-ul">
<li>Data types (int, double, bool, string) and data structures (list, dict)</li>
<li>If/else, loops, functions</li>
<li>Importing libraries</li>
<li>Reading, editing and debugging code</li>
<li>Reading documentation</li>
</ul>
</div>
</div>
<div id="outline-container-org7dd2f87" class="outline-2">
<h2 id="org7dd2f87"><span class="section-number-2">5.</span> Week 1: Linear Algebra Applied I</h2>
<div class="outline-text-2" id="text-5">
<p>
Overview:
</p>
<ul class="org-ul">
<li>The 2 representations of linear algebra (geometry and arrays)</li>
<li>Singular vs non-singular systems</li>
<li>Applications of linear algebra in machine learning
<ul class="org-ul">
<li>Linear regression</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org3fe2237" class="outline-3">
<h3 id="org3fe2237"><span class="section-number-3">5.1.</span> Systems of linear equations</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Example: predicting electrical output of wind turbine
</p>
<ul class="org-ul">
<li>Input: wind speed</li>
<li>Output: power generated</li>
</ul>
<p>
Plotting the power output against wind speed.
</p>

<p>
With linear regression, plot the output vs speed and find the line of best fit.
</p>

<p>
Traditionally: \(y=mx + b\), but in machine learning: \(y = wx+b\):
</p>
<ul class="org-ul">
<li>the number multiplied by \(x\) is called the <b>weight</b></li>
<li>the intercept it called the <b>bias</b></li>
</ul>
</div>

<div id="outline-container-orgd9b4aa5" class="outline-4">
<h4 id="orgd9b4aa5"><span class="section-number-4">5.1.1.</span> Including multiple variables</h4>
<div class="outline-text-4" id="text-5-1-1">
<p>
With a second variable e.g. temperature, makes the equation: \(y=w_1 x_1 + w_2 x_2 + b\). This can then be graphed in 3-dimensional space.
</p>

<p>
With multiple variables, just add new weight for each new feature, however, more difficult to graph. However the other math works the same.
</p>

<p>
\(y\) is called the <b>target</b>.
</p>
</div>
</div>

<div id="outline-container-orgea0d9a0" class="outline-4">
<h4 id="orgea0d9a0"><span class="section-number-4">5.1.2.</span> Real data</h4>
<div class="outline-text-4" id="text-5-1-2">
<p>
With real data, observations are numbered and inserted in parenthesis in the equation, e.g.:
</p>

<p>
\[
w_1 x_1^{(1)} + w_2 x_2^{(1)} + ... + w_n x_n^{(1)} + b = y^{(1)}
\]
</p>

<p>
Solve all equations at same time, or as close as possible.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgeaf3e45" class="outline-2">
<h2 id="orgeaf3e45"><span class="section-number-2">6.</span> Week 1: Linear Algebra Applied II</h2>
<div class="outline-text-2" id="text-6">
<p>
Weights and biases are the same across all observations for:
</p>

<p>
\[
w_1 x_1^{(1)} + w_2 x_2^{(1)} + ... + w_n x_n^{(1)} + b = y^{(1)} \\
w_1 x_1^{(2)} + w_2 x_2^{(2)} + ... + w_n x_n^{(2)} + b = y^{(2)} \\
... \\
w_1 x_1^{(n)} + w_2 x_2^{(n)} + ... + w_n x_n^{(n)} + b = y^{(n)} \\
\]
</p>

<p>
Instead of the above representation, this is equivalent for a vector/matrix:
<img src="./img/weights-biases.png" alt="weights-biases.png" />
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: W</p>
<p class="date">Created: 2024-07-21 Sun 17:01</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
