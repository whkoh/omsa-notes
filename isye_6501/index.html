<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-04-03 Mon 19:03 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>ISYE 6501 Intro to Analytics Modeling Notes</title>
<meta name="author" content="W" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/readtheorg.css"/>
<script type="text/javascript" src="src/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="src/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">ISYE 6501 Intro to Analytics Modeling Notes</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgb814d18">1. Module 01: Intro</a>
<ul>
<li><a href="#org7b9a515">1.1. What's analytics?</a></li>
<li><a href="#org8fd08de">1.2. Modeling</a></li>
<li><a href="#org4f5bcfb">1.3. Course structure</a></li>
<li><a href="#orgf7c72a2">1.4. Three different things are all models</a></li>
<li><a href="#org13198f7">1.5. Hence these are all "models":</a></li>
</ul>
</li>
<li><a href="#orgb625efb">2. Module 02: Classification</a>
<ul>
<li><a href="#orgdd9e022">2.1. M1L1: Intro to classification</a></li>
<li><a href="#org793898d">2.2. M1L2: Choosing a Classifier</a>
<ul>
<li><a href="#orge05d56a">2.2.1. Example: Loan payment (Income vs credit score)</a></li>
</ul>
</li>
<li><a href="#org7059515">2.3. M2L3 Data definitions</a>
<ul>
<li><a href="#org2b6d4a8">2.3.1. Data terminology</a></li>
<li><a href="#org25e2e9e">2.3.2. Data types</a></li>
</ul>
</li>
<li><a href="#orgcbd9bf2">2.4. M2L4: Support vector machines</a>
<ul>
<li><a href="#org1771bfa">2.4.1. When not possible to get full separation</a></li>
</ul>
</li>
<li><a href="#orgc494717">2.5. M2L5: What SVM means</a></li>
<li><a href="#org0dcbac3">2.6. M2L6: Advanced SVM</a></li>
<li><a href="#orgc772b31">2.7. M2L7: Scaling and standardization</a>
<ul>
<li><a href="#org1ceab8d">2.7.1. Scaling data</a></li>
<li><a href="#org8ae3754">2.7.2. Standardization of data</a></li>
<li><a href="#orgd1833cb">2.7.3. Choosing between scaling vs standardization</a></li>
</ul>
</li>
<li><a href="#orgd0cdad3">2.8. M2L8: K Nearest Neighbour model (KNN)</a></li>
</ul>
</li>
<li><a href="#orgbe69e24">3. Module 03: Validation</a>
<ul>
<li><a href="#orga740e4b">3.1. M3L1: Training, validation and test data</a></li>
<li><a href="#org3e12d59">3.2. M3L2: Splitting data</a></li>
<li><a href="#orgb356506">3.3. M3L3: Cross-validation</a></li>
<li><a href="#orgcf3daa7">3.4. M3L4: Summary</a></li>
</ul>
</li>
<li><a href="#orga403445">4. Module 04: Clustering</a>
<ul>
<li><a href="#org3d176f5">4.1. M4L1: Introduction to clustering</a></li>
<li><a href="#org27166e9">4.2. M4L2: Distance Norms</a></li>
<li><a href="#org3c75b10">4.3. M4L3: K-Means Clustering</a></li>
<li><a href="#org249c8f9">4.4. M4L4: Practical details for K-Means</a></li>
<li><a href="#orgcfb702c">4.5. M4L5: Clustering for prediction</a></li>
<li><a href="#org37ba751">4.6. M4L6: Clustering vs Classification</a></li>
</ul>
</li>
<li><a href="#orgad6f532">5. Module 05: Data preparation</a>
<ul>
<li><a href="#orgdf80f19">5.1. M5L1: Common techniques and problems</a></li>
<li><a href="#orgb6288cb">5.2. M5L2: Outliers</a></li>
<li><a href="#org52911bd">5.3. M5L3: What to do with outliers?</a>
<ul>
<li><a href="#org3bc50ef">5.3.1. Bad data</a></li>
<li><a href="#org1db0f84">5.3.2. Real / correct data</a></li>
<li><a href="#orgd6dbe37">5.3.3. Another way to handle outliers</a></li>
<li><a href="#org669e072">5.3.4. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org1919c4c">6. Module 06: Change detection</a>
<ul>
<li><a href="#org7e68dd6">6.1. M6L1: Examples</a></li>
<li><a href="#org65a6baa">6.2. M6L2: Cumulative sum for change detection</a>
<ul>
<li><a href="#org231cfa1">6.2.1. Interpretation</a></li>
</ul>
</li>
<li><a href="#org014b0b4">6.3. M6L3: Ethics: Honestly reporting our results</a></li>
</ul>
</li>
<li><a href="#orgdb77bb7">7. Module 07: Time series</a>
<ul>
<li><a href="#org05ec7e6">7.1. M7L1: Introduction to exponential smoothing</a>
<ul>
<li><a href="#org9103ecd">7.1.1. Random variation</a></li>
<li><a href="#orgc77a2a5">7.1.2. Definitions:</a></li>
<li><a href="#orgb12debf">7.1.3. Exponential smoothing method</a></li>
</ul>
</li>
<li><a href="#org587c652">7.2. M7L2: Trend and cyclic effects</a>
<ul>
<li><a href="#org994d601">7.2.1. Trends</a></li>
<li><a href="#orgf3b1bd4">7.2.2. Cyclical patterns</a></li>
<li><a href="#org9a2a424">7.2.3. Summary</a></li>
</ul>
</li>
<li><a href="#org2ce055b">7.3. M7L3: Etymology (what the name means)</a>
<ul>
<li><a href="#org003eccf">7.3.1. Summary</a></li>
</ul>
</li>
<li><a href="#org1379f70">7.4. M7L4: Forecasting</a></li>
<li><a href="#org8e99bba">7.5. M3L5: ARIMA</a>
<ul>
<li><a href="#orgd83d0dd">7.5.1. (I): Differences</a></li>
<li><a href="#orgd66aaff">7.5.2. (II): Autogression</a></li>
<li><a href="#org5e549ed">7.5.3. (III): Moving Average</a></li>
<li><a href="#orgfce0b78">7.5.4. ARIMA model</a></li>
</ul>
</li>
<li><a href="#orga480855">7.6. M7L6: GARCH</a>
<ul>
<li><a href="#org34cc16f">7.6.1. Variance</a></li>
<li><a href="#org6c3c2c0">7.6.2. GARCH</a></li>
<li><a href="#orgda4253e">7.6.3. Summary - three models for time series analysis</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbe69eb7">8. Module 08: Regression</a>
<ul>
<li><a href="#org183421c">8.1. M8L1: Intro to Regression</a>
<ul>
<li><a href="#orgbdaab01">8.1.1. What questions can regression answer?</a></li>
<li><a href="#orgadf32ce">8.1.2. Simple linear regression</a></li>
</ul>
</li>
<li><a href="#org6562e3b">8.2. M8L2: Maximum Likelihood and Information Criteria</a>
<ul>
<li><a href="#orgb471f14">8.2.1. Likelihood</a></li>
<li><a href="#org09d81fb">8.2.2. Maximum likelihood fitting</a></li>
<li><a href="#org1d10ba2">8.2.3. Akaike Information Criterion</a></li>
<li><a href="#org2c0390c">8.2.4. Corrected AIC (AIC<sub>c</sub>)</a></li>
<li><a href="#org80fdeee">8.2.5. AIC<sub>c</sub> example</a></li>
<li><a href="#orgb0e4b12">8.2.6. Bayesian Information Criterion</a></li>
<li><a href="#orgd329fc9">8.2.7. Summary</a></li>
</ul>
</li>
<li><a href="#orge37a077">8.3. M8L3: Using Regression</a>
<ul>
<li><a href="#org1c34b64">8.3.1. Regression coefficients</a></li>
</ul>
</li>
<li><a href="#org673c1b4">8.4. M8L4: Causation vs Correlation</a>
<ul>
<li><a href="#orgd2caf95">8.4.1. Example: winter recreation</a></li>
<li><a href="#orgba37970">8.4.2. Example: tiredness vs scruffiness</a></li>
<li><a href="#org6d922df">8.4.3. How to tell causation?</a></li>
<li><a href="#orgcb891c4">8.4.4. Meaningless correlations</a></li>
</ul>
</li>
<li><a href="#org038e8aa">8.5. M8L5: Transformations and Interactions</a>
<ul>
<li><a href="#orgfa31cc7">8.5.1. Transforming the data</a></li>
<li><a href="#org3a17ee2">8.5.2. Interaction terms, e.g. product of inputs</a></li>
</ul>
</li>
<li><a href="#orgac33e20">8.6. M6L6: Output</a>
<ul>
<li><a href="#org3d704fe">8.6.1. p-Values</a></li>
<li><a href="#orgded4da9">8.6.2. Confidence interval</a></li>
<li><a href="#orga74f9ba">8.6.3. T-statistic</a></li>
<li><a href="#orgf71d1da">8.6.4. Coefficient itself</a></li>
<li><a href="#org3bacaae">8.6.5. \(R^2\)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgd129a60">9. Module 09: Advanced Data Preparation</a>
<ul>
<li><a href="#org67e7a95">9.1. M9L1: Box-Cox Transformations</a></li>
<li><a href="#orgf78ed40">9.2. M9L2: Detrending</a></li>
<li><a href="#orga3af405">9.3. M9L3: Intro to PCA</a></li>
<li><a href="#orgd372985">9.4. M9L4: Using PCA</a>
<ul>
<li><a href="#org0d84804">9.4.1. Math of PCA</a></li>
<li><a href="#orgf4eef86">9.4.2. PCA as linear combination</a></li>
<li><a href="#orge7c3ae8">9.4.3. PCA for regression</a></li>
<li><a href="#org0d9f7c4">9.4.4. Summary of PCA</a></li>
</ul>
</li>
<li><a href="#org9739cbe">9.5. M9L5: Eigenvalues and Eigenvectors</a>
<ul>
<li><a href="#orgb8f24ea">9.5.1. Initial example</a></li>
<li><a href="#orga5161f3">9.5.2. Important: know how eigenvalues and eigenvectors are important to PCA</a></li>
</ul>
</li>
<li><a href="#org0d311b2">9.6. M9L6: PCA: The good and the bad</a>
<ul>
<li><a href="#orgae599ee">9.6.1. Example where PCA is good</a></li>
<li><a href="#org265a43e">9.6.2. Example where PCA is bad</a></li>
<li><a href="#org7dee3b1">9.6.3. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgd42817e">10. Module 10: Advanced Regression</a>
<ul>
<li><a href="#org222e62e">10.1. M10L01: Introduction to CART</a>
<ul>
<li><a href="#org0aaa354">10.1.1. Trees in regression</a></li>
<li><a href="#orgc6255e0">10.1.2. Recall</a></li>
<li><a href="#org0f1c6b9">10.1.3. What if responses can be differentiated by a factor?</a></li>
<li><a href="#org2b2dab1">10.1.4. Further splits are possible</a></li>
<li><a href="#orgf8790d8">10.1.5. Disadvantages</a></li>
<li><a href="#org37110b5">10.1.6. Other places to use trees</a></li>
<li><a href="#org3286d1b">10.1.7. Common questions</a></li>
<li><a href="#orga410547">10.1.8. Etymology of "tree"</a></li>
</ul>
</li>
<li><a href="#org16611f9">10.2. M10L02: Branching</a>
<ul>
<li><a href="#orgcb28f82">10.2.1. Main questions</a></li>
<li><a href="#org7d93d36">10.2.2. Branching methods</a></li>
<li><a href="#org1147274">10.2.3. Generic branching concept</a></li>
</ul>
</li>
<li><a href="#orgbfb7899">10.3. M10L03: Random Forests</a>
<ul>
<li><a href="#org2867fb5">10.3.1. Intro summary</a></li>
<li><a href="#org26b9537">10.3.2. Introducing randomness</a></li>
<li><a href="#orge2b074e">10.3.3. Note</a></li>
<li><a href="#orgf0ddbe9">10.3.4. Summary of RF</a></li>
</ul>
</li>
<li><a href="#org69b5264">10.4. M10L04: Explainability and Interpretability</a>
<ul>
<li><a href="#orgd52a1e9">10.4.1. Example: linear regression</a></li>
<li><a href="#orgb65eb84">10.4.2. Example: regression tree</a></li>
<li><a href="#org91325d7">10.4.3. Example: random forests</a></li>
<li><a href="#orgfc1e170">10.4.4. Comparisons</a></li>
<li><a href="#orgb3c8500">10.4.5. Tradeoff</a></li>
</ul>
</li>
<li><a href="#org385b00a">10.5. M10L05: Confusion Matrices</a>
<ul>
<li><a href="#orge613d0b">10.5.1. Details</a></li>
<li><a href="#org4e9b44c">10.5.2. Definitions</a></li>
</ul>
</li>
<li><a href="#orgc30b608">10.6. M10L06: Situationally-Driven Comparisons</a>
<ul>
<li><a href="#org0c14cbc">10.6.1. Example: from spam detection</a></li>
<li><a href="#org962b737">10.6.2. Evaluating quality / changing metrics</a></li>
</ul>
</li>
<li><a href="#org7fa14eb">10.7. L10L07: Advanced Topics in Regression</a>
<ul>
<li><a href="#org8e355df">10.7.1. Poisson regression</a></li>
<li><a href="#orge63fd73">10.7.2. Regression splines</a></li>
<li><a href="#orga74535c">10.7.3. Bayesian regression</a></li>
<li><a href="#org78cb665">10.7.4. k-Nearest Neighbour Regression</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org82af719">11. Module 11: Variable Selection</a>
<ul>
<li><a href="#org76ac404">11.1. M11L1: Introduction</a>
<ul>
<li><a href="#orgcd57ed0">11.1.1. Why bother limiting factors?</a></li>
</ul>
</li>
<li><a href="#orgda78e57">11.2. M11L2: Models for variable selection</a>
<ul>
<li><a href="#org8024cd9">11.2.1. Forward selection</a></li>
<li><a href="#orgf7ede56">11.2.2. Backward elimination</a></li>
<li><a href="#org34f5a56">11.2.3. Stepwise regression</a></li>
<li><a href="#org788873e">11.2.4. Types of approaches</a></li>
<li><a href="#orgbbc3570">11.2.5. Lasso approach</a></li>
<li><a href="#org8a6ddbd">11.2.6. Elastic net</a></li>
<li><a href="#org48d0f8a">11.2.7. Ridge regression</a></li>
</ul>
</li>
<li><a href="#org954408a">11.3. M11L3: Lasso vs Ridge regression</a>
<ul>
<li><a href="#org5e86982">11.3.1. The key difference</a></li>
</ul>
</li>
<li><a href="#org0895e45">11.4. M11L4: Bias-Variance tradeoff</a>
<ul>
<li><a href="#org48a0ff5">11.4.1. Fit and real vs random patterns</a></li>
<li><a href="#orgc526d8c">11.4.2. Summary</a></li>
</ul>
</li>
<li><a href="#orgbeb77ba">11.5. M11L5: Ridge regression / regularization</a>
<ul>
<li><a href="#org5210856">11.5.1. Ridge regression</a></li>
<li><a href="#orge1085a9">11.5.2. Coefficients -&gt; magnitude of effect</a></li>
<li><a href="#org10232e5">11.5.3. Ridge regression limits the magnitude of the regression coefficient instead of the number of variables</a></li>
</ul>
</li>
<li><a href="#org8e52124">11.6. M11L6: Choosing a variable selection model</a>
<ul>
<li><a href="#orgd931a66">11.6.1. Lasso vs ridge vs elastic net</a></li>
<li><a href="#orgee33a05">11.6.2. Elastic net</a></li>
<li><a href="#org6b3df15">11.6.3. Which one to use?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org7cc922d">12. Module 12: Design of Experiments</a>
<ul>
<li><a href="#org58f5662">12.1. M12L1: Intro</a>
<ul>
<li><a href="#orgbceebc4">12.1.1. Comparison and control</a></li>
<li><a href="#org91bed8c">12.1.2. Blocking</a></li>
</ul>
</li>
<li><a href="#org9565636">12.2. M12L2: A/B testing</a>
<ul>
<li><a href="#orgb03e29d">12.2.1. Required to use A/B testing</a></li>
</ul>
</li>
<li><a href="#org083fdc1">12.3. M12L3: Factorial design</a>
<ul>
<li><a href="#org75d4964">12.3.1. Full factorial design</a></li>
<li><a href="#orgfa67a79">12.3.2. Fractional factorial design</a></li>
<li><a href="#org53564cd">12.3.3. Independent factors</a></li>
<li><a href="#org533f4cf">12.3.4. Summary</a></li>
</ul>
</li>
<li><a href="#org7a6aa76">12.4. M12L4: Multi-armed bandits</a>
<ul>
<li><a href="#org8328d4e">12.4.1. Exploration vs exploitation</a></li>
<li><a href="#org2cbb5f3">12.4.2. Multi-armed bandit</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org50e483f">13. Module 13: Probability-based Models</a>
<ul>
<li><a href="#orgcc2b6b1">13.1. M13L1: Intro</a>
<ul>
<li><a href="#orgefe67f9">13.1.1. Simple modelling</a></li>
<li><a href="#org5fa9e77">13.1.2. Example on ticket owner not showing up</a></li>
<li><a href="#org9583824">13.1.3. Summary</a></li>
</ul>
</li>
<li><a href="#org5fe2cef">13.2. M13L2: Bernoulli, Binomial and Geometric Distributions</a>
<ul>
<li><a href="#org023a15a">13.2.1. Bernoulli distribution</a></li>
<li><a href="#org94e3c60">13.2.2. Binomial distribution</a></li>
<li><a href="#org6615dc3">13.2.3. Geometric distribution</a></li>
</ul>
</li>
<li><a href="#org923bfb6">13.3. M13L3: Poisson, Weibull and Exponential Distributions</a>
<ul>
<li><a href="#orgdbc0857">13.3.1. Poisson</a></li>
<li><a href="#org0c93daa">13.3.2. Exponential distribution</a></li>
<li><a href="#org3aa1a3f">13.3.3. Weibull</a></li>
<li><a href="#orgdb7f076">13.3.4. Software can help but may be confusing</a></li>
</ul>
</li>
<li><a href="#org5b5f231">13.4. M13L4: Q-Q plots</a>
<ul>
<li><a href="#orgaa6c9d9">13.4.1. Visualizing</a></li>
<li><a href="#org5c12e82">13.4.2. Types of Q-Q plots</a></li>
</ul>
</li>
<li><a href="#org1cbf477">13.5. M13L5: Queuing</a>
<ul>
<li><a href="#org654c258">13.5.1. Queuing example</a></li>
<li><a href="#orgb84f60f">13.5.2. More complex example</a></li>
<li><a href="#org904873d">13.5.3. Queuing models</a></li>
</ul>
</li>
<li><a href="#org3a07c75">13.6. M13L6: Simulation basics</a>
<ul>
<li><a href="#org05b14d1">13.6.1. Types of simulations</a></li>
<li><a href="#org2c453ce">13.6.2. Discrete-event stochastic simulations</a></li>
<li><a href="#org773465c">13.6.3. Simulation software</a></li>
<li><a href="#orgda8ae8c">13.6.4. Replications</a></li>
<li><a href="#orgbf8741a">13.6.5. Simulation validation</a></li>
</ul>
</li>
<li><a href="#org10e247c">13.7. M13L7: Prescriptive simulation</a>
<ul>
<li><a href="#org392c6ab">13.7.1. Simulation comparisons</a></li>
<li><a href="#orgda3ca58">13.7.2. Validation can be hard</a></li>
<li><a href="#org0ab326e">13.7.3. Simulation/validation should consider all processes</a></li>
</ul>
</li>
<li><a href="#orgb0eda6f">13.8. M13L8: Markov chains</a>
<ul>
<li><a href="#orge2157f1">13.8.1. Answering questions with the transition matrix</a></li>
<li><a href="#org73f76ad">13.8.2. Key assumption</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org69eb982">14. Module 14: Missing Data</a>
<ul>
<li><a href="#orgf349244">14.1. M14L01: Intro to missing data</a>
<ul>
<li><a href="#orga420d23">14.1.1. When is there missing data?</a></li>
<li><a href="#orgf699bce">14.1.2. Data problems</a></li>
<li><a href="#orgf289d5c">14.1.3. Patterns in missing data</a></li>
</ul>
</li>
<li><a href="#org034a0f7">14.2. M14L02: Methods not requiring imputation</a>
<ul>
<li><a href="#org9932aeb">14.2.1. Dealing with missing data</a></li>
<li><a href="#org63042aa">14.2.2. Discard records</a></li>
<li><a href="#org36e6c8d">14.2.3. Categorical variable approach</a></li>
<li><a href="#orgb89d67a">14.2.4. Summary</a></li>
</ul>
</li>
<li><a href="#org46a865b">14.3. M14L03: Imputation methods</a>
<ul>
<li><a href="#orge8008b2">14.3.1. Mid-range value</a></li>
<li><a href="#orgafbd343">14.3.2. Regression</a></li>
<li><a href="#org7cceeba">14.3.3. Regression with perturbation (imputation with variability)</a></li>
<li><a href="#org4471080">14.3.4. Imputation approaches</a></li>
<li><a href="#org4ef72ac">14.3.5. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org4747747">15. Module 15: Optimization</a>
<ul>
<li><a href="#org191020e">15.1. M15L01: Intro to Optimization</a>
<ul>
<li><a href="#orga689a52">15.1.1. Examples</a></li>
<li><a href="#org22ab7c4">15.1.2. Optimization provides direction for an organization</a></li>
<li><a href="#orgf556079">15.1.3. Optimization software</a></li>
</ul>
</li>
<li><a href="#orgf1efcf6">15.2. M15L02: Elements of Optimization Models</a></li>
<li><a href="#orgf33236a">15.3. M15L03: Optimization is an art</a>
<ul>
<li><a href="#org51de984">15.3.1. Examples</a></li>
</ul>
</li>
<li><a href="#org440d8bb">15.4. M15L04: Modeling with binary variables</a>
<ul>
<li><a href="#orgbce793b">15.4.1. Example: stock market investment</a></li>
<li><a href="#orgce9e97d">15.4.2. Recap uses of integer variables in optimization</a></li>
</ul>
</li>
<li><a href="#orge1c5584">15.5. M15L05: Discovering the real questions</a>
<ul>
<li><a href="#org362d812">15.5.1. Real life</a></li>
<li><a href="#org94fc2b2">15.5.2. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org520a1b1">16. Module 16: Advanced Models</a>
<ul>
<li><a href="#org5ab56af">16.1. M16L01: Non-parametric methods</a>
<ul>
<li><a href="#org318dc49">16.1.1. Non-parametric tests: Statistics tests when the distribution is unknown</a></li>
<li><a href="#org167948c">16.1.2. McNemar's test is paired</a></li>
<li><a href="#org77de03c">16.1.3. Wilcoxon Signed Rank Test for Medians</a></li>
<li><a href="#org9771474">16.1.4. Mann-Whitney test</a></li>
<li><a href="#orga22ed5c">16.1.5. Summary from video</a></li>
</ul>
</li>
<li><a href="#org4de77c2">16.2. M16L01a: Matching tests for situations</a>
<ul>
<li><a href="#org6a6b727">16.2.1. Summary</a></li>
<li><a href="#org695c947">16.2.2. Summary from lecture</a></li>
</ul>
</li>
<li><a href="#org068a2d2">16.3. M16L02: Bayesian modeling</a>
<ul>
<li><a href="#org2b985bd">16.3.1. Bayesian models</a></li>
<li><a href="#org9705022">16.3.2. Empirical Bayes modeling</a></li>
<li><a href="#orgbad2dd9">16.3.3. Lecture summary</a></li>
</ul>
</li>
<li><a href="#org964fc1a">16.4. M16L03: Communities in graphs</a>
<ul>
<li><a href="#org8fb54a0">16.4.1. Transcript summary</a></li>
<li><a href="#orgbeb67a7">16.4.2. Uses</a></li>
<li><a href="#org30acc15">16.4.3. Specifically</a></li>
<li><a href="#orgbb31261">16.4.4. Definitions</a></li>
<li><a href="#orga85dc29">16.4.5. Louvain algorithm</a></li>
<li><a href="#org8f73ea8">16.4.6. Lecture summary</a></li>
</ul>
</li>
<li><a href="#org5dadb2e">16.5. M16L04: Neural networks and deep learning</a>
<ul>
<li><a href="#orgcff567e">16.5.1. Transcript summary</a></li>
<li><a href="#org8ed86a0">16.5.2. Reacting to patterns that we don't understand</a></li>
<li><a href="#org8ab89f8">16.5.3. Neural networks</a></li>
<li><a href="#org0686af7">16.5.4. Deep learning</a></li>
</ul>
</li>
<li><a href="#orgf218af4">16.6. M16L05: Competitive models</a>
<ul>
<li><a href="#org18e0177">16.6.1. Summary</a></li>
<li><a href="#orgfa1dc43">16.6.2. Us against data?</a></li>
<li><a href="#org6295ff3">16.6.3. Examples:</a></li>
<li><a href="#org80ea7d7">16.6.4. Game theory</a></li>
<li><a href="#org72f78b9">16.6.5. Timing</a></li>
<li><a href="#orgb49fc2d">16.6.6. Types of strategy</a></li>
<li><a href="#org008e9f9">16.6.7. Information levels</a></li>
<li><a href="#orgfc8c564">16.6.8. Zero-sum vs non-zero-sum games</a></li>
<li><a href="#org9553f95">16.6.9. Lecture summary</a></li>
</ul>
</li>
<li><a href="#org68b62b4">16.7. M16L05a: Competitive model demo</a>
<ul>
<li><a href="#orgf713673">16.7.1. Summary</a></li>
<li><a href="#org5118034">16.7.2. Stable equilibrium</a></li>
<li><a href="#orge38b441">16.7.3. Extension of example</a></li>
</ul>
</li>
<li><a href="#org5992e21">16.8. M16L06: Natural language processing</a>
<ul>
<li><a href="#orgbec5c66">16.8.1. Summary</a></li>
<li><a href="#orgb52efb6">16.8.2. When?</a></li>
<li><a href="#org4638c48">16.8.3. Why hard?</a></li>
<li><a href="#org37f67a2">16.8.4. Natural language processing</a></li>
</ul>
</li>
<li><a href="#orge315799">16.9. M16L07: Survival models</a>
<ul>
<li><a href="#orgbcdd98f">16.9.1. Summary</a></li>
<li><a href="#orgf6e4ee3">16.9.2. What are survival models?</a></li>
<li><a href="#orga90317f">16.9.3. Uses of survival models</a></li>
<li><a href="#orgc20e015">16.9.4. Cox proportional hazard model</a></li>
<li><a href="#org5fa7c26">16.9.5. Data&#x2026;</a></li>
</ul>
</li>
<li><a href="#org874d840">16.10. M16L08: Gradient boosting</a>
<ul>
<li><a href="#org2a665e3">16.10.1. Summary</a></li>
<li><a href="#org54c3a10">16.10.2. Computing topic, i.e.</a></li>
<li><a href="#org852045f">16.10.3. Basic idea</a></li>
<li><a href="#org0e4a4b6">16.10.4. In detail</a></li>
</ul>
</li>
<li><a href="#orgf6ec558">16.11. M16L08a: Gradient boosting example</a>
<ul>
<li><a href="#orga15acd2">16.11.1. Summary</a></li>
<li><a href="#org0322a52">16.11.2. Detailed steps</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgb814d18" class="outline-2">
<h2 id="orgb814d18"><span class="section-number-2">1.</span> Module 01: Intro</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org7b9a515" class="outline-3">
<h3 id="org7b9a515"><span class="section-number-3">1.1.</span> What's analytics?</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Analytics answers these questions
</p>
<ol class="org-ol">
<li>Descriptive - what happened</li>
<li>Predictive - what will happen</li>
<li>Prescriptive - what action is best</li>
<li>General questions</li>
</ol>
</div>
</div>
<div id="outline-container-org8fd08de" class="outline-3">
<h3 id="org8fd08de"><span class="section-number-3">1.2.</span> Modeling</h3>
<div class="outline-text-3" id="text-1-2">
<ol class="org-ol">
<li>Describe real-life situation with math</li>
<li>Analyze math</li>
<li>Turn math answer back to real situation</li>
</ol>
</div>
</div>
<div id="outline-container-org4f5bcfb" class="outline-3">
<h3 id="org4f5bcfb"><span class="section-number-3">1.3.</span> Course structure</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Enough math intuition and detail
</p>
<ul class="org-ul">
<li>Models
<ul class="org-ul">
<li>Machine learning</li>
<li>Regression</li>
<li>Optimizaton</li>
</ul></li>
<li>Cross-cutting
<ul class="org-ul">
<li>Data prep</li>
<li>Output quality</li>
<li>Missing data</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf7c72a2" class="outline-3">
<h3 id="orgf7c72a2"><span class="section-number-3">1.4.</span> Three different things are all models</h3>
<div class="outline-text-3" id="text-1-4">
<ol class="org-ol">
<li>Real life situation expressed as math</li>
<li>Analyse the math</li>
<li>Turn mathematical analyse to real-life solution</li>
</ol>
</div>
</div>
<div id="outline-container-org13198f7" class="outline-3">
<h3 id="org13198f7"><span class="section-number-3">1.5.</span> Hence these are all "models":</h3>
<div class="outline-text-3" id="text-1-5">
<ol class="org-ol">
<li>Regression</li>
<li>Regression on size, weight, distance</li>
<li>Regression estimate = 37+81*Size +76*Wt, etc</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgb625efb" class="outline-2">
<h2 id="orgb625efb"><span class="section-number-2">2.</span> Module 02: Classification</h2>
<div class="outline-text-2" id="text-2">
<blockquote>
<p>
Definition: putting things into groups
</p>
</blockquote>
</div>
<div id="outline-container-orgdd9e022" class="outline-3">
<h3 id="orgdd9e022"><span class="section-number-3">2.1.</span> M1L1: Intro to classification</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Types of classification models
</p>
<ol class="org-ol">
<li>Number of groups</li>
<li>Number of dimensions
<ul class="org-ul">
<li>Can 1 dimension be sufficient to classify?</li>
</ul></li>
<li>Soft vs hard classifiers (is it 100% error-free?)</li>
</ol>
</div>
</div>
<div id="outline-container-org793898d" class="outline-3">
<h3 id="org793898d"><span class="section-number-3">2.2.</span> M1L2: Choosing a Classifier</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Definition of bad classification
</p>
<ul class="org-ul">
<li>Cost: is one type of mistake worse than the other?</li>
</ul>
</div>
<div id="outline-container-orge05d56a" class="outline-4">
<h4 id="orge05d56a"><span class="section-number-4">2.2.1.</span> Example: Loan payment (Income vs credit score)</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>Plot lines and find one that can separate default vs non-default.</li>
<li>How do we know the right lines are drawn?</li>
<li>We want to be as conservative as possible (less error prone)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7059515" class="outline-3">
<h3 id="org7059515"><span class="section-number-3">2.3.</span> M2L3 Data definitions</h3>
<div class="outline-text-3" id="text-2-3">
</div>
<div id="outline-container-org2b6d4a8" class="outline-4">
<h4 id="org2b6d4a8"><span class="section-number-4">2.3.1.</span> Data terminology</h4>
<div class="outline-text-4" id="text-2-3-1">
<ol class="org-ol">
<li>Row = data point</li>
<li>Column = dimension, attribute, feature, predictor, covariate
<ol class="org-ol">
<li>Special column = response, outcome</li>
</ol></li>
</ol>
</div>
</div>
<div id="outline-container-org25e2e9e" class="outline-4">
<h4 id="org25e2e9e"><span class="section-number-4">2.3.2.</span> Data types</h4>
<div class="outline-text-4" id="text-2-3-2">
<ol class="org-ol">
<li>Structured data
<ol class="org-ol">
<li>Quantitative
<ul class="org-ul">
<li>Numbers with meaning</li>
</ul></li>
<li>Categorical
<ul class="org-ul">
<li>Numbers without meaning</li>
</ul></li>
<li>Binary data (subset of categorical)</li>
<li>Unrelated data</li>
<li>Time series data</li>
</ol></li>
<li>Unstructured
<ol class="org-ol">
<li>Text data</li>
</ol></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgcbd9bf2" class="outline-3">
<h3 id="orgcbd9bf2"><span class="section-number-3">2.4.</span> M2L4: Support vector machines</h3>
<div class="outline-text-3" id="text-2-4">
<ul class="org-ul">
<li><b>Supervised</b> method (algorithm uses known results when training)</li>
<li>Terminology
<ul class="org-ul">
<li>m = number of data points</li>
<li>n = number of attributes</li>
<li>x<sub>ij</sub> = j attribute of i data point
<ul class="org-ul">
<li>e.g. x<sub>51</sub> = credit score of person 5; x<sub>52</sub> = income of person 5</li>
</ul></li>
<li>y<sub>i</sub> = response of data point i
<ul class="org-ul">
<li>e.g. 1 if data point is group 1</li>
<li>-1 if data point is group 2</li>
</ul></li>
<li>Line: \(a_1 x_1\) + \(a_2 x_2\) + &#x2026; + \(a_n x_n\) + \(a_0\) = 0</li>
<li>Note the intercept \(a_0\)</li>
</ul></li>
<li>In general: \(\sum_{j=1}^{n} a_j x_j + a_0 = 0\)</li>
<li>Separation problem: get max distance between lines</li>
<li>\(2\over{\sqrt(\sum_{j} \left(a_j\right)^2)}\)</li>
<li>i.e. Min<sub>a<sub>0</sub> &#x2026; a<sub>n</sub></sub>: \(\sum_{j=1}^{n}\left(a_j\right)^2\)</li>
<li>Subject to constraints</li>
</ul>
</div>
<div id="outline-container-org1771bfa" class="outline-4">
<h4 id="org1771bfa"><span class="section-number-4">2.4.1.</span> When not possible to get full separation</h4>
<div class="outline-text-4" id="text-2-4-1">
<ul class="org-ul">
<li>Then we minimize error</li>
<li>There's a trade-off between margin and error</li>
<li>Error for data point is:
\[
  \text{max} \{ 0, 1-(\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}
  \]</li>
<li>Total error is:
\[
  \sum_{i=1}^{m} \text{max} \{ 0, 1 - (\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}
  \]</li>
<li>Margin denominator: \(\sum_{j=1}^{n}(a_j)^2\)</li>

<li>We multiply margin by \(\lambda\) to <b>assign its importance of margin vs error</b>.</li>
<li>Hence, the full equation is:
\[
  \text{Minimize}_{a_0,...,a_n} \sum_{i=1}^{m} \text{max} \{ 0, 1 - (\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}  + \lambda \sum_{j=1}^{n}(a_j)^2
  \]</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc494717" class="outline-3">
<h3 id="orgc494717"><span class="section-number-3">2.5.</span> M2L5: What SVM means</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li>Etymology
<ul class="org-ul">
<li>Vector = point</li>
<li><b>Support vector</b> = points that holds up (or, supports) a shape. Shape is correctly balanced on parallel lines</li>
<li>Model determines the "support vectors"</li>
<li>Automatically from data hence "<b>machine</b>"</li>
</ul></li>
<li>Support can be from top or side</li>
<li>Looking for max separation i.e. the support vector touches the data points</li>
<li>Classifier is in between the two support vectors</li>
</ul>
</div>
</div>
<div id="outline-container-org0dcbac3" class="outline-3">
<h3 id="org0dcbac3"><span class="section-number-3">2.6.</span> M2L6: Advanced SVM</h3>
<div class="outline-text-3" id="text-2-6">
<ul class="org-ul">
<li>The constant term a<sub>0</sub> can be used to adjust the intercept and hence tweak the SVM model.
<ul class="org-ul">
<li>If it's more costly to grant a bad loan, e.g.: \(\frac{2}{3}(a_0-1) + \frac{1}{3}(a_0+1)\)</li>
</ul></li>
<li>For soft classification, you can add a multiplier m<sub>j</sub> for each type of error:
<ul class="org-ul">
<li>m<sub>j</sub> &gt; 1 for more costly</li>
<li>m<sub>j</sub> &lt; 1 for less costly</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc772b31" class="outline-3">
<h3 id="orgc772b31"><span class="section-number-3">2.7.</span> M2L7: Scaling and standardization</h3>
<div class="outline-text-3" id="text-2-7">
<ul class="org-ul">
<li>Predictive factors may have different orders of magnitude, i.e.
<ul class="org-ul">
<li>Income in \(10^5\)</li>
<li>Credit score in \(10^2\)</li>
<li>Classifier is \(0 = a_0 + \sum_{j} a_j x_j\)</li>
<li>Maximise gap by minimizing: \(\sum_{j} a_j^2\)</li>
<li>Coefficients might be 10<sup>6</sup> + 5*income + 701*credit score
<ul class="org-ul">
<li>Sum of squared coefficients:
\(\sum_j a_j^2 = 5^2 + 700^2 = 490,025\)</li>
<li>Changing credit score by 1 increases the sum by 1,401:
\(\sum_j a_j^2 = 5^2 + 701^2 = 491,426\)</li>
</ul></li>
<li>Small change in one coefficient affects the sum a lot due to difference in scales.
<ul class="org-ul">
<li>As data has such different scale.</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="outline-container-org1ceab8d" class="outline-4">
<h4 id="org1ceab8d"><span class="section-number-4">2.7.1.</span> Scaling data</h4>
<div class="outline-text-4" id="text-2-7-1">
<ul class="org-ul">
<li>Common scale is between 0 and 1</li>
<li>Scale data by factor
\[
  x_{ij}^{\text{scaled}} = \frac{x_{ij}-x_{\text{min}j}}{x_{\text{max}j} - x_{\text{min}j}}
  \]</li>
<li>General scaling between a, b:
\[
  x_{ij}^{\text{scaled}[b,a]} = x_{ij}^{\text{scaled}[0,1]}(a-b)+b
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-org8ae3754" class="outline-4">
<h4 id="org8ae3754"><span class="section-number-4">2.7.2.</span> Standardization of data</h4>
<div class="outline-text-4" id="text-2-7-2">
<ul class="org-ul">
<li>Scale to normal distribution</li>
<li>Common scale is:
<ul class="org-ul">
<li>Mean = 0</li>
<li>SD = 1</li>
</ul></li>
<li>Factor j has:
<ul class="org-ul">
<li>mean \(\mu_j = \frac{\sum_{i=1}^n x_{ij}}{n}\)</li>
<li>SD \(\sigma_j\)</li>
</ul></li>
<li>For each data point \(i\):
\[
  x_{ij}^{\text{standardized}} = \frac{x_{ij}-\mu_j}{\sigma_j}
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-orgd1833cb" class="outline-4">
<h4 id="orgd1833cb"><span class="section-number-4">2.7.3.</span> Choosing between scaling vs standardization</h4>
<div class="outline-text-4" id="text-2-7-3">
<ul class="org-ul">
<li>Scale when:
<ul class="org-ul">
<li>Data is in bounded (defined) range, e.g.
<ul class="org-ul">
<li>Neural networks</li>
<li>Optimization models requiring bounded data</li>
<li>Batting averages (between 0 and 1)</li>
<li>RGB color scale (0-255)</li>
<li>SAT scores (200-800)</li>
</ul></li>
</ul></li>
<li>Standardization, examples:
<ul class="org-ul">
<li>PCA</li>
<li>Clustering</li>
</ul></li>
<li>Try both when not clear</li>
<li>Should be used throughout course even when not stated explicitly</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd0cdad3" class="outline-3">
<h3 id="orgd0cdad3"><span class="section-number-3">2.8.</span> M2L8: K Nearest Neighbour model (KNN)</h3>
<div class="outline-text-3" id="text-2-8">
<ul class="org-ul">
<li><b>Classification</b></li>
<li>e.g. loan dataset with two predictors and a response</li>
<li>Assume each point has similar characteristics with its neighbors</li>
<li>Choice of number of points is denoted by \(k\)</li>
<li>Algorithm to find color (class) of a new point:
<ol class="org-ol">
<li>Pick \(k\) closest points (i.e., nearest neighbours) to the new one</li>
<li>The new point's class is the most common among the \(k\) neighbors</li>
</ol></li>
<li>Complexities
<ul class="org-ul">
<li>More than one distance metric (<i>c.f.</i> distance selection topic_).
<ul class="org-ul">
<li>Straight line is: \(\sqrt{\sum_{i=1}^n |x_i-y_i|^2}\)</li>
</ul></li>
<li>Attributes can be given more weight if more important, \(w_i\)
<ul class="org-ul">
<li>Weights to be found with other techniques e.g. regression</li>
</ul></li>
<li>Unimportant metrics can be removed
<ul class="org-ul">
<li><i>c.f.</i> variable selection topic</li>
<li>Choose good value of \(k\), <i>c.f.</i> validation @ <a href="#orgbe69e24">3</a></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgbe69e24" class="outline-2">
<h2 id="orgbe69e24"><span class="section-number-2">3.</span> Module 03: Validation</h2>
<div class="outline-text-2" id="text-3">
<blockquote>
<p>
Check how good a model is
</p>
</blockquote>
</div>
<div id="outline-container-orga740e4b" class="outline-3">
<h3 id="orga740e4b"><span class="section-number-3">3.1.</span> M3L1: Training, validation and test data</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li><b>Cannot</b> calculate accuracy or effectiveness metrics from training dataset
<ul class="org-ul">
<li>Since model was trained on it</li>
<li>This doesn't allow separation of real effects from random effects</li>
</ul></li>
<li>When fitting a model, this captures both real and random effects
<ul class="org-ul">
<li>Real effects: exist in all datasets (or subsets)</li>
<li>Random effects: different in all datasets</li>
</ul></li>
<li>Use a <b>training</b> set of data to fit model</li>
<li>Use another <b>validation</b> set of data to judge model effectiveness</li>
<li>When comparing &gt;1 model, use a <b>test</b> dataset.
<ul class="org-ul">
<li>e.g. SVM and KNN, with 10 total models, we cannot use the effectiveness metric calculated on the validation set.</li>
</ul></li>
<li>Test data is required as high performing models have above average random effects
<ul class="org-ul">
<li>Too optimistic; it might have performed well but also likely received a boost from random effects</li>
</ul></li>
<li>Analogize with models equally good</li>
<li>Flowchart:
<img src="./img/validation01.png" alt="validation01.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-org3e12d59" class="outline-3">
<h3 id="org3e12d59"><span class="section-number-3">3.2.</span> M3L2: Splitting data</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>How much data goes to each set?
<ol class="org-ol">
<li>70 to 90% train, remaining test</li>
<li>50 to 70% train, remaining evenly split validation &amp; test</li>
</ol></li>
<li>Methods of splitting data
<ol class="org-ol">
<li>Random</li>
<li>Rotation (take turn selecting data points into training, test, valid across the sets of split data)
<ul class="org-ul">
<li>Advantage: in time series data, may avoid all datasets having early/late data</li>
<li>Need to ensure rotation doesn't introduce bias</li>
</ul></li>
<li>Combined:
60% of Monday data for training, 60^% of Tuesday data for training, etc.</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-orgb356506" class="outline-3">
<h3 id="orgb356506"><span class="section-number-3">3.3.</span> M3L3: Cross-validation</h3>
<div class="outline-text-3" id="text-3-3">
<blockquote>
<p>
What happens with important data appears only in one data set e.g., validation?
</p>
</blockquote>
<ul class="org-ul">
<li>Use cross-validation!</li>
<li>k-fold cross validation
<ol class="org-ol">
<li>Split data for testing (e.g. 20%)</li>
<li>With remaining data, use it for both training and validation by splitting into 4 x 20%, then:
<ol class="org-ol">
<li>Train 1, 2, 3, Validate 4</li>
<li>Train 1, 2, 4, Validate 3</li>
<li>Train 1, 3, 4, Validate 2</li>
<li>Train 2, 3, 4, Validate 1</li>
</ol></li>
</ol></li>
<li>Summary of k-fold cross-validation:
<ul class="org-ul">
<li>Train model on all other parts</li>
<li>Evaluate model on remaining part</li>
<li>Average \(k\) evaluations to estimate the model quality.</li>
<li>\(10\) is commonly selected for \(k\).</li>
<li><b>But</b>, the model selected from cross-validation is not used. Coefficients should also not be averaged.</li>
<li>Once model is selected, <b>retrain</b> with all data</li>
</ul></li>
<li>Advantages of k-fold cross-validation:
<ol class="org-ol">
<li>Better uses data</li>
<li>Better estimates model quality</li>
<li>Choose model more effectively</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-orgcf3daa7" class="outline-3">
<h3 id="orgcf3daa7"><span class="section-number-3">3.4.</span> M3L4: Summary</h3>
<div class="outline-text-3" id="text-3-4">
<ol class="org-ol">
<li>Build model with training data</li>
<li>Pick model with validation data</li>
<li>Estimate performance with test data</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orga403445" class="outline-2">
<h2 id="orga403445"><span class="section-number-2">4.</span> Module 04: Clustering</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org3d176f5" class="outline-3">
<h3 id="org3d176f5"><span class="section-number-3">4.1.</span> M4L1: Introduction to clustering</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li><b>Unsupervised</b> method (response not available for use in training)</li>
<li>Grouping data points</li>
<li>Might help discover attributes in the dataset</li>
<li>Example of use
<ul class="org-ul">
<li>Segmenting market of car buyers by:
<ol class="org-ol">
<li>Size</li>
<li>Price</li>
<li>Versatility, etc</li>
</ol></li>
<li>Personalized medicine</li>
<li>Locating facilities</li>
<li>Image analysis</li>
<li>Exploratory data analysis (different model for each attribute)</li>
</ul></li>
<li>Example: Miles driven vs. Age</li>
</ul>
</div>
</div>
<div id="outline-container-org27166e9" class="outline-3">
<h3 id="org27166e9"><span class="section-number-3">4.2.</span> M4L2: Distance Norms</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>Straight line distance (Euclidean)
\(\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}\)</li>
<li>Rectilinear distance (Manhattan, 1-norm)
\(|x_1-y_1| + |x_2-y_2|\)</li>
<li>Generalized p-norm (Minkowski)
\(\sqrt[p]{|x_1-y_1|^p+|x_2-y_2|^p}\)</li>
<li>&infin;-norm distance
\(\sqrt[\infty]{\sum_{i=1}^n|x_i-y_i|^{\infty}}\)
<ul class="org-ul">
<li>sum = \(|x_i-y_i|^{\infty}\)</li>
<li>\(\sqrt[\infty]{\text{max}_{i}^n|x_i-y_i|^{\infty}}\)</li>
<li>Largest term dominates the rest, hence simplifies to:</li>
<li>\(\text{max}_i |x_i-y_i|\)</li>
</ul></li>
<li>Analogize with warehouse picking robot. The operation that takes the longest dominates the total operation time.</li>
</ul>
</div>
</div>
<div id="outline-container-org3c75b10" class="outline-3">
<h3 id="org3c75b10"><span class="section-number-3">4.3.</span> M4L3: K-Means Clustering</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li><b>Unsupervised</b> technique</li>
<li>Steps to implement K-Means:
<ol class="org-ol">
<li>Plot data points on suitable axes (e.g., age vs temperature, sepal width vs sepal height)</li>
<li>Let:
<ul class="org-ul">
<li>\(x_{ij}\) = attribute \(j\) of data point \(i\)</li>
<li>\(y_{ik}\) = \(1\) iif data point \(i\) in cluster \(k\), else \(0\)</li>
<li>\(z_{jk}\) = coordinate \(j\) of cluster center \(k\)</li>
<li>Mathematically, but it takes too long:
\[
       \text{Min}_{y,z}\sum_i\sum_k \sqrt{\sum_{j} (x_{ij} - z_{jk})^2}
       \]
subject to: \(\sum_k y_{ik} = 1\) for each \(i\)</li>
</ul></li>
<li>Practical method:
<ul class="org-ul">
<li>Pick \(k\) cluster centers in data</li>
<li>Assign each point to nearest cluster center</li>
<li>Recalculate cluster center (centroid)
<ul class="org-ul">
<li>Now, data points might not belong to the right cluster</li>
</ul></li>
<li>Go back to assign, then re-calc, then assign, then re-calc iteratively until stable</li>
</ul></li>
<li>K-Means is a <b>heuristic</b>, i.e.:
<ul class="org-ul">
<li>it is fast and good</li>
<li><b>not guaranteed</b> to find global best solution.</li>
</ul></li>
<li>It is expectation-maximization (EM), and alternates between expectation (<i>finding cluster centers</i>) and maximization (<i>assigning points to clusters</i>)</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org249c8f9" class="outline-3">
<h3 id="org249c8f9"><span class="section-number-3">4.4.</span> M4L4: Practical details for K-Means</h3>
<div class="outline-text-3" id="text-4-4">
<p>
Algorithm just assigns outliers to nearest clusters.
</p>
<ul class="org-ul">
<li>Choosing <b>starting points</b>:
<ol class="org-ol">
<li>Run several times with different initial cluster centers</li>
<li>Algorithm is non-deterministic, <i>i.e.</i> can produce different results when run with different inputs</li>
<li>Choose the best solution from the results produced</li>
</ol></li>
<li>Handling <b>outliers</b>:
<ol class="org-ol">
<li>Discard, but may not be the 'right' answer</li>
<li>Ask why the outlier happens
<ul class="org-ul">
<li>What it means to discard or include the outlier</li>
<li>Ultimately, algorithm is just a guide. Best solution is what fits the situation.</li>
</ul></li>
</ol></li>
<li>Choosing <b>number of clusters</b>. Is adding a cluster always better?
<ul class="org-ul">
<li>It may increase the metric (total distance of each data point to their cluster center), hence clustering appears to work better.</li>
<li>However, it may defeat the purpose of clustering if every cluster just consists of one data point.</li>
</ul></li>
<li>Total distance can be compared to find the 'kink' or 'elbow'.
<ul class="org-ul">
<li>After this point, the marginal benefit of adding another cluster decreases.</li>
<li><p>
Elbow diagram:
</p>


<div id="orgf6212b1" class="figure">
<p><img src="./img/04-elbow.png" alt="04-elbow.png" />
</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgcfb702c" class="outline-3">
<h3 id="orgcfb702c"><span class="section-number-3">4.5.</span> M4L5: Clustering for prediction</h3>
<div class="outline-text-3" id="text-4-5">
<blockquote>
<p>
Given a new point, which cluster should it be in?
</p>
</blockquote>
<ul class="org-ul">
<li>Is point inside cluster?</li>
<li>Otherwise, what's the nearest cluster center?</li>
<li>Asked another way: for the range of the dataset, which areas would we assign to each cluster if a new point appears there?
<ul class="org-ul">
<li>This is a <a href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi diagram</a>.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org37ba751" class="outline-3">
<h3 id="org37ba751"><span class="section-number-3">4.6.</span> M4L6: Clustering vs Classification</h3>
<div class="outline-text-3" id="text-4-6">
<ul class="org-ul">
<li>Since both group data points&#x2026;</li>
<li>The difference is what we know about the data points.</li>
<li>For classification, the correct response is known, i.e.
<ul class="org-ul">
<li>supervised learning</li>
<li>model uses both attributes <b>and</b> response</li>
</ul></li>
<li>For clustering, the 'correct' classification is unknown
<ul class="org-ul">
<li>unsupervised learning</li>
<li>model decides clusters <b>only</b> based on the attributes</li>
</ul></li>
<li>Supervised learning is more common</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgad6f532" class="outline-2">
<h2 id="orgad6f532"><span class="section-number-2">5.</span> Module 05: Data preparation</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgdf80f19" class="outline-3">
<h3 id="orgdf80f19"><span class="section-number-3">5.1.</span> M5L1: Common techniques and problems</h3>
<div class="outline-text-3" id="text-5-1">
<ol class="org-ol">
<li>Scale data
<ul class="org-ul">
<li>Outliers?</li>
</ul></li>
<li>Extraneous (unnecessary data)
<ul class="org-ul">
<li>Complicates the model and</li>
<li>Makes it harder to interpret the solution</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-orgb6288cb" class="outline-3">
<h3 id="orgb6288cb"><span class="section-number-3">5.2.</span> M5L2: Outliers</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>Types
<dl class="org-dl">
<dt>Point outliers</dt><dd>one / few points very different from others</dd>
<dt>Contextual outlier</dt><dd>Value far from other points in time (not in absolute value)</dd>
<dt>Collective outlier</dt><dd>Something missing in a range of points, but not sure exactly where. Outlier by omission.</dd>
</dl></li>
<li>How to detect?
<ul class="org-ul">
<li>Box-and-whisker plot if data can be plotted in 1-dimension
<ul class="org-ul">
<li>Box: 25/75th percentile
<ul class="org-ul">
<li>Line: 50th percentile</li>
</ul></li>
<li>Whiskers: 10/90th percentile, 5/95th, etc</li>
</ul></li>
<li>For multi-dimensional, no good way. We can still:
<ol class="org-ol">
<li>Fit a model.</li>
<li>Points with large error might be outlier</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org52911bd" class="outline-3">
<h3 id="org52911bd"><span class="section-number-3">5.3.</span> M5L3: What to do with outliers?</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>Need to understand why there's outliers
<ol class="org-ol">
<li>Bad data
<ul class="org-ul">
<li>Sensor fail</li>
<li>Contaminated experiment</li>
<li>Wrong data input</li>
</ul></li>
<li>Unexpected, real, data
<ul class="org-ul">
<li>Need to understand more about the data, e.g.</li>
<li>Where it came from</li>
<li>How it was compiled</li>
<li>Unique situations</li>
</ul></li>
</ol></li>
</ul>
</div>
<div id="outline-container-org3bc50ef" class="outline-4">
<h4 id="org3bc50ef"><span class="section-number-4">5.3.1.</span> Bad data</h4>
<div class="outline-text-4" id="text-5-3-1">
<ul class="org-ul">
<li>Omit the points</li>
<li>Use imputation to replace the points</li>
</ul>
</div>
</div>
<div id="outline-container-org1db0f84" class="outline-4">
<h4 id="org1db0f84"><span class="section-number-4">5.3.2.</span> Real / correct data</h4>
<div class="outline-text-4" id="text-5-3-2">
<ul class="org-ul">
<li>Outliers are somewhat expected in large datasets</li>
<li>E.g., for normally-distributed data:
<ul class="org-ul">
<li>4% will be outside 2 &sigma;</li>
<li>1e6 data points = 2000 outside 3 &sigma;</li>
</ul></li>
<li>Removing <b>real</b> outliers might make model too optimistic. <i>e.g.</i> not account for actual shipments that take a long time from US to Africa</li>
<li>Outliers might be due to weather, political events</li>
</ul>
</div>
</div>
<div id="outline-container-orgd6dbe37" class="outline-4">
<h4 id="orgd6dbe37"><span class="section-number-4">5.3.3.</span> Another way to handle outliers</h4>
<div class="outline-text-4" id="text-5-3-3">
<ol class="org-ol">
<li>First build a logistic regression model
<ul class="org-ul">
<li>This estimated probability of outliers under different conditions</li>
</ul></li>
<li>Next, build the regular model i.e. estimate delivery time under <b>normal conditions</b>
<ul class="org-ul">
<li>Use data without outliers</li>
<li>Report different outcomes&#x2026;</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org669e072" class="outline-4">
<h4 id="org669e072"><span class="section-number-4">5.3.4.</span> Summary</h4>
<div class="outline-text-4" id="text-5-3-4">
<ul class="org-ul">
<li>Outliers aren't predictable</li>
<li>Investigate the data in case you're wrong</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org1919c4c" class="outline-2">
<h2 id="org1919c4c"><span class="section-number-2">6.</span> Module 06: Change detection</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org7e68dd6" class="outline-3">
<h3 id="org7e68dd6"><span class="section-number-3">6.1.</span> M6L1: Examples</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>Usually with time series data</li>
<li>Determine if action is needed, e.g.,
<ul class="org-ul">
<li>Time for machine maintenance?</li>
<li>Have sales increased?</li>
</ul></li>
<li>Determine impact of some past action, e.g.,
<ul class="org-ul">
<li>Did new tax / increase rate decrease sales?</li>
<li>Did price discount increase sales?</li>
</ul></li>
<li>Determine changes of current actions, e.g.
<ul class="org-ul">
<li>Did voting patterns change?</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org65a6baa" class="outline-3">
<h3 id="org65a6baa"><span class="section-number-3">6.2.</span> M6L2: Cumulative sum for change detection</h3>
<div class="outline-text-3" id="text-6-2">
<blockquote>
<p>
Answers whether mean of the observed distribution gone above a critical level
</p>
</blockquote>
<ul class="org-ul">
<li>x<sub>t</sub> is observed value at time \(t\)</li>
<li>&mu; is mean of \(x\), if no change in distribution</li>
<li>Hence, \((x_t - \mu)\) is how much the observation is above mean at time \(t\)</li>
<li>Detecting an increase
\[
  S_t = \text{max}\{ 0, s_{t-1}+(x_t-\mu-C) \}
  \]
<ul class="org-ul">
<li>Determine threshold \(T\) and ask whether S<sub>t</sub> ⩾ T?
<ul class="org-ul">
<li>If running total &lt; 0, it's irrelevant</li>
<li>There should still be some randomness</li>
<li>C is a term to control how faster S<sub>t</sub> increases</li>
</ul></li>
</ul></li>
<li>Detecting a decrease
\[
  S_t = \text{max}\{ 0, s_{t-1}+(\mu-x_t-C) \}
  \]
<ul class="org-ul">
<li>Is S<sub>t</sub> ⩾ T?</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org231cfa1" class="outline-4">
<h4 id="org231cfa1"><span class="section-number-4">6.2.1.</span> Interpretation</h4>
<div class="outline-text-4" id="text-6-2-1">
<ul class="org-ul">
<li>Choices of model parameters
<dl class="org-dl">
<dt>T</dt><dd>the threshold, above which alarm is raised</dd>
<dt>C</dt><dd>the control term (smaller = more sensitive)</dd>
</dl></li>
<li>Consider / trade off:
<ol class="org-ol">
<li>How costly is it to delay detection? (false negative) -&gt; if it's costly, use small C</li>
<li>How costly is false positive? -&gt; if it's costly, use big C</li>
</ol></li>
<li>Use a control chart and plot S<sub>t</sub> vs t with \(T\) as a horizontal line
<img src="./img/06-control-chart.png" alt="06-control-chart.png" /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org014b0b4" class="outline-3">
<h3 id="org014b0b4"><span class="section-number-3">6.3.</span> M6L3: Ethics: Honestly reporting our results</h3>
<div class="outline-text-3" id="text-6-3">
<ul class="org-ul">
<li>Be faithful to data</li>
<li>Have sound conclusions drawn from the model and not your own conceptions</li>
<li>Always be honest and true to your analysis</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgdb77bb7" class="outline-2">
<h2 id="orgdb77bb7"><span class="section-number-2">7.</span> Module 07: Time series</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org05ec7e6" class="outline-3">
<h3 id="org05ec7e6"><span class="section-number-3">7.1.</span> M7L1: Introduction to exponential smoothing</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>Data for the same response is known for many time periods</li>
<li>Examples:
<ul class="org-ul">
<li>Temperature readings</li>
<li>Price of stocks</li>
<li>Daily sales of hamburgers</li>
<li>Blood pressure readings</li>
</ul></li>
<li>Variation in time series data:
<ol class="org-ol">
<li>Trends increase or decrease</li>
<li>Cyclical variables over a year or a week</li>
</ol></li>
</ul>
</div>
<div id="outline-container-org9103ecd" class="outline-4">
<h4 id="org9103ecd"><span class="section-number-4">7.1.1.</span> Random variation</h4>
<div class="outline-text-4" id="text-7-1-1">
<ul class="org-ul">
<li>No underlying reason for the variation</li>
</ul>
</div>
</div>
<div id="outline-container-orgc77a2a5" class="outline-4">
<h4 id="orgc77a2a5"><span class="section-number-4">7.1.2.</span> Definitions:</h4>
<div class="outline-text-4" id="text-7-1-2">
<ul class="org-ul">
<li>\(S_t\): expected <b>baseline</b> response at time period \(t\)</li>
<li>\(x_t\): the observed response at \(t\)</li>
<li>Seeing a increase over time, is it
<ol class="org-ol">
<li>A real increase?</li>
<li>Random?</li>
</ol></li>
<li>There are two ways to answer:
<ol class="org-ol">
<li>It's a real increase, hence \(S_t = x_t\)
<ul class="org-ul">
<li>the observed reading is real indicator of revised baseline</li>
</ul></li>
<li>It's random, hence \(S_t = S_{t-1}\)
<ul class="org-ul">
<li>today's baseline = yesterday's baseline</li>
</ul></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-orgb12debf" class="outline-4">
<h4 id="orgb12debf"><span class="section-number-4">7.1.3.</span> Exponential smoothing method</h4>
<div class="outline-text-4" id="text-7-1-3">
<p>
Combines both, i.e.
\(S_t = \alpha x_t + (1-\alpha)S_{t-1}\)
</p>
<ul class="org-ul">
<li><p>
0 &lt; &alpha; &lt;1
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&alpha;</th>
<th scope="col" class="org-left">example value of &alpha;</th>
<th scope="col" class="org-left">randomness</th>
<th scope="col" class="org-left">trust</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">small</td>
<td class="org-left">&rarr; 0 (e.g. 0.01)</td>
<td class="org-left">high</td>
<td class="org-left">previous baseline i.e. \(S_{t-1}\)</td>
</tr>

<tr>
<td class="org-left">large</td>
<td class="org-left">&rarr; 1 (e.g. 0.99)</td>
<td class="org-left">low</td>
<td class="org-left">today's estimate i.e. \(x_t\)</td>
</tr>
</tbody>
</table></li>

<li>How to start? \(S_1 = x_1\)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org587c652" class="outline-3">
<h3 id="org587c652"><span class="section-number-3">7.2.</span> M7L2: Trend and cyclic effects</h3>
<div class="outline-text-3" id="text-7-2">
<p>
Complexities!
</p>
<ul class="org-ul">
<li>Trends, increasing or decreasing</li>
<li>Cyclical patterns, e.g. annual, weekly, daily</li>
</ul>
</div>
<div id="outline-container-org994d601" class="outline-4">
<h4 id="org994d601"><span class="section-number-4">7.2.1.</span> Trends</h4>
<div class="outline-text-4" id="text-7-2-1">
<ul class="org-ul">
<li>\(T_t\): the trend at time period \(t\)</li>
<li>\(S_t = \alpha x_t + (1-\alpha)(S_{t-1}+T_{t-1})\)</li>
<li>\(T_t = \beta(S_t - S_{t-1}) + (1-\beta)T_{t-1}\)</li>
<li>Initial condition: \(T_1=0\)</li>
</ul>
</div>
</div>
<div id="outline-container-orgf3b1bd4" class="outline-4">
<h4 id="orgf3b1bd4"><span class="section-number-4">7.2.2.</span> Cyclical patterns</h4>
<div class="outline-text-4" id="text-7-2-2">
<ul class="org-ul">
<li>Make cycles additive: behaves like trend</li>
<li>Make cycles multiplicative: more notation required
<ul class="org-ul">
<li>L = length of cycle</li>
<li>\(C_t\) = the multiplicative seasonality factor
<ul class="org-ul">
<li>This inflates or deflates the observation</li>
</ul></li>
<li>New baseline formula
\[
    S_t = \frac{\alpha x_t}{C_{t-L}} + (1-\alpha)(S_{t-1}+T_{t-1})
    \]</li>
<li>Need to use the factor from \(L\) time periods ago
<ul class="org-ul">
<li>as that's the most recent cyclic factor we have from that part of the cycle</li>
</ul></li>
<li>Update the cyclic factor in a similar way i.e.:
<ul class="org-ul">
<li>\(C_t = \gamma(x_t/S_t) + (1-\gamma)(C_{t-L})\)</li>
<li>C<sub>1</sub>, &#x2026;, C<sub>L</sub> = 1
<ul class="org-ul">
<li>meaning there's no initial cyclic effect</li>
</ul></li>
<li>If C = 1.1 on Sunday:
<ul class="org-ul">
<li>sales are higher by 10% just because it's Sunday</li>
</ul></li>
</ul></li>
<li>Initial values: first \(L\) are set to 1. Multiplying by 1 = no effect</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9a2a424" class="outline-4">
<h4 id="org9a2a424"><span class="section-number-4">7.2.3.</span> Summary</h4>
<div class="outline-text-4" id="text-7-2-3">
<ul class="org-ul">
<li>Exponential smoothing
<ul class="org-ul">
<li>Single</li>
<li>Double (with trend)</li>
<li>Triple (with trend and cyclic effects)
<ul class="org-ul">
<li>AKA Winter's method, or Holt-Winters</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org2ce055b" class="outline-3">
<h3 id="org2ce055b"><span class="section-number-3">7.3.</span> M7L3: Etymology (what the name means)</h3>
<div class="outline-text-3" id="text-7-3">
<p>
Example equation when \(\alpha = \frac{1}{2}\):
\(S_t = 0.5 x_t + 0.5 S_{t-1}\)
</p>
</div>
<ol class="org-ol">
<li><a id="orged272bc"></a>Smoothing<br />
<div class="outline-text-5" id="text-7-3-0-1">
<ul class="org-ul">
<li>Note: when x<sub>t</sub> is high, S<sub>t</sub> is <b>not</b> as high, as \((1-\alpha)S_{t-1}\) pulls it down</li>
<li>Conversely: when x<sub>t</sub> is low, S<sub>t</sub> is <b>not</b> as low, as \((1-\alpha)S_{t-1}\) pulls it up</li>
<li>Peaks and valleys are smoothed out
<img src="./img/07-smoothed-graph.png" alt="07-smoothed-graph.png" /></li>
</ul>
</div>
</li>
<li><a id="org982dfe7"></a>Exponential<br />
<div class="outline-text-5" id="text-7-3-0-2">
<ul class="org-ul">
<li>Each \(S_{t-1}\) actually contains every previous value of x!
<ul class="org-ul">
<li>When written or expanded out, e.g.
\[
    S_t = \alpha x_t + (1-\alpha)S_{t-1}
    \]
\[
    S_{t} = \alpha x_t + (1-\alpha)[\alpha x_{t-1} + (1-\alpha)S_{t-2}]
    \]
\[
    S_{t} = \alpha x_t + (1-\alpha)\alpha x_{t-1} + (1-\alpha)^2S_{t-2}
    \]</li>
</ul></li>
<li>Each S<sub>t</sub> is weighed by (1-&alpha;) to an increasing <b>exponent</b></li>
<li>This means not only the current observation matters; instead, every past observation contributes to the current baseline estimate</li>
<li>However, more recent observations are more important as they have higher weight</li>
</ul>
</div>
</li>
</ol>
<div id="outline-container-org003eccf" class="outline-4">
<h4 id="org003eccf"><span class="section-number-4">7.3.1.</span> Summary</h4>
<div class="outline-text-4" id="text-7-3-1">
<ul class="org-ul">
<li>Exponential smoothing smooths out jumps in observed data</li>
<li>It's an exponential weighting of all past observations</li>
<li>More recent observations are more important to the current baseline estimate</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1379f70" class="outline-3">
<h3 id="org1379f70"><span class="section-number-3">7.4.</span> M7L4: Forecasting</h3>
<div class="outline-text-3" id="text-7-4">
<ul class="org-ul">
<li>Recap: \(S_t = \alpha x_t + (1-\alpha)S_{t-1}\)</li>
<li>Prediction:
<ul class="org-ul">
<li>\(S_{t+1} = \alpha x_{t+1} + (1-\alpha)S_{t}\)</li>
<li>However x<sub>t+1</sub> is unknown</li>
<li>Best guess for x<sub>t+1</sub> is \(S_t\)</li>
</ul></li>
<li>Our forecast for \(t+1\) is hence (after substituting):
\[
  F_{t+1}=\alpha S_t + (1-\alpha) S_t \\
  F_{t+1} = S_t \\
  F_{t+k} = S_t \text{when } k=1, 2, ...
  \]
<ul class="org-ul">
<li>note that forecast error becomes larger for larger \(k\)</li>
</ul></li>
<li>If including trend:
\[
  S_t = \alpha x_t + (1-\alpha)(S_{t-1}+T_{t-1}) \\
  T_t = \beta (S_t-S_{t-1})+(1-\beta)T_{t-1} \\
  F_{t+1} = S_t + T_t \\
  F_{t+k} = S_t + kT_t, k=1,2,...
  \]
<dl class="org-dl">
<dt>Best estimate of next baseline</dt><dd>the most current baseline estimate</dd>
<dt>Best estimate of the trend</dt><dd>the most current trend estimate</dd>
</dl></li>
<li>If including multiplicative seasonality:
\[
  S_t = \alpha x_t/C_{t-L} + (1-\alpha)(S_{t-1}+T_{t-1})
  F_{t+1} = (S_t+T_t)C_{(t+1)-L}
  \]
<dl class="org-dl">
<dt>Best estimate of next time period seasonal factor</dt><dd>the corresponding (lagged) seasonal factor, i.e. \(C_{t+1}=C_{t+1-L}\)</dd>
</dl></li>
<li>Finding the right &alpha;, &beta;, &gamma;: use optimization, to be covered in future
<ul class="org-ul">
<li>\(\min{(F_t-x_t)^2}\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8e99bba" class="outline-3">
<h3 id="org8e99bba"><span class="section-number-3">7.5.</span> M3L5: ARIMA</h3>
<div class="outline-text-3" id="text-7-5">
<p>
AutoRegressive Integrated Moving Average.
</p>
<ul class="org-ul">
<li>ARIMA <b>theory</b> is not covered in IAM.</li>
</ul>
</div>
<div id="outline-container-orgd83d0dd" class="outline-4">
<h4 id="orgd83d0dd"><span class="section-number-4">7.5.1.</span> (I): Differences</h4>
<div class="outline-text-4" id="text-7-5-1">
<ul class="org-ul">
<li>Exponential smoothing assumes <b>stationary</b> data, i.e.
<ul class="org-ul">
<li>mean, variance, other measures are constant over time</li>
</ul></li>
<li>ARIMA works for data that's not stationary
<ul class="org-ul">
<li>if differences in data are stationary
<dl class="org-dl">
<dt>1st order difference D<sub>(1)</sub></dt><dd>difference of consecutive observations, i.e. \(D_{(1)t}=(x_t-x_{t-1})\)</dd>
<dt>2nd order difference D<sub>(2)</sub></dt><dd>difference of the differences i.e.
\(D_{(2)t}=(x_t-x_{t-1})-(x_{t-1}-x_{t-2})\)</dd>
<dt>d<sup>th</sup> order difference D<sub>(d)</sub></dt><dd>diff&#x2026; d times</dd>
</dl></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd66aaff" class="outline-4">
<h4 id="orgd66aaff"><span class="section-number-4">7.5.2.</span> (II): Autogression</h4>
<div class="outline-text-4" id="text-7-5-2">
<ul class="org-ul">
<li>Predicting current values based on previous period's values</li>
<li>Regression: predicting value based on other factors</li>
<li>Auto: use earlier values to predict. Only works with time series</li>
<li>When used to forecast, exponential smoothing is an order-&infin; autoregressive model
<ul class="org-ul">
<li>All previous values are used to make current prediction</li>
</ul></li>
<li>Order-p autoregressive model: S<sub>t</sub> is function of \(\{x_t, x_{t-1}, ..., x_{t-(p-1)}\}\)
<ul class="org-ul">
<li>Only go back \(p\) periods</li>
</ul></li>
<li>ARIMA: combines autoregression and differencing
<ul class="org-ul">
<li>Autoregression on the differences</li>
<li>Use \(p\) time periods of previous observations to predict \(d^{th}\) order differences</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5e549ed" class="outline-4">
<h4 id="org5e549ed"><span class="section-number-4">7.5.3.</span> (III): Moving Average</h4>
<div class="outline-text-4" id="text-7-5-3">
<ul class="org-ul">
<li>Use previous errors &epsilon;<sub>t</sub> as predictors
<ul class="org-ul">
<li>\(\epsilon_t = (\hat{x_t}-x_t)\)</li>
</ul></li>
<li>Order-q moving average
<ul class="org-ul">
<li>go back \(q\) time periods</li>
<li>\(\epsilon_{t-1}, \epsilon_{t-2}, ..., \epsilon_{t-q}\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgfce0b78" class="outline-4">
<h4 id="orgfce0b78"><span class="section-number-4">7.5.4.</span> ARIMA model</h4>
<div class="outline-text-4" id="text-7-5-4">
<p>
ARIMA (p,d,q) model
</p>
<ul class="org-ul">
<li>\(d^{th}\) order differences</li>
<li>\(p^{th}\) order autoregression</li>
<li>\(q^{th}\) order moving average</li>
<li><a id="org8d0cedd"></a>Equation:
\[
  D_{(d)t} = \mu + \sum^p_{i=1}\alpha_i D_{(d)t-i} - \sum^q_{i=1} \theta_i (\hat{x}_{t-i}-x_{t-i})
  \]</li>
<li>Software can find \(d, p, q\)</li>
<li>Extensions
<ol class="org-ol">
<li>Add seasonality (out of scope for IAM)</li>
<li>Specific models:
<dl class="org-dl">
<dt>ARIMA(0,0,0)</dt><dd>white noise</dd>
<dt>ARIMA(0,1,0)</dt><dd>random walk</dd>
<dt>ARIMA(p,0,0)</dt><dd>AR (autoregressive) model</dd>
<dt>ARIMA(0,0,q)</dt><dd>MA (moving avg) model</dd>
<dt>ARIMA(0,1,1)</dt><dd>basic exponential smoothing model</dd>
</dl></li>
</ol></li>
<li>Can be used for short-term forecasting
<ul class="org-ul">
<li>ARIMA is better than ES when data is more stable with fewer peaks, valleys, outliers</li>
<li>ARIMA needs 40+ historical data points to work well</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga480855" class="outline-3">
<h3 id="orga480855"><span class="section-number-3">7.6.</span> M7L6: GARCH</h3>
<div class="outline-text-3" id="text-7-6">
<dl class="org-dl">
<dt>GARCH</dt><dd>Generalized Autoregressive Conditional Heteroskedasticity</dd>
</dl>
<p>
To estimate or forecast the variance
</p>
</div>
<div id="outline-container-org34cc16f" class="outline-4">
<h4 id="org34cc16f"><span class="section-number-4">7.6.1.</span> Variance</h4>
<div class="outline-text-4" id="text-7-6-1">
<ul class="org-ul">
<li>Estimates the amount of error</li>
<li>E.g. forecasting demand for trucks
<ul class="org-ul">
<li>tell you how much forecast might be higher/lower than the actual value you see (later) to plan accordingly</li>
</ul></li>
<li>In investment (portfolio optimization):
<ul class="org-ul">
<li>Balance the expected return in investment with amount of volatility.
<dl class="org-dl">
<dt>Riskier</dt><dd>higher expected return</dd>
<dt>Less risky</dt><dd>lower expected return</dd>
</dl></li>
<li>Variance is a proxy for amount of volatility or risk</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6c3c2c0" class="outline-4">
<h4 id="org6c3c2c0"><span class="section-number-4">7.6.2.</span> GARCH</h4>
<div class="outline-text-4" id="text-7-6-2">
<p>
\[
\sigma^2_t = \omega + \sum^p_{i=1}\beta_i\sigma^2_{t-1}+\sum^q_{i=1} \gamma_i \epsilon^2_{t-i}
\]
It looks very similar to <a href="#org8d0cedd">ARIMA Equation</a>, but:
<b>Differences</b>:
</p>
<dl class="org-dl">
<dt>GARCH deals with variances and squared errors</dt><dd>ARIMA deals with observations and linear errors</dd>
<dt>GARCH deals with raw variances</dt><dd>ARIMA deals with differences of variances</dd>
</dl>
</div>
</div>
<div id="outline-container-orgda4253e" class="outline-4">
<h4 id="orgda4253e"><span class="section-number-4">7.6.3.</span> Summary - three models for time series analysis</h4>
<div class="outline-text-4" id="text-7-6-3">
<ol class="org-ol">
<li>Exponential smoothing</li>
<li>ARIMA, a generalization of exponential smoothing</li>
<li>GARCH, an ARIMA-like model for analyzing variance</li>
</ol>
</div>
</div>
</div>
</div>
<div id="outline-container-orgbe69eb7" class="outline-2">
<h2 id="orgbe69eb7"><span class="section-number-2">8.</span> Module 08: Regression</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-org183421c" class="outline-3">
<h3 id="org183421c"><span class="section-number-3">8.1.</span> M8L1: Intro to Regression</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<div id="outline-container-orgbdaab01" class="outline-4">
<h4 id="orgbdaab01"><span class="section-number-4">8.1.1.</span> What questions can regression answer?</h4>
<div class="outline-text-4" id="text-8-1-1">
<ol class="org-ol">
<li>How do systems work? (descriptive)</li>
<li>What will happen in the future? (predictive)</li>
</ol>
</div>
</div>
<div id="outline-container-orgadf32ce" class="outline-4">
<h4 id="orgadf32ce"><span class="section-number-4">8.1.2.</span> Simple linear regression</h4>
<div class="outline-text-4" id="text-8-1-2">
<ul class="org-ul">
<li>Linear regression with one predictor, e.g. \(y = a_0 + a_1x+1\)
<ul class="org-ul">
<li>Date point \(i\)'s prediction error
\(= y_i - \hat{y}_i -(a_0+a_1x_1)\)</li>
<li>Sum of squared errors
\(=\sum^n_{i=1}(y_i - \hat{y}_i)^2\)
\(=\sum^n_{i=1}(y_i-(a_0+a_1x_1))^2\)</li>
</ul></li>
<li>Best fit regression line
<ul class="org-ul">
<li>Minimizes sum of squared errors</li>
<li>Defined by a<sub>0</sub> and a<sub>1</sub></li>
</ul></li>
<li>Underlying math
<ul class="org-ul">
<li>Minimize convex quadratic function</li>
<li>Set partial derivatives to 0</li>
<li>Solve simultaneous equations</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org6562e3b" class="outline-3">
<h3 id="org6562e3b"><span class="section-number-3">8.2.</span> M8L2: Maximum Likelihood and Information Criteria</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<div id="outline-container-orgb471f14" class="outline-4">
<h4 id="orgb471f14"><span class="section-number-4">8.2.1.</span> Likelihood</h4>
<div class="outline-text-4" id="text-8-2-1">
<ul class="org-ul">
<li>Measure the probability density of a parameter set</li>
<li id="Maximum likelihood">the parameters that give the highest probability</li>
<li>Assuming:
<ol class="org-ol">
<li>Errors are normally distributed with mean 0, variance &sigma;<sup>2</sup>, independently and identically distributed</li>
<li>Observations are z<sub>1</sub> to z<sub>n</sub></li>
<li>Model estimates are y<sub>1</sub> to y<sub>n</sub></li>
</ol></li>
<li>Probability density of observing z<sub>i</sub> if true value y<sub>i</sub> is
\[
  \frac{1}{\sigma\sqrt(2\pi)}e^-\frac{(z_u-y_i)^2}{2\sigma^2}
  \]</li>
<li>Joint density over \(n\) terms
\[
  \prod^n_{i=1}\frac{1}{\sigma\sqrt(2\pi)}e^-\frac{(z_u-y_i)^2}{2\sigma^2} \\
  = (\frac{1}{\sigma\sqrt{2\pi}})^n e^-\frac{1}{2\sigma^2}\sum^n_{i=1}(z_i-y_i)^2
  \]</li>
<li>Hence <b>to minimize</b> \(\sum^n_{i=1}(z_i-y_i)^2\) over a<sub>0</sub>, &#x2026;, a<sub>m</sub>:
equals to minimizing \(\sum^n_{i=1}(z_i-(a_0 + \sum^m_{j=1}a_jx_{ij}))^2\)</li>
</ul>
</div>
</div>
<div id="outline-container-org09d81fb" class="outline-4">
<h4 id="org09d81fb"><span class="section-number-4">8.2.2.</span> Maximum likelihood fitting</h4>
<div class="outline-text-4" id="text-8-2-2">
<ul class="org-ul">
<li>Simplest example is regression with i.i.d. errors</li>
<li>Complex examples:
<ul class="org-ul">
<li>Different estimation formulas</li>
<li>Different error assumptions</li>
</ul></li>
<li>Good software can handle complex cases</li>
</ul>
</div>
</div>
<div id="outline-container-org1d10ba2" class="outline-4">
<h4 id="org1d10ba2"><span class="section-number-4">8.2.3.</span> Akaike Information Criterion</h4>
<div class="outline-text-4" id="text-8-2-3">
<dl class="org-dl">
<dt>L<sup>*</sup></dt><dd>maximum likelihood value</dd>
<dt>\(k\)</dt><dd>number of parameters being estimated</dd>
<dt>AIC</dt><dd>\(2k-2\log(L^{*})\)</dd>
<dt>Penalty term</dt><dd>balances likelihood with simplicity, helps avoid overfitting</dd>
</dl>
</div>
<ol class="org-ol">
<li><a id="orgc9da048"></a>For simple regression<br />
<div class="outline-text-5" id="text-8-2-3-1">
<dl class="org-dl">
<dt>AIC</dt><dd>\[
  2(m+1) - 2\log(\frac{1}{\sigma\sqrt(2\pi)}^ne^{-\frac{1}{2\sigma^2}}\sum^n_{i=1}(z_i-(a_0 + \sum^m_{j=1}a_jx_{ij}))^2)
  \]</dd>
<dt>Preference</dt><dd>smaller AIC models</dd>
<dt>Requires</dt><dd>infinitely many data points</dd>
</dl>
</div>
</li>
</ol>
</div>
<div id="outline-container-org2c0390c" class="outline-4">
<h4 id="org2c0390c"><span class="section-number-4">8.2.4.</span> Corrected AIC (AIC<sub>c</sub>)</h4>
<div class="outline-text-4" id="text-8-2-4">
<p>
Use for smaller datasets.
\[
AIC_c = AIC + \frac{2k(k+1)}{n-k-1} \\
= 2k-2\log(L^{*})+\frac{2k(k+1)}{n-k-1}
\]
</p>
</div>
</div>
<div id="outline-container-org80fdeee" class="outline-4">
<h4 id="org80fdeee"><span class="section-number-4">8.2.5.</span> AIC<sub>c</sub> example</h4>
<div class="outline-text-4" id="text-8-2-5">
<ul class="org-ul">
<li>Model 1: AIC 75; Model 2: AIC 80</li>
<li>Relative likelihood equals:
\[
  e^\frac{AIC_1-AIC_2}{2} \\
  = 8.2%
  \]</li>
<li>Hence, Model 2 (larger AIC) is 8.2% as likely as Model 1 to be better
<ul class="org-ul">
<li>Model 1 is probably better</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb0e4b12" class="outline-4">
<h4 id="orgb0e4b12"><span class="section-number-4">8.2.6.</span> Bayesian Information Criterion</h4>
<div class="outline-text-4" id="text-8-2-6">
<ul class="org-ul">
<li>BIC:
\[
  k\log(n)-2\log(L^{*})
  \]</li>
<li>Similar to AIC, but
<ul class="org-ul">
<li>bigger penalty term than AIC's penalty term</li>
<li>encourages models with fewer parameters</li>
</ul></li>
<li>Use BIC when there are <b>more data points</b> than parameters</li>
<li><p>
Rule of thumb for |BIC<sub>1</sub> - BIC<sub>2</sub>|
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">value</th>
<th scope="col" class="org-left">interpretation for smaller BIC model</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">&gt;10</td>
<td class="org-left">very likely better</td>
</tr>

<tr>
<td class="org-right">6-10</td>
<td class="org-left">likely better</td>
</tr>

<tr>
<td class="org-right">2-6</td>
<td class="org-left">somewhat likely better</td>
</tr>

<tr>
<td class="org-right">0-2</td>
<td class="org-left">slightly likely better</td>
</tr>
</tbody>
</table></li>
</ul>
</div>
</div>
<div id="outline-container-orgd329fc9" class="outline-4">
<h4 id="orgd329fc9"><span class="section-number-4">8.2.7.</span> Summary</h4>
<div class="outline-text-4" id="text-8-2-7">
<ul class="org-ul">
<li>No definite rules for AIC, BIC, maximum likelihood</li>
<li>Can look at all 3 to decide what's best</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge37a077" class="outline-3">
<h3 id="orge37a077"><span class="section-number-3">8.3.</span> M8L3: Using Regression</h3>
<div class="outline-text-3" id="text-8-3">
</div>
<div id="outline-container-org1c34b64" class="outline-4">
<h4 id="org1c34b64"><span class="section-number-4">8.3.1.</span> Regression coefficients</h4>
<div class="outline-text-4" id="text-8-3-1">
<ul class="org-ul">
<li>a<sub>0</sub>, a<sub>1</sub>, &#x2026;, a<sub>m</sub> for the equation:</li>
<li>\(y=a_0+a_1x_1+...+a_mx_m\)</li>
<li>Example for baseball, descriptive question:
<ul class="org-ul">
<li>How many runs is associated with every homerun</li>
<li>Response: how many runs are scored by a team</li>
<li>Predictors:
<ol class="org-ol">
<li>Number of HR</li>
<li>Triples</li>
<li>Doubles</li>
<li>Singles</li>
<li>Outs</li>
<li>Double Plays</li>
<li>Stolen bases, etc</li>
</ol></li>
<li>Equation:
\[
    \text{Runs scored} = a_0 + a_1\text{Number of HR} + a_2\text{Number of triples} + ... + a_7\text{Number of stolen bases}
    \]</li>
<li>a<sub>1</sub> = 1.4
<ul class="org-ul">
<li>Means that every HR adds 1.4 runs scored on average, ceteris paribus</li>
</ul></li>
</ul></li>
<li>Example: height, predictive question:
<ul class="org-ul">
<li>How tall will a 2-year old be as an adult?</li>
<li>Response: a person's adult height</li>
<li>Predictors:
<ol class="org-ol">
<li>Father's height</li>
<li>Mother's height</li>
<li>Height at age 2</li>
<li>Male, female</li>
</ol></li>
<li>Equation:
\[
    \text{Adult height} = a_0 + a_1\text{Father's height} + a_2 \text{Mother's height} + ... + a_4\text{Male or female}
    \]</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org673c1b4" class="outline-3">
<h3 id="org673c1b4"><span class="section-number-3">8.4.</span> M8L4: Causation vs Correlation</h3>
<div class="outline-text-3" id="text-8-4">
<dl class="org-dl">
<dt>Causation</dt><dd>one thing causes another thing</dd>
<dt>Correlation</dt><dd>two things tend to happen / not happen together, but neither one causes the other</dd>
</dl>
</div>
<div id="outline-container-orgd2caf95" class="outline-4">
<h4 id="orgd2caf95"><span class="section-number-4">8.4.1.</span> Example: winter recreation</h4>
<div class="outline-text-4" id="text-8-4-1">
<ul class="org-ul">
<li>y: hours per day spent outdoors in winter</li>
<li>x<sub>1</sub>: city's average daily winter temperature</li>
<li>Equation: \(y=a_0+a_1x_1\)</li>
<li>Correlation between y and x<sub>1</sub>
<ul class="org-ul">
<li>with low p-value of a<sub>1</sub></li>
</ul></li>
<li>Does higher temperature in winter cause people to go outside?
<ul class="org-ul">
<li>Probably</li>
</ul></li>
<li>Reversing the equation:
<ul class="org-ul">
<li>y: hours per day spent outdoors in winter</li>
<li>x<sub>1</sub>: city's average daily winter temperature</li>
<li>Equation: \(x_1 = b_0 + b_1y\)</li>
<li>Same correlation between y, x<sub>1</sub>
<ul class="org-ul">
<li>Same p-value of b<sub>1</sub> and a<sub>1</sub></li>
</ul></li>
<li>Hence, does spending more time outside <b>cause</b> higher winter temperatures?
<ul class="org-ul">
<li>No</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgba37970" class="outline-4">
<h4 id="orgba37970"><span class="section-number-4">8.4.2.</span> Example: tiredness vs scruffiness</h4>
<div class="outline-text-4" id="text-8-4-2">
<ul class="org-ul">
<li>Neither one caused another, they're just related to a common tired factor, kids</li>
</ul>
</div>
</div>
<div id="outline-container-org6d922df" class="outline-4">
<h4 id="org6d922df"><span class="section-number-4">8.4.3.</span> How to tell causation?</h4>
<div class="outline-text-4" id="text-8-4-3">
<ul class="org-ul">
<li>When is there causation?
<ol class="org-ol">
<li>Cause before effect</li>
<li>Idea of causation makes sense</li>
<li>No outside factors can cause the relationship (hard to ensure this - need to consider <b>all</b> other factors)</li>
</ol></li>
<li>Be careful before claiming causation</li>
</ul>
</div>
</div>
<div id="outline-container-orgcb891c4" class="outline-4">
<h4 id="orgcb891c4"><span class="section-number-4">8.4.4.</span> Meaningless correlations</h4>
<div class="outline-text-4" id="text-8-4-4">
<ul class="org-ul">
<li>Per capita consumption of mozzarella with number of civil engineering doctorates awarded</li>
<li><a href="http://tylervigen.com/spurious-correlations">link</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org038e8aa" class="outline-3">
<h3 id="org038e8aa"><span class="section-number-3">8.5.</span> M8L5: Transformations and Interactions</h3>
<div class="outline-text-3" id="text-8-5">
<ul class="org-ul">
<li>Recall: \(y=a_0+a_1x_1+...+a_mx_m\)</li>
<li>What if the fit isn't linear for x?</li>
<li>Answer: transforming the data!</li>
</ul>
</div>
<div id="outline-container-orgfa31cc7" class="outline-4">
<h4 id="orgfa31cc7"><span class="section-number-4">8.5.1.</span> Transforming the data</h4>
<div class="outline-text-4" id="text-8-5-1">
<ul class="org-ul">
<li>Quadratic regression, e.g.
\[
  y = a_0 + a_1 x_1 + a_2 x_1^2
  \]</li>
<li>Trigonometric:
\[
  y = a_0 + a_2 \sin(x^2)
  \]</li>
<li>Response transform:
\[
  \log(y) = a_0 + a_1 x_1 + ... + a_m x_m
  \]</li>
<li>etc.</li>
<li>Box-Cox transforms can be automated</li>
</ul>
</div>
</div>
<div id="outline-container-org3a17ee2" class="outline-4">
<h4 id="org3a17ee2"><span class="section-number-4">8.5.2.</span> Interaction terms, e.g. product of inputs</h4>
<div class="outline-text-4" id="text-8-5-2">
<ul class="org-ul">
<li>Child's heights might be influenced by <b>product</b> of father and mother's heights (\(x_1x_2\))</li>
<li>\(y = a_0 + a_1 x_1 + a_2 x_2 + a_3 (x_1 x_2)\)</li>
<li><b>Treat x<sub>1</sub> x<sub>2</sub> as new input, x<sub>3</sub></b></li>
<li>Then find best fit coefficients in the last module</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgac33e20" class="outline-3">
<h3 id="orgac33e20"><span class="section-number-3">8.6.</span> M6L6: Output</h3>
<div class="outline-text-3" id="text-8-6">
</div>
<div id="outline-container-org3d704fe" class="outline-4">
<h4 id="org3d704fe"><span class="section-number-4">8.6.1.</span> p-Values</h4>
<div class="outline-text-4" id="text-8-6-1">
<ul class="org-ul">
<li>Estimates the <b>probability</b> that coefficient is actually 0
<ul class="org-ul">
<li>A hypothesis test</li>
</ul></li>
<li>If p-value is big (&gt;0.05), the coefficient is likely 0, hence remove its attribute from the model</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org513afb6"></a>Other thresholds<br />
<div class="outline-text-5" id="text-8-6-1-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Threshold</th>
<th scope="col" class="org-left">Number of factors included</th>
<th scope="col" class="org-left">Risk</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Higher (&gt;0.05)</td>
<td class="org-left">More factors included</td>
<td class="org-left">Irrelevant factors included</td>
</tr>

<tr>
<td class="org-left">Lower (&lt;0.05)</td>
<td class="org-left">Less factors included</td>
<td class="org-left">Relevant factors left out</td>
</tr>
</tbody>
</table>
</div>
</li>
<li><a id="orgf7e8070"></a>Warnings<br />
<div class="outline-text-5" id="text-8-6-1-2">
<ul class="org-ul">
<li>With lots of data:
<ul class="org-ul">
<li>p-values can get small and seem significant even when attributes aren't related to response</li>
</ul></li>
<li>Even when meaningful, p-values only represent <b>probabilities</b>
<ol class="org-ol">
<li>With 100 attributes having p-value 0.02:</li>
<li>Each of them have 2% chance of <b>not</b> being significant</li>
<li>Hence on average 2/100 are actually irrelevant</li>
</ol></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgded4da9" class="outline-4">
<h4 id="orgded4da9"><span class="section-number-4">8.6.2.</span> Confidence interval</h4>
<div class="outline-text-4" id="text-8-6-2">
<ul class="org-ul">
<li>Mostly given at 95% level around the coefficient</li>
<li>Range of where the coefficient probably lies</li>
<li>And how close that is to zero</li>
<li>Related to p-value</li>
</ul>
</div>
</div>
<div id="outline-container-orga74f9ba" class="outline-4">
<h4 id="orga74f9ba"><span class="section-number-4">8.6.3.</span> T-statistic</h4>
<div class="outline-text-4" id="text-8-6-3">
<ul class="org-ul">
<li>\(\frac{\text{Coefficient}}{\text{Std error}}\)</li>
<li>Related to p-value</li>
</ul>
</div>
</div>
<div id="outline-container-orgf71d1da" class="outline-4">
<h4 id="orgf71d1da"><span class="section-number-4">8.6.4.</span> Coefficient itself</h4>
<div class="outline-text-4" id="text-8-6-4">
<ul class="org-ul">
<li>If very small, then when multiplied by attribute, it's likely irrelevant</li>
</ul>
</div>
</div>
<div id="outline-container-org3bacaae" class="outline-4">
<h4 id="org3bacaae"><span class="section-number-4">8.6.5.</span> \(R^2\)</h4>
<div class="outline-text-4" id="text-8-6-5">
<ul class="org-ul">
<li>Estimate of how much variability can be explained by the model</li>
<li>E.g. R<sup>2</sup> = 0.59:
<ul class="org-ul">
<li>0.59 of data variability can be explained by the model</li>
<li>remaining 0.41 is either:
<ul class="org-ul">
<li>random variation</li>
<li>or other factors</li>
</ul></li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgc37ea6d"></a>Adjusted \(R^2\)<br />
<div class="outline-text-5" id="text-8-6-5-1">
<ul class="org-ul">
<li>Accounts for (penalizes) the number of attributes used</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgd129a60" class="outline-2">
<h2 id="orgd129a60"><span class="section-number-2">9.</span> Module 09: Advanced Data Preparation</h2>
<div class="outline-text-2" id="text-9">
</div>
<div id="outline-container-org67e7a95" class="outline-3">
<h3 id="org67e7a95"><span class="section-number-3">9.1.</span> M9L1: Box-Cox Transformations</h3>
<div class="outline-text-3" id="text-9-1">
<ul class="org-ul">
<li>Models may require data to be normally distributed</li>
<li>What happens when this assumption isn't valid in the data?
<ul class="org-ul">
<li>Results will have bias in this case</li>
<li>Data exhibits heteroskedasicity</li>
<li>i.e., variances are not i.i.d.</li>
</ul></li>
<li>Another example is time series data, where later values have higher variance</li>
<li>Box-Cox is a logarithmic transformation that:
<ol class="org-ol">
<li>Stretches smaller range to increase variability</li>
<li>Shrinks larger range to reduce variability</li>
</ol></li>
<li>E.g. \(t(y)=\frac{y^\lambda-a}{\lambda}\)
<ul class="org-ul">
<li>t(y) can become close to normally distributed</li>
</ul></li>
<li>Need to remember to check for normality (e.g., with Normal Q-Q plot)</li>
</ul>
</div>
</div>
<div id="outline-container-orgf78ed40" class="outline-3">
<h3 id="orgf78ed40"><span class="section-number-3">9.2.</span> M9L2: Detrending</h3>
<div class="outline-text-3" id="text-9-2">
<ul class="org-ul">
<li>For time series data with trends, i.e. an increase or decrease over time
<ul class="org-ul">
<li>For example: increase in price of gold over time but need to account for inflation over time (value of $ decreases over time)</li>
<li>The trend if not correct can mess up a factor-based analysis</li>
<li>Can detrend:
<ul class="org-ul">
<li>Response</li>
<li>Predictors</li>
<li>Factor-based model (consider whenever using these models)
<ul class="org-ul">
<li>Regression, SVM, etc.</li>
</ul></li>
</ul></li>
</ul></li>
<li>How to detrend:
<ul class="org-ul">
<li>Factor by factor for one-dimensional regression, y=a<sub>0</sub>+a<sub>1x</sub>
<ul class="org-ul">
<li>Simple, works well to remove trend for factor-based analysis</li>
<li>This requires going factor by factor and fitting a linear regression model on it</li>
<li>E.g. for simple linear regression for gold prices:
<ul class="org-ul">
<li>Price = - 45600 + 23.2xYear</li>
<li>Detrend end price = Actual price -(-45600+23.2+year)</li>
<li>This produces a similar graph to the inflation-adjusted rate</li>
<li>Useful when we don’t know the response (as in most cases)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga3af405" class="outline-3">
<h3 id="orga3af405"><span class="section-number-3">9.3.</span> M9L3: Intro to PCA</h3>
<div class="outline-text-3" id="text-9-3">
<ul class="org-ul">
<li>Works on high dimensional and correlated data
<ul class="org-ul">
<li>Which subset of features are important to predict response?</li>
<li>e.g. which stocks can predict how well the market performs the next day?
<ul class="org-ul">
<li>6K securities</li>
<li>Remove days that have major events</li>
</ul></li>
<li>Issues:
<ul class="org-ul">
<li>6K predictors need many many data points to avoid overfitting (need to reduce predictors)
<ul class="org-ul">
<li>However, even with unlimited data, the underlying situation could have changed over time</li>
<li>E.g. TSLA stock is good predictor now but it was only listed 5 years ago</li>
</ul></li>
<li>High correlation between predictors</li>
</ul></li>
</ul></li>
<li>PCA transforms data by:
<ul class="org-ul">
<li>Removing correlations within predictors</li>
<li>Ranking coordinates by importance
<ul class="org-ul">
<li>Most important are first</li>
</ul></li>
<li>By concentrating on first <b>n</b> principal components
<ul class="org-ul">
<li>This reduces random effects and</li>
<li>These PCs have higher signal to noise ratio</li>
</ul></li>
<li>Graphically:
<ul class="org-ul">
<li>rotate plot until it’s orthogonal to the correlation</li>
</ul></li>
<li>If D1 and D2 are the new PCs,
<ul class="org-ul">
<li>D1 (that explains more variance) will be the first factor</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgd372985" class="outline-3">
<h3 id="orgd372985"><span class="section-number-3">9.4.</span> M9L4: Using PCA</h3>
<div class="outline-text-3" id="text-9-4">
</div>
<div id="outline-container-org0d84804" class="outline-4">
<h4 id="org0d84804"><span class="section-number-4">9.4.1.</span> Math of PCA</h4>
<div class="outline-text-4" id="text-9-4-1">
<ul class="org-ul">
<li>Definitions
<dl class="org-dl">
<dt>\(X\)</dt><dd>initial matrix of data</dd>
<dt>\(x_{ij}\)</dt><dd>j<sup>th</sup> factor of i<sup>th</sup> data point</dd>
<dt>Scale to:</dt><dd>\(\frac{1}{m}\sum_i x_{ij} = \mu_j = 0\)</dd>
</dl></li>
<li>To find all eigenvectors of X<sup>T</sup> X, where:
<dl class="org-dl">
<dt>V</dt><dd>Matrix of eigenvectors, sorted by eigenvalue</dd>
<dt>V</dt><dd>[V<sub>1</sub> V<sub>2</sub> &#x2026; ]</dd>
<dt>V<sub>j</sub></dt><dd>j<sup>th</sup> eigenvector of X<sup>T</sup> X</dd>
</dl></li>
<li>PCA is a linear combination:
<ul class="org-ul">
<li>1st component is XV<sub>1</sub>, then 2nd is XV<sub>2</sub>, &#x2026;</li>
<li>k<sup>th</sup> new factor for i<sup>th</sup> data point:
\[
    t_{ik} = \sum^m_{ik} x_{ij}v_{jk}
    \]</li>
<li>t<sub>ik</sub> is the factor after PCA</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf4eef86" class="outline-4">
<h4 id="orgf4eef86"><span class="section-number-4">9.4.2.</span> PCA as linear combination</h4>
<div class="outline-text-4" id="text-9-4-2">
<ul class="org-ul">
<li>It <b><b>removes</b></b> correlation between factors</li>
<li>In order to have fewer variables/factors in the model:
<ul class="org-ul">
<li>Choose to include only first <i>n</i> principal components</li>
</ul></li>
<li>PCA can also deal with non-linear functions, using kernels. This is similar to SVM modeling</li>
</ul>
</div>
</div>
<div id="outline-container-orge7c3ae8" class="outline-4">
<h4 id="orge7c3ae8"><span class="section-number-4">9.4.3.</span> PCA for regression</h4>
<div class="outline-text-4" id="text-9-4-3">
<ul class="org-ul">
<li>How to interpret the new model in terms of original factors?</li>
<li>Example: PCA finds \(L\) new factors (each \(t_{ik}\)), and regression coefficients b<sub>0</sub>, b<sub>1</sub>, &#x2026; b<sub>L</sub>:
\[
  y_i = b_0 + \sum^L_{k=1}b_k t_{ik} \\
  = b_0 + \sum^L_{k=1}b_k [\sum^m_{j=1} x_{ij} v{jk}] \\
  = b_0 + \sum^m_{j=1}x_{ij} [\sum^L_{k=1}b_kv_{jk}]
  \\
  = b_0 + \sum^m_{j=1}x_{ij}[a_j]
  \]</li>
<li>Each t vector does not have nice intuitive explanations as they are linear combinations of original factors.</li>
<li>Hence just plug in the transformation for each t factor:
\[
  a_j = \sum^L_{k=1}b_kv_{jk}
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-org0d9f7c4" class="outline-4">
<h4 id="org0d9f7c4"><span class="section-number-4">9.4.4.</span> Summary of PCA</h4>
<div class="outline-text-4" id="text-9-4-4">
<ul class="org-ul">
<li>Use PCA for high-dimensional and correlated data</li>
<li>PCA removes these correlations and ranks coordinates by importance (i.e., variability explained)
<ul class="org-ul">
<li>PC1 &gt; PC2 &gt; PC3, etc</li>
</ul></li>
<li>PCA can be transformed back to the original factor space to get intuitive explanations</li>
<li>PCA allows use of fewer variables
<ul class="org-ul">
<li>Pick the ones that explain the most variability</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9739cbe" class="outline-3">
<h3 id="org9739cbe"><span class="section-number-3">9.5.</span> M9L5: Eigenvalues and Eigenvectors</h3>
<div class="outline-text-3" id="text-9-5">
</div>
<div id="outline-container-orgb8f24ea" class="outline-4">
<h4 id="orgb8f24ea"><span class="section-number-4">9.5.1.</span> Initial example</h4>
<div class="outline-text-4" id="text-9-5-1">
<ul class="org-ul">
<li>Definitions:
<dl class="org-dl">
<dt>\(A\)</dt><dd>a square matrix</dd>
<dt>\(v\)</dt><dd>a vector such that \(Av=\lambda v\)</dd>
<dt>\(V\)</dt><dd>eigenvector of \(A\)</dd>
<dt>\(\lambda\)</dt><dd>eigenvalue of \(A\), i.e. det(A-&lambda; I) = 0. Every &lambda; is eigenvalue of A</dd>
</dl></li>
<li>Given &lambda;, solve \(Av=\lambda v\) to find the eigenvector \(v\)</li>
</ul>
</div>
</div>
<div id="outline-container-orga5161f3" class="outline-4">
<h4 id="orga5161f3"><span class="section-number-4">9.5.2.</span> Important: know how eigenvalues and eigenvectors are important to PCA</h4>
<div class="outline-text-4" id="text-9-5-2">
<ul class="org-ul">
<li>With a scaled matrix \(X\) of data, and x<sub>ij</sub> is factor value for i<sup>th</sup> data point after scaling,</li>
<li>Find eigenvectors v<sub>1</sub> &#x2026; v<sub>n</sub> of \((X^TX)\)</li>
<li>Then, find the principal components:
<ol class="org-ol">
<li>Multiply \(X\) by the eigenvectors</li>
<li>\(Xv_1, Xv_2, ..., Xv_n\) are the principal components
<ul class="org-ul">
<li>i.e. the transformed set of orthogonal coordinate directions</li>
</ul></li>
</ol></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org0d311b2" class="outline-3">
<h3 id="org0d311b2"><span class="section-number-3">9.6.</span> M9L6: PCA: The good and the bad</h3>
<div class="outline-text-3" id="text-9-6">
<ul class="org-ul">
<li>Summary
<img src="./img/m9l6-pca-summary.png" alt="m9l6-pca-summary.png" /></li>
<li>D<sub>1</sub> has more explanatory power (vaariation)</li>
<li>But it may not be the most helpful for explanatory/predictive modeling</li>
<li><b>PCA depends only on the independent variables</b>, not the response variable
<ul class="org-ul">
<li>It's possible response is affected by variables with low variability instead of those with high variability!</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgae599ee" class="outline-4">
<h4 id="orgae599ee"><span class="section-number-4">9.6.1.</span> Example where PCA is good</h4>
<div class="outline-text-4" id="text-9-6-1">
<ul class="org-ul">
<li>Assume PCA is used for classification</li>
<li>PC1 has most of the variance and PC1 can classify red and blue points
<img src="./img/m9l6-pca-good.png" alt="m9l6-pca-good.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-org265a43e" class="outline-4">
<h4 id="org265a43e"><span class="section-number-4">9.6.2.</span> Example where PCA is bad</h4>
<div class="outline-text-4" id="text-9-6-2">
<ul class="org-ul">
<li>PC1, though it has more variance, cannot classify the red and blue points</li>
<li>PC2 has less variance but it can classify the points exactly
<img src="./img/m9l6-pca-bad.png" alt="m9l6-pca-bad.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-org7dee3b1" class="outline-4">
<h4 id="org7dee3b1"><span class="section-number-4">9.6.3.</span> Summary</h4>
<div class="outline-text-4" id="text-9-6-3">
<ul class="org-ul">
<li>We still use PCA (or try to!) as dimensions have higher variation specifically because they contain more information</li>
<li>However, this is not always true</li>
<li>PCA is a helpful approach to try</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd42817e" class="outline-2">
<h2 id="orgd42817e"><span class="section-number-2">10.</span> Module 10: Advanced Regression</h2>
<div class="outline-text-2" id="text-10">
<blockquote>
<p>
Midterm 1 covers up to Module 10
</p>
</blockquote>
</div>
<div id="outline-container-org222e62e" class="outline-3">
<h3 id="org222e62e"><span class="section-number-3">10.1.</span> M10L01: Introduction to CART</h3>
<div class="outline-text-3" id="text-10-1">
<blockquote>
<p>
Classification and Regression Trees
</p>
</blockquote>
</div>
<div id="outline-container-org0aaa354" class="outline-4">
<h4 id="org0aaa354"><span class="section-number-4">10.1.1.</span> Trees in regression</h4>
<div class="outline-text-4" id="text-10-1-1">
</div>
<ol class="org-ol">
<li><a id="orgcae7873"></a>Uses<br />
<div class="outline-text-5" id="text-10-1-1-1">
<ol class="org-ol">
<li>Classification</li>
<li>Decision tree</li>
</ol>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgc6255e0" class="outline-4">
<h4 id="orgc6255e0"><span class="section-number-4">10.1.2.</span> Recall</h4>
<div class="outline-text-4" id="text-10-1-2">
<p>
In simple linear regression, e.g.:
impact of marketing email on recipient spending.
</p>
<ul class="org-ul">
<li>Predictors:
<ol class="org-ol">
<li>Demographics e.g. age, sex, number of children, income</li>
<li>Purchasing factors e.g. amount spent per month</li>
<li>Binary factor e.g. was email received and opened</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org0f1c6b9" class="outline-4">
<h4 id="org0f1c6b9"><span class="section-number-4">10.1.3.</span> What if responses can be differentiated by a factor?</h4>
<div class="outline-text-4" id="text-10-1-3">
<p>
(The above example of simple linear regression assumes every data point behaves the same way)
If each group instead have their own characteristics and responses, two regressions can thus be fitted, e.g.:
</p>
<ol class="org-ol">
<li>25 years or younger
\(\text{Money spent}=50+13.75\times\text{Number of Children}+0\times\text{Income over 30,000}+\text{...}\)</li>
<li>older than 25
\(\text{Money spent}=32+28.13\times\text{Number of children}+7.13\times\text{Income over 30,000}+\text{...}\)</li>
</ol>
</div>
</div>
<div id="outline-container-org2b2dab1" class="outline-4">
<h4 id="org2b2dab1"><span class="section-number-4">10.1.4.</span> Further splits are possible</h4>
<div class="outline-text-4" id="text-10-1-4">
<ul class="org-ul">
<li>Each branch is further split</li>
<li>Each ending is a <i>"leaf"</i>
<ul class="org-ul">
<li><i>Descriptively</i>: Each leaf's coefficients explains behaviour in that leaf</li>
<li><i>Predictively</i>: Each leaf's regression model can be used to predict a new point in that branch.</li>
</ul></li>
<li>Each branch can run \(R^2\) and those with low \(R^2\) can be investigated/improved.</li>
</ul>
</div>
</div>
<div id="outline-container-orgf8790d8" class="outline-4">
<h4 id="orgf8790d8"><span class="section-number-4">10.1.5.</span> Disadvantages</h4>
<div class="outline-text-4" id="text-10-1-5">
<ul class="org-ul">
<li>Lots of computations and regressions</li>
<li>Fewer and fewer data points in each node</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org4af9ada"></a>Hence:<br />
<div class="outline-text-5" id="text-10-1-5-1">
<p>
Simplify the regression by just using the constant term input
</p>
<ul class="org-ul">
<li>e.g. \(y=a_0\) instead of \(y=a_0+a_1x+\text{...}\)</li>
<li>This is the mean response over all data points in the node, i.e.
\[
  a_0 = \frac{\sum_i\text{in node }y_i}{\text{count of data points in node}} \\
  = \text{avg response in node}
  \]</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org37110b5" class="outline-4">
<h4 id="org37110b5"><span class="section-number-4">10.1.6.</span> Other places to use trees</h4>
<div class="outline-text-4" id="text-10-1-6">
<ul class="org-ul">
<li>The branching concept can be applied to:
<ul class="org-ul">
<li>Logistic regression model
<ul class="org-ul">
<li>fraction of node's data points with True response</li>
</ul></li>
<li>Classification model
<ul class="org-ul">
<li>Most common classification among node's data points</li>
</ul></li>
<li>Decision model
<ul class="org-ul">
<li>Each leaf is the decision "do I send a marketing email?"</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3286d1b" class="outline-4">
<h4 id="org3286d1b"><span class="section-number-4">10.1.7.</span> Common questions</h4>
<div class="outline-text-4" id="text-10-1-7">
<ol class="org-ol">
<li>How to choose the branches?</li>
<li>When to stop branching?</li>
<li>Why is this called a regression tree?</li>
</ol>
</div>
</div>
<div id="outline-container-orga410547" class="outline-4">
<h4 id="orga410547"><span class="section-number-4">10.1.8.</span> Etymology of "tree"</h4>
<div class="outline-text-4" id="text-10-1-8">

<div id="org29e9140" class="figure">
<p><img src="./img/m1001-tree.png" alt="m1001-tree.png" />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org16611f9" class="outline-3">
<h3 id="org16611f9"><span class="section-number-3">10.2.</span> M10L02: Branching</h3>
<div class="outline-text-3" id="text-10-2">
</div>
<div id="outline-container-orgcb28f82" class="outline-4">
<h4 id="orgcb28f82"><span class="section-number-4">10.2.1.</span> Main questions</h4>
<div class="outline-text-4" id="text-10-2-1">
<ol class="org-ol">
<li>Which factors are used to decide on branching?</li>
<li>How to split data?</li>
</ol>
<p>
In practice, no good algorithm to help decide. Instead, branch on 1 factor at a time.
</p>
</div>
</div>
<div id="outline-container-org7d93d36" class="outline-4">
<h4 id="org7d93d36"><span class="section-number-4">10.2.2.</span> Branching methods</h4>
<div class="outline-text-4" id="text-10-2-2">
<ol class="org-ol">
<li>Start with half of data and run a regression</li>
<li>Split the data into 2 halves based on some factor we can branch from (e.g. age &gt;25)</li>
<li>For each leaf:
<ol class="org-ol">
<li>Calculate variance of response amongst all data points in each leaf</li>
<li>Test splitting on each factor to see how much lower total variance of two branches would be vs. the least variance.</li>
<li>Choose the factor with lowest total variance.</li>
<li>Make split iif:
<ol class="org-ol">
<li>Enough data points in each branch</li>
<li>Decrease is lower than threshold &delta;</li>
</ol></li>
<li>Otherwise, don't split the leaf</li>
</ol></li>
<li>Go backwards to <b>prune</b> using the 2nd half of data not used in initial branching. For each pair of leaves created in each branch:
<ol class="org-ol">
<li>Use the other half of data in each branch to see if estimation error was improved by branching
<ol class="org-ol">
<li>If error increases/no change, then remove branch</li>
<li>Else, keep the branch</li>
</ol></li>
</ol></li>
</ol>
</div>
</div>
<div id="outline-container-org1147274" class="outline-4">
<h4 id="org1147274"><span class="section-number-4">10.2.3.</span> Generic branching concept</h4>
<div class="outline-text-4" id="text-10-2-3">
<blockquote>
<p>
Overfitting can be costly; make sure the benefit of each branch is greater than its cost
</p>
</blockquote>
<p>
Key ideas
</p>
<ol class="org-ol">
<li>Use a metric related to model quality</li>
<li>Find 'best factor' to branch with</li>
<li><b>Check</b>: did this improve the model?
<ol class="org-ol">
<li>If not, prune the branch back.</li>
</ol></li>
</ol>
<p>
Rejecting potential branches
</p>
<ol class="org-ol">
<li>Low improvement benefit</li>
<li>Some side of branch has too few data points after branching
<ol class="org-ol">
<li>Each leaf should contain &ge;5% of original data (we don't want to over-fit the model)</li>
</ol></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgbfb7899" class="outline-3">
<h3 id="orgbfb7899"><span class="section-number-3">10.3.</span> M10L03: Random Forests</h3>
<div class="outline-text-3" id="text-10-3">
</div>
<div id="outline-container-org2867fb5" class="outline-4">
<h4 id="org2867fb5"><span class="section-number-4">10.3.1.</span> Intro summary</h4>
<div class="outline-text-4" id="text-10-3-1">
<ul class="org-ul">
<li>Introduce randomness</li>
<li>Generate lots of random trees
<ul class="org-ul">
<li>Each has its strengths and weaknesses</li>
</ul></li>
<li>Key concept: average better than single tree</li>
</ul>
</div>
</div>
<div id="outline-container-org26b9537" class="outline-4">
<h4 id="org26b9537"><span class="section-number-4">10.3.2.</span> Introducing randomness</h4>
<div class="outline-text-4" id="text-10-3-2">
<blockquote>
<p>
via bootstrapping
</p>
</blockquote>
<ul class="org-ul">
<li>With \(n\) number of original data points, we make trees each with \(n\) points.
<ul class="org-ul">
<li>However, some points can be picked multiple times while others get picked 0 times.</li>
</ul></li>
<li>When branching:
<ul class="org-ul">
<li>Not as before (before: we choose 1 factor at a time)</li>
<li>In RF: pick a small number of factors \(X\)</li>
<li>Choose the best factor in that set to branch on</li>
<li>Common number of factors used: \(1+\log(n)\)</li>
</ul></li>
<li>No need to prune tree</li>
</ul>
</div>
</div>
<div id="outline-container-orge2b074e" class="outline-4">
<h4 id="orge2b074e"><span class="section-number-4">10.3.3.</span> Note</h4>
<div class="outline-text-4" id="text-10-3-3">
<ul class="org-ul">
<li>Each tree has slightly different data</li>
<li>Will end up with lots of different trees (500-1000 are common)</li>
<li>Each tree gives a slightly different regression model</li>
<li>Which one to use?
<ul class="org-ul">
<li>Regression trees: use the <b>average</b> predicted response</li>
<li>Classification trees: use the <b>most common</b> predicted response</li>
</ul></li>
<li>Benefits of RF:
<ul class="org-ul">
<li>Better overall estimate</li>
<li>Average between tree can somewhat address over-fitting</li>
</ul></li>
<li>Disadvantages of RF:
<ul class="org-ul">
<li>Harder to explain and interpret results</li>
<li>Cannot explain how variables interact, or how some sequence of branches is helpful/meaningful (which can be found in single tree)</li>
<li>Can't give specific model from the data</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf0ddbe9" class="outline-4">
<h4 id="orgf0ddbe9"><span class="section-number-4">10.3.4.</span> Summary of RF</h4>
<div class="outline-text-4" id="text-10-3-4">
<ul class="org-ul">
<li>Method: introduce randomness into the trees</li>
<li>Good as 'black box' predictor</li>
<li>Cannot give much detailed insight</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org69b5264" class="outline-3">
<h3 id="org69b5264"><span class="section-number-3">10.4.</span> M10L04: Explainability and Interpretability</h3>
<div class="outline-text-3" id="text-10-4">
<blockquote>
<p>
How easy or not it is to understand how models create their output?
</p>
</blockquote>
</div>
<div id="outline-container-orgd52a1e9" class="outline-4">
<h4 id="orgd52a1e9"><span class="section-number-4">10.4.1.</span> Example: linear regression</h4>
<div class="outline-text-4" id="text-10-4-1">
<p>
\[y=a_0 + \sum^n_{j=1}a_j x_{ij}\]
To answer "how is the value of \(y\) affected by different values of the predictor?" with:
</p>
<dl class="org-dl">
<dt>y</dt><dd>Number of tickets sold this year</dd>
<dt>x<sub>1</sub></dt><dd>Salary of top 4 stars</dd>
<dt>x<sub>2</sub></dt><dd>Number of movies with similar plots this year</dd>
<dt>x<sub>3</sub></dt><dd>Rated <b>R</b> or more restrictive (1=yes)</dd>
<dt>x<sub>4</sub></dt><dd>Number of days left in the year</dd>
<dt>a<sub>0</sub></dt><dd>1,000,000</dd>
<dt>a<sub>1</sub></dt><dd>0.25</dd>
<dt>a<sub>2</sub></dt><dd>-1,000,000</dd>
<dt>a<sub>3</sub></dt><dd>-1,000,000</dd>
<dt>a<sub>4</sub></dt><dd>20,000</dd>
</dl>
<p>
The interpretation is thus:
</p>
<ul class="org-ul">
<li>Baseline is 1,000,000 tickets (a<sub>0</sub>)</li>
<li>Salary of star, each dollar increases number of tickets sold by $0.25 (a<sub>1</sub>)</li>
<li>Similar movie: each similar movie decreases number of tickets sold by 1,000,000 (a<sub>2</sub>)</li>
<li>Restrictive rating: decreases number of tickets sold by 1,000,000</li>
<li>Days left in year: each day increases number of tickets sold by 20,000</li>
</ul>
</div>
</div>
<div id="outline-container-orgb65eb84" class="outline-4">
<h4 id="orgb65eb84"><span class="section-number-4">10.4.2.</span> Example: regression tree</h4>
<div class="outline-text-4" id="text-10-4-2">
<ul class="org-ul">
<li>With the same values above, it becomes a long if<sub>else</sub> statement</li>
<li>Can describe detail of tree but it's not helpful for understanding</li>
</ul>
</div>
</div>
<div id="outline-container-org91325d7" class="outline-4">
<h4 id="org91325d7"><span class="section-number-4">10.4.3.</span> Example: random forests</h4>
<div class="outline-text-4" id="text-10-4-3">
<ul class="org-ul">
<li>If one tree is hard to explain, 500 are even worse</li>
<li>Although random forests give relative branching importance of each variable,
<ul class="org-ul">
<li>They do not say <b>how</b></li>
<li>Hence RF are not precise for interpretability or explainability</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgfc1e170" class="outline-4">
<h4 id="orgfc1e170"><span class="section-number-4">10.4.4.</span> Comparisons</h4>
<div class="outline-text-4" id="text-10-4-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Model</th>
<th scope="col" class="org-left">Explainability</th>
<th scope="col" class="org-left">Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Linear regression</td>
<td class="org-left">Higher</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">Regression tree</td>
<td class="org-left">Medium</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">Random forest</td>
<td class="org-left">Lower</td>
<td class="org-left">Sometimes higher</td>
</tr>
</tbody>
</table>

<p>
More explainable models:
</p>
<ul class="org-ul">
<li>help us understand "why"</li>
<li>help decision makers to choose between models</li>
<li>can be a legal requirement, e.g. in finance</li>
</ul>
<p>
However, less explainable models can give better results at times as they can identify and model more complex patterns
</p>
</div>
</div>
<div id="outline-container-orgb3c8500" class="outline-4">
<h4 id="orgb3c8500"><span class="section-number-4">10.4.5.</span> Tradeoff</h4>
<div class="outline-text-4" id="text-10-4-5">
<p>
Pay attention to tradeoffs when proposing a model:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Explainability</th>
<th scope="col" class="org-left">Value</th>
<th scope="col" class="org-left">Adoption</th>
<th scope="col" class="org-left">Legal requirement</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Less</td>
<td class="org-left">Potentially more</td>
<td class="org-left">?</td>
<td class="org-left">?</td>
</tr>

<tr>
<td class="org-left">More</td>
<td class="org-left">?</td>
<td class="org-left">More likely</td>
<td class="org-left">Might be required</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-org385b00a" class="outline-3">
<h3 id="org385b00a"><span class="section-number-3">10.5.</span> M10L05: Confusion Matrices</h3>
<div class="outline-text-3" id="text-10-5">
<blockquote>
<p>
Answers: How to measure how well a classification-type model works?
</p>
</blockquote>
<p>
This is a confusion matrix:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Model</th>
<th scope="col" class="org-left">Classification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Yes</td>
<td class="org-left">No</td>
</tr>

<tr>
<td class="org-left">True</td>
<td class="org-left">Yes</td>
<td class="org-left">Correct</td>
<td class="org-left">Wrong</td>
</tr>

<tr>
<td class="org-left">Classification</td>
<td class="org-left">No</td>
<td class="org-left">Wrong</td>
<td class="org-left">Correct</td>
</tr>
</tbody>
</table>

<p>
It shows how much the model is confusing the two categories.
</p>
</div>
<div id="outline-container-orge613d0b" class="outline-4">
<h4 id="orge613d0b"><span class="section-number-4">10.5.1.</span> Details</h4>
<div class="outline-text-4" id="text-10-5-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Model</th>
<th scope="col" class="org-left">Classification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Yes</td>
<td class="org-left">No</td>
</tr>

<tr>
<td class="org-left">True</td>
<td class="org-left">Yes</td>
<td class="org-left">True Pos</td>
<td class="org-left">False Neg</td>
</tr>

<tr>
<td class="org-left">Classification</td>
<td class="org-left">No</td>
<td class="org-left">False Pos</td>
<td class="org-left">True Neg</td>
</tr>
</tbody>
</table>
<ul class="org-ul">
<li>Positive: model <b>says</b> it's in the category</li>
<li>Negative: model <b>says</b> it's NOT in the category</li>
<li>True: model got it right</li>
<li>False: model got it wrong</li>
</ul>
</div>
</div>
<div id="outline-container-org4e9b44c" class="outline-4">
<h4 id="org4e9b44c"><span class="section-number-4">10.5.2.</span> Definitions</h4>
<div class="outline-text-4" id="text-10-5-2">
<dl class="org-dl">
<dt>Sensitivity</dt><dd>TP/(TP+FN), i.e. TP / All actual positives</dd>
<dt>Specificity</dt><dd>TN/(TN+FP), i.e. TN/ All actual negatives</dd>
</dl>
<p>
Others: don't memorize, just refer.
</p>
</div>
</div>
</div>
<div id="outline-container-orgc30b608" class="outline-3">
<h3 id="orgc30b608"><span class="section-number-3">10.6.</span> M10L06: Situationally-Driven Comparisons</h3>
<div class="outline-text-3" id="text-10-6">
</div>
<div id="outline-container-org0c14cbc" class="outline-4">
<h4 id="org0c14cbc"><span class="section-number-4">10.6.1.</span> Example: from spam detection</h4>
<div class="outline-text-4" id="text-10-6-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Model</th>
<th scope="col" class="org-right">Classification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-right">Yes</td>
<td class="org-right">No</td>
</tr>

<tr>
<td class="org-left">True</td>
<td class="org-left">Yes</td>
<td class="org-right">490</td>
<td class="org-right">10</td>
</tr>

<tr>
<td class="org-left">Classification</td>
<td class="org-left">No</td>
<td class="org-right">100</td>
<td class="org-right">400</td>
</tr>
</tbody>
</table>
<ul class="org-ul">
<li>Cost: $0 for correct classification
<ul class="org-ul">
<li>$0.04 to read spam</li>
<li>$1 to miss a real message</li>
</ul></li>
<li>If 50% of email is spam, the total cost is &sum;:
<ol class="org-ol">
<li>490 &times; $0 + 440 &times; $0 = 0</li>
<li>10 &times; $1 = $10</li>
<li>100 &times; $0.04 = $4, i.e.</li>
</ol></li>
</ul>
<p>
$0.014 per email
</p>
<ul class="org-ul">
<li>If 40% of email is spam: total cost is &sum;:
<ol class="org-ol">
<li>490 &times; 0.6/0.5 &times; 0 + 400 &times; 0.4/0.5 \ times 0 = $0</li>
<li>10 &times; 0.6/0.5 &times; $1 = $12</li>
<li>100 &times; 0.4/0.5 &times; $0.04 = $3.2</li>
</ol></li>
</ul>
<p>
$0.0152 per email
</p>
</div>
</div>
<div id="outline-container-org962b737" class="outline-4">
<h4 id="org962b737"><span class="section-number-4">10.6.2.</span> Evaluating quality / changing metrics</h4>
<div class="outline-text-4" id="text-10-6-2">
<ul class="org-ul">
<li>E.g. make model stricter that can reject more spam</li>
<li>This can make model reject more spam, but also cause more false negatives (which are much more costly)
Hence overall cost is higher at $52 ($0.104 per email)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7fa14eb" class="outline-3">
<h3 id="org7fa14eb"><span class="section-number-3">10.7.</span> L10L07: Advanced Topics in Regression</h3>
<div class="outline-text-3" id="text-10-7">
</div>
<div id="outline-container-org8e355df" class="outline-4">
<h4 id="org8e355df"><span class="section-number-4">10.7.1.</span> Poisson regression</h4>
<div class="outline-text-4" id="text-10-7-1">
<p>
Use when response follows a Poisson distribution i.e.
\[
f(z) = \frac{\lambda^Z e^{-z}}{z!}
\]
Examples:
</p>
<ul class="org-ul">
<li>Count of arrivals at airport security</li>
<li>Arrival rate might be function of <b>time</b></li>
<li>Hence, estimate &lambda;(x)</li>
</ul>
</div>
</div>
<div id="outline-container-orge63fd73" class="outline-4">
<h4 id="orge63fd73"><span class="section-number-4">10.7.2.</span> Regression splines</h4>
<div class="outline-text-4" id="text-10-7-2">
<p>
Spline: function of polynomials that connect to each other
<img src="./img/10-07-spline.png" alt="10-07-spline.png" />
</p>
<ul class="org-ul">
<li>Different functions are fitted to different parts of the data set</li>
<li>Hence, smoothens connections between parts</li>
<li>"Order-k" regression spline means that polynomials are all order k.</li>
<li>Example: multi-adaptive regression splines (MARS)
<ul class="org-ul">
<li>Called "Earth" in many stats libraries</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga74535c" class="outline-4">
<h4 id="orga74535c"><span class="section-number-4">10.7.3.</span> Bayesian regression</h4>
<div class="outline-text-4" id="text-10-7-3">
<ul class="org-ul">
<li>Start with:
<ul class="org-ul">
<li>Data AND</li>
<li>Estimate of how regression coefficients and random error is distributed</li>
</ul></li>
<li>Example: to predict how tall a child will be as an adult, based on:
<ul class="org-ul">
<li>Data: heights of child's parents</li>
<li>Expert opinion: starting distribution, coefficients of father's and mother's heights are normally distributed between 0.8 and 1.2</li>
</ul></li>
<li>Then use Baye's theorem to update estimate</li>
<li><b>Helpful when data is lacking</b>:
<ul class="org-ul">
<li>Combines expert opinion with the data we do have.</li>
<li>Can replace expert opinion with a broad prior distribution (e.g., uniform over a large interval) as seed data</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org78cb665" class="outline-4">
<h4 id="org78cb665"><span class="section-number-4">10.7.4.</span> k-Nearest Neighbour Regression</h4>
<div class="outline-text-4" id="text-10-7-4">
<ul class="org-ul">
<li>Similar to KNN for classification</li>
<li>Hence, <b>KNN can be used for both regression and classification</b></li>
<li>Implementation:
<ul class="org-ul">
<li>No estimate of prediction function (function-less)</li>
<li>Plot all data</li>
<li>To predict response for a new point:
<ul class="org-ul">
<li>Average response of \(k\) closest data points</li>
</ul></li>
<li>Can be made fancier, e.g.:
<ul class="org-ul">
<li>Weight each dimension of distance</li>
<li>Removing dimensions that are not predictive</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org82af719" class="outline-2">
<h2 id="org82af719"><span class="section-number-2">11.</span> Module 11: Variable Selection</h2>
<div class="outline-text-2" id="text-11">
<ul class="org-ul">
<li>Factor based models:
<ol class="org-ol">
<li>Classification</li>
<li>Clustering</li>
<li>Regression</li>
</ol></li>
</ul>
</div>
<div id="outline-container-org76ac404" class="outline-3">
<h3 id="org76ac404"><span class="section-number-3">11.1.</span> M11L1: Introduction</h3>
<div class="outline-text-3" id="text-11-1">
</div>
<div id="outline-container-orgcd57ed0" class="outline-4">
<h4 id="orgcd57ed0"><span class="section-number-4">11.1.1.</span> Why bother limiting factors?</h4>
<div class="outline-text-4" id="text-11-1-1">
<ol class="org-ol">
<li>Prevents overfitting
<ul class="org-ul">
<li>When number of factors close to number of data points
<ul class="org-ul">
<li>Cause bad estimates</li>
</ul></li>
<li>Model fits too closely to the random effects</li>
</ul></li>
<li>Simplicity
<ul class="org-ul">
<li>Simple models better than complex models
<ul class="org-ul">
<li>Less data required</li>
<li>Less chance of insignificant factors</li>
<li>Easier to interpret</li>
</ul></li>
<li>Factors can be illegal to use
<ul class="org-ul">
<li>race, sex, religion, marital status cannot be used to make credit decisions</li>
<li>factors correlated to these also cannot be used</li>
</ul></li>
</ul></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgda78e57" class="outline-3">
<h3 id="orgda78e57"><span class="section-number-3">11.2.</span> M11L2: Models for variable selection</h3>
<div class="outline-text-3" id="text-11-2">
</div>
<div id="outline-container-org8024cd9" class="outline-4">
<h4 id="org8024cd9"><span class="section-number-4">11.2.1.</span> Forward selection</h4>
<div class="outline-text-4" id="text-11-2-1">
<ul class="org-ul">
<li>Start with no factors, then add
<img src="file:///Users/whkoh/git-repos/omsa-notes/isye_6501/img/m11-fwd-sel.png" alt="m11-fwd-sel.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-orgf7ede56" class="outline-4">
<h4 id="orgf7ede56"><span class="section-number-4">11.2.2.</span> Backward elimination</h4>
<div class="outline-text-4" id="text-11-2-2">
<ul class="org-ul">
<li>Start with all factors, then eliminate
<img src="file:///Users/whkoh/git-repos/omsa-notes/isye_6501/img/m11-backw-elim.png" alt="m11-backw-elim.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-org34f5a56" class="outline-4">
<h4 id="org34f5a56"><span class="section-number-4">11.2.3.</span> Stepwise regression</h4>
<div class="outline-text-4" id="text-11-2-3">
<ul class="org-ul">
<li>Combines forward selection and backward elimination
<img src="file:///Users/whkoh/git-repos/omsa-notes/isye_6501/img/m11-stepwise.png" alt="m11-stepwise.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-org788873e" class="outline-4">
<h4 id="org788873e"><span class="section-number-4">11.2.4.</span> Types of approaches</h4>
<div class="outline-text-4" id="text-11-2-4">
<ul class="org-ul">
<li>Greedy
<ul class="org-ul">
<li>Decisions are made stp by step</li>
<li>Known as <i>Greedy Algorithm</i></li>
<li>At each step, take one thing that looks best
<ul class="org-ul">
<li>Doesn't consider future options</li>
</ul></li>
</ul></li>
<li>Global (see below)</li>
</ul>
</div>
</div>
<div id="outline-container-orgbbc3570" class="outline-4">
<h4 id="orgbbc3570"><span class="section-number-4">11.2.5.</span> Lasso approach</h4>
<div class="outline-text-4" id="text-11-2-5">
<ul class="org-ul">
<li>Add constraint to standard regression equation
<ul class="org-ul">
<li>Still min SSE
\[
    \sum^m_{i=1}(y_i - (a_0 + \sum^n_{j=1}a_jx_{ij}))^2
    \]
 <b>and</b> keep:</li>
<li>Sum of coefficients less than threshold T \(\sum_{j=1}^n|a_j| \leq \tau_{\text{Lasso}}\)</li>
</ul></li>
<li>Gives regression a budget to use on coefficients
<ul class="org-ul">
<li>Most important coefficients kept</li>
<li>Others given 0</li>
</ul></li>
<li>Important to scale data and pick T correctly</li>
<li><b>Scaling</b> is important (e.g. age in years will be much bigger than age in days)</li>
<li>Picking \(T\) depends on:
<ol class="org-ol">
<li>Number of variables</li>
<li>Quality of model</li>
<li>Best tradeoff is to use LASSO method with different T values and assess</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org8a6ddbd" class="outline-4">
<h4 id="org8a6ddbd"><span class="section-number-4">11.2.6.</span> Elastic net</h4>
<div class="outline-text-4" id="text-11-2-6">
<ul class="org-ul">
<li>Constraint combination of abs. values of coefficients and their squares
\(\bar{\lambda}\sum_{j=1}^n|a_j| +(1-\bar{\lambda})\sum_{j=1}^na_j^2 \leq T\)</li>
<li>Important to scale data and pick T, \(\bar{\lambda}\) correctly</li>
</ul>
</div>
</div>
<div id="outline-container-org48d0f8a" class="outline-4">
<h4 id="org48d0f8a"><span class="section-number-4">11.2.7.</span> Ridge regression</h4>
<div class="outline-text-4" id="text-11-2-7">
<ul class="org-ul">
<li>Take out absolute value term from elastic net</li>
<li>Unlike Lasso, Ridge regression <b><b>does not</b></b> do variable selection</li>
<li>It can lead to better predictive models</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org954408a" class="outline-3">
<h3 id="org954408a"><span class="section-number-3">11.3.</span> M11L3: Lasso vs Ridge regression</h3>
<div class="outline-text-3" id="text-11-3">
<ul class="org-ul">
<li>Ridge regression is very similar to lasso
<ul class="org-ul">
<li>Lasso does variable selection, ridge does not</li>
</ul></li>
<li>The restriction for ridge regression is:
\(\sum_{j=1}^n(a_j)^2 \leq \tau_{\text{Ridge}}\)</li>
</ul>
</div>
<div id="outline-container-org5e86982" class="outline-4">
<h4 id="org5e86982"><span class="section-number-4">11.3.1.</span> The key difference</h4>
<div class="outline-text-4" id="text-11-3-1">
<ul class="org-ul">
<li>The constraint or restriction is different</li>
<li>Graphically on which points are <b>allowed</b>:
<img src="./img/m11-lasso-ridge.png" alt="m11-lasso-ridge.png" />
<ul class="org-ul">
<li>Lasso is a diamond</li>
<li>Ridge is a circle</li>
</ul></li>
<li>Which points are <b>the best</b>?
<ul class="org-ul">
<li>The total error area is a circle</li>
<li>Lasso regression shape is diamond so it is more likely to hit a point where one of the variables (of a<sub>1</sub> and a<sub>2</sub>) is zero, hence selecting the <b>other</b> variable</li>
<li>Ridge regression shape is a circle, hence it is extremely unlikely that both circles will coincide to remove one of the variables (a<sub>1</sub> or a<sub>2</sub>)</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org0895e45" class="outline-3">
<h3 id="org0895e45"><span class="section-number-3">11.4.</span> M11L4: Bias-Variance tradeoff</h3>
<div class="outline-text-3" id="text-11-4">
</div>
<div id="outline-container-org48a0ff5" class="outline-4">
<h4 id="org48a0ff5"><span class="section-number-4">11.4.1.</span> Fit and real vs random patterns</h4>
<div class="outline-text-4" id="text-11-4-1">
<ul class="org-ul">
<li>There is a natural tradeoff between more and less fit:
<dl class="org-dl">
<dt>Less fit</dt><dd>bad (less fit to real patterns); good (less fit to random patterns); underfit</dd>
<dt>More fit</dt><dd>good (better fit to real patterns); bad (more fit to random patterns); overfit</dd>
</dl></li>
<li>Put another way:
<ul class="org-ul">
<li>Less variables = less fit = underfit to real patterns
<ul class="org-ul">
<li>Less relationship between constant and response</li>
<li>Smaller coefficients</li>
<li><b>High bias</b>: misses or minimizes real effects</li>
<li><b>Low variance</b>: less diff between predictions</li>
</ul></li>
<li>More variables = more fit = overfit to random patterns
<ul class="org-ul">
<li><b>Low bias</b>: real effects ok</li>
<li><b>High variance</b>: more diff between predictions (though.. random patterns)</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc526d8c" class="outline-4">
<h4 id="orgc526d8c"><span class="section-number-4">11.4.2.</span> Summary</h4>
<div class="outline-text-4" id="text-11-4-2">
<ul class="org-ul">
<li>Difficult to model well (high fit to real; low to random)</li>
<li>Easy to model badly (choose some random variable)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgbeb77ba" class="outline-3">
<h3 id="orgbeb77ba"><span class="section-number-3">11.5.</span> M11L5: Ridge regression / regularization</h3>
<div class="outline-text-3" id="text-11-5">
</div>
<div id="outline-container-org5210856" class="outline-4">
<h4 id="org5210856"><span class="section-number-4">11.5.1.</span> Ridge regression</h4>
<div class="outline-text-4" id="text-11-5-1">
<ul class="org-ul">
<li>Reduces the <b>size</b> of coefficients if the error points start from outside the ridge regression threshold circle</li>
<li>Does not work if the error points are already inside the threshold circle
<ul class="org-ul">
<li>In this case, reduce the size of &tau;<sub>\text</sub>{Ridge} until it reaches point outside the circle</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge1085a9" class="outline-4">
<h4 id="orge1085a9"><span class="section-number-4">11.5.2.</span> Coefficients -&gt; magnitude of effect</h4>
<div class="outline-text-4" id="text-11-5-2">
<ul class="org-ul">
<li>We want to reduce the amount of fit</li>
<li>This is accomplished by reducing the magnitude of the regression coefficients</li>
<li>Ideally, reduce only fit to random patterns, however this is impossible, hence reduce fit to all</li>
<li>Reducing magnitude -&gt; reduces variance -&gt; reduce fit</li>
</ul>
</div>
</div>
<div id="outline-container-org10232e5" class="outline-4">
<h4 id="org10232e5"><span class="section-number-4">11.5.3.</span> Ridge regression limits the magnitude of the regression coefficient instead of the number of variables</h4>
<div class="outline-text-4" id="text-11-5-3">
<ul class="org-ul">
<li>This technique is also known as regularization</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org8e52124" class="outline-3">
<h3 id="org8e52124"><span class="section-number-3">11.6.</span> M11L6: Choosing a variable selection model</h3>
<div class="outline-text-3" id="text-11-6">
<ul class="org-ul">
<li>Recap on methods of variable selection:
<ul class="org-ul">
<li>Good for initial analysis but often lacks performance
<ul class="org-ul">
<li>forward</li>
<li>backward</li>
<li>stepwise regression</li>
</ul></li>
<li>Slower, better performing
<ul class="org-ul">
<li>lasso</li>
<li>elastic net</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgd931a66" class="outline-4">
<h4 id="orgd931a66"><span class="section-number-4">11.6.1.</span> Lasso vs ridge vs elastic net</h4>
<div class="outline-text-4" id="text-11-6-1">
<ul class="org-ul">
<li>Elastic net is like lasso + ridge
<ul class="org-ul">
<li>Start with lasso adds absolute value term in constraint;</li>
<li>Ridge adds quadratic (squared) term;</li>
</ul></li>
<li>Lasso: some coefficients forced to 0 to simplify model</li>
<li>Ridge: coefficients shrink towards 0 to reduce variance in estimate</li>
</ul>
</div>
</div>
<div id="outline-container-orgee33a05" class="outline-4">
<h4 id="orgee33a05"><span class="section-number-4">11.6.2.</span> Elastic net</h4>
<div class="outline-text-4" id="text-11-6-2">
<ul class="org-ul">
<li>Benefits:
<ul class="org-ul">
<li>Has variable selection like Lasso</li>
<li>Has predictive benefits like Ridge</li>
</ul></li>
<li>Downsides:
<ul class="org-ul">
<li>Rules out some correlated variables like Lasso (only one is kept but it may not be the best one)</li>
<li>Underestimates very predictive variables like Ridge</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6b3df15" class="outline-4">
<h4 id="org6b3df15"><span class="section-number-4">11.6.3.</span> Which one to use?</h4>
<div class="outline-text-4" id="text-11-6-3">
<ul class="org-ul">
<li>No good rule of thumb. Compare and contrast.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org7cc922d" class="outline-2">
<h2 id="org7cc922d"><span class="section-number-2">12.</span> Module 12: Design of Experiments</h2>
<div class="outline-text-2" id="text-12">
</div>
<div id="outline-container-org58f5662" class="outline-3">
<h3 id="org58f5662"><span class="section-number-3">12.1.</span> M12L1: Intro</h3>
<div class="outline-text-3" id="text-12-1">
<p>
What if dataset is hard to get/requires some process to get?
Examples:
</p>
<ol class="org-ol">
<li>determining which ad is better for advertising OMSA.</li>
<li>which similar or related product to show to users?</li>
<li>how to get representative sample of all relevant factors?</li>
<li>combinations of medical treatments</li>
<li>maximizing agricultural productiveness</li>
</ol>
</div>
<div id="outline-container-orgbceebc4" class="outline-4">
<h4 id="orgbceebc4"><span class="section-number-4">12.1.1.</span> Comparison and control</h4>
<div class="outline-text-4" id="text-12-1-1">
<ul class="org-ul">
<li>Answering whether red used cars sell for higher prices than blue used cars?</li>
<li>Control other factors:
<ol class="org-ol">
<li>Color</li>
<li>Age</li>
<li>Sports vs family car</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org91bed8c" class="outline-4">
<h4 id="org91bed8c"><span class="section-number-4">12.1.2.</span> Blocking</h4>
<div class="outline-text-4" id="text-12-1-2">
<ul class="org-ul">
<li>A blocking factor creates variation</li>
<li>E.g. sports car vs family car</li>
<li>Sports car more likely to be red</li>
<li>Analyzing red sports cars vs red family cars have less variance than all red cars</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9565636" class="outline-3">
<h3 id="org9565636"><span class="section-number-3">12.2.</span> M12L2: A/B testing</h3>
<div class="outline-text-3" id="text-12-2">
<p>
Choosing the best out of alternatives. Example:  banner ads: how to decide which version to show?
</p>
<ul class="org-ul">
<li>Show two different ads and how often each ad was clicked</li>
<li>This is binomial data; use hypothesis testing to test for statistical significance.</li>
</ul>
</div>
<div id="outline-container-orgb03e29d" class="outline-4">
<h4 id="orgb03e29d"><span class="section-number-4">12.2.1.</span> Required to use A/B testing</h4>
<div class="outline-text-4" id="text-12-2-1">
<ol class="org-ol">
<li>Data can be collected quickly</li>
<li>Data must be representative</li>
<li>Data collected is small vs. entire population (cost: does not make sense to spend 2000/2500 on building model. Remaining 500 too little to exploit.)</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org083fdc1" class="outline-3">
<h3 id="org083fdc1"><span class="section-number-3">12.3.</span> M12L3: Factorial design</h3>
<div class="outline-text-3" id="text-12-3">
</div>
<div id="outline-container-org75d4964" class="outline-4">
<h4 id="org75d4964"><span class="section-number-4">12.3.1.</span> Full factorial design</h4>
<div class="outline-text-4" id="text-12-3-1">
<ul class="org-ul">
<li>Test every combination and use ANOVA to determine the importance of each factor</li>
<li>Explodes with number of combinations, e.g. 7 factors x 3 choices = 3<sup>7</sup> = 2187 combinations</li>
</ul>
</div>
</div>
<div id="outline-container-orgfa67a79" class="outline-4">
<h4 id="orgfa67a79"><span class="section-number-4">12.3.2.</span> Fractional factorial design</h4>
<div class="outline-text-4" id="text-12-3-2">
<ul class="org-ul">
<li>Test subset of combinations</li>
<li>Balanced design
<ul class="org-ul">
<li>Test each choice the same # of times</li>
<li>Test each pair of choices the same # of times</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org53564cd" class="outline-4">
<h4 id="org53564cd"><span class="section-number-4">12.3.3.</span> Independent factors</h4>
<div class="outline-text-4" id="text-12-3-3">
<ul class="org-ul">
<li>Factors need to be independent</li>
<li>Test subset of combinations
<ul class="org-ul">
<li>Use regression to estimate effects</li>
</ul></li>
<li>But there still some interaction factors, e.g. white background can't be used with white font color</li>
</ul>
</div>
</div>
<div id="outline-container-org533f4cf" class="outline-4">
<h4 id="org533f4cf"><span class="section-number-4">12.3.4.</span> Summary</h4>
<div class="outline-text-4" id="text-12-3-4">
<ul class="org-ul">
<li>Factorial methods can be very useful before data is collected</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7a6aa76" class="outline-3">
<h3 id="org7a6aa76"><span class="section-number-3">12.4.</span> M12L4: Multi-armed bandits</h3>
<div class="outline-text-3" id="text-12-4">
<ul class="org-ul">
<li>What if there are &gt; 2 possible alternatives</li>
</ul>
</div>
<div id="outline-container-org8328d4e" class="outline-4">
<h4 id="org8328d4e"><span class="section-number-4">12.4.1.</span> Exploration vs exploitation</h4>
<div class="outline-text-4" id="text-12-4-1">
<ul class="org-ul">
<li>With 10 alternatives, 1000 tests on each alternative:
<ul class="org-ul">
<li>10000 test total, but only 1 is best</li>
<li>So 9000 tests lost value</li>
</ul></li>
<li>Trade-off between having more information and immediate value
<dl class="org-dl">
<dt>Exploration</dt><dd>more information</dd>
<dt>Exploitation</dt><dd>immediate value</dd>
</dl></li>
</ul>
</div>
</div>
<div id="outline-container-org2cbb5f3" class="outline-4">
<h4 id="org2cbb5f3"><span class="section-number-4">12.4.2.</span> Multi-armed bandit</h4>
<div class="outline-text-4" id="text-12-4-2">
<ul class="org-ul">
<li>Finding the slot machine with the highest payout requires testing them all</li>
<li>Each slot machine is a 'single-armed bandit'</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org4dd1508"></a>Implementation<br />
<div class="outline-text-5" id="text-12-4-2-1">
<ol class="org-ol">
<li>Start with K alternatives, no information
<ul class="org-ul">
<li>Equal probability of selecting each alternative</li>
</ul></li>
<li>Repeat
<ul class="org-ul">
<li>Choose an alternative to test
<ul class="org-ul">
<li>Based on probability of each alternative being best</li>
</ul></li>
<li>After test, update probabilities of each one being best</li>
<li>Until the best alternative is clear</li>
</ul></li>
</ol>
</div>
</li>
<li><a id="orgae16360"></a>Parameters<br />
<div class="outline-text-5" id="text-12-4-2-2">
<ul class="org-ul">
<li>Number of tests between recalculating probabilities</li>
<li>How to update probabilities</li>
<li>How to pick an alternative to test based on probabilities and / or expected values</li>
</ul>
</div>
</li>
<li><a id="orgf20cbe8"></a>Summary<br />
<div class="outline-text-5" id="text-12-4-2-3">
<ul class="org-ul">
<li>No simple rule</li>
<li>Usually better than fix/large number of tests</li>
<li>Learn faster along the fly and create more value while doing so</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org50e483f" class="outline-2">
<h2 id="org50e483f"><span class="section-number-2">13.</span> Module 13: Probability-based Models</h2>
<div class="outline-text-2" id="text-13">
</div>
<div id="outline-container-orgcc2b6b1" class="outline-3">
<h3 id="orgcc2b6b1"><span class="section-number-3">13.1.</span> M13L1: Intro</h3>
<div class="outline-text-3" id="text-13-1">
</div>
<div id="outline-container-orgefe67f9" class="outline-4">
<h4 id="orgefe67f9"><span class="section-number-4">13.1.1.</span> Simple modelling</h4>
<div class="outline-text-4" id="text-13-1-1">
<ul class="org-ul">
<li>Examples:
<ul class="org-ul">
<li>Airline security flows</li>
<li>Will season ticket owners show up?</li>
<li>Staffing fast food outlets</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5fa9e77" class="outline-4">
<h4 id="org5fa9e77"><span class="section-number-4">13.1.2.</span> Example on ticket owner not showing up</h4>
<div class="outline-text-4" id="text-13-1-2">
<ul class="org-ul">
<li>How long should we wait before selling seat upgrade?</li>
<li>Fan can pay more if they get the seat earlier, however, this increases risk that the ticket owner will arrive</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org86326cf"></a>Factors<br />
<div class="outline-text-5" id="text-13-1-2-1">
<ul class="org-ul">
<li>About ticket holder (age, children, past data)</li>
<li>About the team (standings, players, etc)</li>
<li>About the game (opponent, star players, etc)</li>
<li>Day factors (week, season, holiday)</li>
</ul>
</div>
</li>
<li><a id="org75971a4"></a>Simple model can still work better<br />
<div class="outline-text-5" id="text-13-1-2-2">
<ul class="org-ul">
<li>Probability-distribution analysis can work just as well e.g. ticket holder X tends to arrive after about 60% of other fans</li>
<li>Less dependency vs other factors</li>
<li>Just use this instead of collecting other data</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org9583824" class="outline-4">
<h4 id="org9583824"><span class="section-number-4">13.1.3.</span> Summary</h4>
<div class="outline-text-4" id="text-13-1-3">
<p>
Other examples that can work:
</p>
<ul class="org-ul">
<li>Broken equipment</li>
<li>Website purchases</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5fe2cef" class="outline-3">
<h3 id="org5fe2cef"><span class="section-number-3">13.2.</span> M13L2: Bernoulli, Binomial and Geometric Distributions</h3>
<div class="outline-text-3" id="text-13-2">
</div>
<div id="outline-container-org023a15a" class="outline-4">
<h4 id="org023a15a"><span class="section-number-4">13.2.1.</span> Bernoulli distribution</h4>
<div class="outline-text-4" id="text-13-2-1">
<ul class="org-ul">
<li>E.g., flipping a coin that's not 50:50</li>
<li>Can specify:
<dl class="org-dl">
<dt>\(p\)</dt><dd>probability it comes up heads</dd>
<dt>$$1-p</dt><dd>probability that it comes up tails</dd>
</dl></li>
<li>By itself, talks about 1 data point</li>
<li>How to relate to other data points?</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org74e6f2c"></a>Example<br />
<div class="outline-text-5" id="text-13-2-1-1">
<ul class="org-ul">
<li>P(Sends donations) = p</li>
<li>p does not differ from month to month</li>
<li>Number of donations each month is binomially distributed</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org94e3c60" class="outline-4">
<h4 id="org94e3c60"><span class="section-number-4">13.2.2.</span> Binomial distribution</h4>
<div class="outline-text-4" id="text-13-2-2">
<ul class="org-ul">
<li>Probability of getting \(x\) successes from \(n\) iid Bernoulli (\(p\)) trials</li>
<li><b><b>Large</b></b> \(n\):
<ul class="org-ul">
<li>Converges to normal distribution
<ul class="org-ul">
<li>Useful for predicting errors</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6615dc3" class="outline-4">
<h4 id="org6615dc3"><span class="section-number-4">13.2.3.</span> Geometric distribution</h4>
<div class="outline-text-4" id="text-13-2-3">
<ul class="org-ul">
<li>Probability of having \(x\) Bernoulli (\(p\)) failures until first success?
<ul class="org-ul">
<li>Equivalently: having x Bernoulli (\(1-p\)) success until first failure</li>
</ul></li>
<li>Need to define \(p\) and \(1-p\) carefully</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org8db67b1"></a>Can also answer questions about process<br />
<div class="outline-text-5" id="text-13-2-3-1">
<ul class="org-ul">
<li>If it fits geometric distribution, then hits are i.i.d. Bernoulli trials</li>
<li>If it does not fit, hits are not i.i.d., and need to consider other factors</li>
<li>Are airport screeners more likely to screen if there hasn't been a screening in a while?
<ul class="org-ul">
<li>Observe the graph and see whether it fits a geometric distribution</li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org923bfb6" class="outline-3">
<h3 id="org923bfb6"><span class="section-number-3">13.3.</span> M13L3: Poisson, Weibull and Exponential Distributions</h3>
<div class="outline-text-3" id="text-13-3">
</div>
<div id="outline-container-orgdbc0857" class="outline-4">
<h4 id="orgdbc0857"><span class="section-number-4">13.3.1.</span> Poisson</h4>
<div class="outline-text-4" id="text-13-3-1">
<ul class="org-ul">
<li>Good at modelling random  arrivals
<dl class="org-dl">
<dt>&lambda;</dt><dd>the average number of arrivals per time period</dd>
</dl></li>
<li>Arrivals are i.i.d.</li>
</ul>
</div>
</div>
<div id="outline-container-org0c93daa" class="outline-4">
<h4 id="org0c93daa"><span class="section-number-4">13.3.2.</span> Exponential distribution</h4>
<div class="outline-text-4" id="text-13-3-2">
<ul class="org-ul">
<li>Related to Poisson</li>
<li>If arrivals are Poisson(&lambda;):
<ul class="org-ul">
<li>Time between successive arrivals is distributed by exponential(&lambda;) distribution</li>
</ul></li>
<li>Poisson # of arrivals &lt;==&gt; exponential inter-arrival time</li>
</ul>
</div>
</div>
<div id="outline-container-org3aa1a3f" class="outline-4">
<h4 id="org3aa1a3f"><span class="section-number-4">13.3.3.</span> Weibull</h4>
<div class="outline-text-4" id="text-13-3-3">
<ul class="org-ul">
<li>Models the <b>time</b> between failures</li>
<li>Whereas geometric models the <b>number of tries</b> between failures</li>
<li>\(k < 1\)
<ul class="org-ul">
<li>Modelling when failure rate <b>decreases</b> with time</li>
<li>"Worst things fail first"</li>
</ul></li>
<li>\(k > 1\)
<ul class="org-ul">
<li>Modelling when failure rate <b>increases</b> with time</li>
<li>"Things that wear out" e.g. tires</li>
</ul></li>
<li>\(k = 1\)
<ul class="org-ul">
<li>Modelling when failure rate is constant with time</li>
<li>This is equal to the <b>exponential distribution</b>
<ul class="org-ul">
<li>With different notation</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgdb7f076" class="outline-4">
<h4 id="orgdb7f076"><span class="section-number-4">13.3.4.</span> Software can help but may be confusing</h4>
</div>
</div>
<div id="outline-container-org5b5f231" class="outline-3">
<h3 id="org5b5f231"><span class="section-number-3">13.4.</span> M13L4: Q-Q plots</h3>
<div class="outline-text-3" id="text-13-4">
</div>
<div id="outline-container-orgaa6c9d9" class="outline-4">
<h4 id="orgaa6c9d9"><span class="section-number-4">13.4.1.</span> Visualizing</h4>
<div class="outline-text-4" id="text-13-4-1">
<ul class="org-ul">
<li>Whether 2 distributions (different datasets) are about the same</li>
<li>Whether a dataset is distributed similarly to a probability distribution
<dl class="org-dl">
<dt>Horizontal axis</dt><dd>data</dd>
<dt>Vertical axis</dt><dd>theoretical values of percentiles of a probability distribution</dd>
</dl></li>
<li>Statistical tests work but can hide details about ranges, overall etc.</li>
</ul>
</div>
</div>
<div id="outline-container-org5c12e82" class="outline-4">
<h4 id="org5c12e82"><span class="section-number-4">13.4.2.</span> Types of Q-Q plots</h4>
<div class="outline-text-4" id="text-13-4-2">
<ul class="org-ul">
<li>Understand how to read the plots rather than memorize shapes</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1cbf477" class="outline-3">
<h3 id="org1cbf477"><span class="section-number-3">13.5.</span> M13L5: Queuing</h3>
<div class="outline-text-3" id="text-13-5">
<ul class="org-ul">
<li>Telemarketing example with autodialer in marketing</li>
</ul>
</div>
<div id="outline-container-org654c258" class="outline-4">
<h4 id="org654c258"><span class="section-number-4">13.5.1.</span> Queuing example</h4>
<div class="outline-text-4" id="text-13-5-1">
<ul class="org-ul">
<li>Qn: how many employees should we have?</li>
<li>Variables:
<ul class="org-ul">
<li>Number of people who answer the autodialer</li>
<li>Duration of call once it starts</li>
</ul></li>
<li>Probability distributions:
<ul class="org-ul">
<li>Call arrives to queue:
<ul class="org-ul">
<li>Based on probability distribution of time between arrivals</li>
</ul></li>
<li>Call finish:
<ul class="org-ul">
<li>Based on probability distribution of talking time</li>
</ul></li>
</ul></li>
<li>Call arrival e.g. poisson</li>
<li>Call duration e.g. exponential</li>
</ul>
</div>
</div>
<div id="outline-container-orgb84f60f" class="outline-4">
<h4 id="orgb84f60f"><span class="section-number-4">13.5.2.</span> More complex example</h4>
<div class="outline-text-4" id="text-13-5-2">
<ul class="org-ul">
<li>New factors:
<ul class="org-ul">
<li>Limited number of calls in queue</li>
<li>Additional employee</li>
</ul></li>
<li>New concept: <b>memoryless property</b>
<ul class="org-ul">
<li>This means it doesn't matter what happened in the past, only what's happening <b>now</b></li>
<li>E.g. memoryless exponential distribution
<ul class="org-ul">
<li>Regardless of current call duration, the <i>remaining</i> call time distribution = <i>initial</i> distribution of call time using the distribution</li>
<li>Therefore can discover from the distribution</li>
</ul></li>
<li>E.g. memoryless Posson distribution</li>
</ul></li>
<li>If data fits exponential distribution =&gt; It is memoryless</li>
<li>Otherwise, not fitting exponential distribution =&gt; not memoryless</li>
</ul>
</div>
</div>
<div id="outline-container-org904873d" class="outline-4">
<h4 id="org904873d"><span class="section-number-4">13.5.3.</span> Queuing models</h4>
<div class="outline-text-4" id="text-13-5-3">
<ul class="org-ul">
<li>Parameters:
<dl class="org-dl">
<dt>A</dt><dd>General arrival distribution</dd>
<dt>S</dt><dd>General service distribution</dd>
<dt>c</dt><dd>Number of servers</dd>
<dt>K</dt><dd>Size of queue</dd>
<dt>N</dt><dd>Population size</dd>
<dt>D</dt><dd>Queuing discipline</dd>
</dl></li>
<li>Kendall notation M/M/1 queue</li>
<li>Potential extensions:
<ul class="org-ul">
<li>Hangups, balking etc</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org3a07c75" class="outline-3">
<h3 id="org3a07c75"><span class="section-number-3">13.6.</span> M13L6: Simulation basics</h3>
<div class="outline-text-3" id="text-13-6">
</div>
<div id="outline-container-org05b14d1" class="outline-4">
<h4 id="org05b14d1"><span class="section-number-4">13.6.1.</span> Types of simulations</h4>
<div class="outline-text-4" id="text-13-6-1">
<ul class="org-ul">
<li>Random behaviour?
<ul class="org-ul">
<li>Deterministic (no randomness)
<ul class="org-ul">
<li>Same inputs give identical outputs</li>
</ul></li>
<li>Stochastic (includes randoness)
<ul class="org-ul">
<li>Outputs may differ even for identical inputs</li>
</ul></li>
</ul></li>
<li>Time
<ul class="org-ul">
<li>Continuous-time
<ul class="org-ul">
<li>Changes happen continuously</li>
<li>E.g. chemical processes, disease spread</li>
<li>Use differential equation models</li>
</ul></li>
<li>Discrete event simulations
<ul class="org-ul">
<li>The <b>focus</b></li>
<li>Example: call center simulations</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org2c453ce" class="outline-4">
<h4 id="org2c453ce"><span class="section-number-4">13.6.2.</span> Discrete-event stochastic simulations</h4>
<div class="outline-text-4" id="text-13-6-2">
<ul class="org-ul">
<li>Use when systems have high variability</li>
<li>Averages are not good enough</li>
</ul>
</div>
</div>
<div id="outline-container-org773465c" class="outline-4">
<h4 id="org773465c"><span class="section-number-4">13.6.3.</span> Simulation software</h4>
<div class="outline-text-4" id="text-13-6-3">
<ul class="org-ul">
<li>Elements include:
<dl class="org-dl">
<dt>Entities</dt><dd>things that move through simulations, e.g. bags, people</dd>
<dt>Modules</dt><dd>represent part of process, e.g. queues, storage</dd>
<dt>Actions</dt><dd>thing to do</dd>
<dt>Resources</dt><dd>e.g. workers</dd>
<dt>Decision points</dt><dd>can affect flow</dd>
</dl></li>
<li>Can output statisntics for tracking</li>
<li>Random numbers are important!</li>
</ul>
</div>
</div>
<div id="outline-container-orgda8ae8c" class="outline-4">
<h4 id="orgda8ae8c"><span class="section-number-4">13.6.4.</span> Replications</h4>
<div class="outline-text-4" id="text-13-6-4">
<ul class="org-ul">
<li>The number of runs of simulation</li>
<li>One run is insufficient due to the random nature; not representative</li>
<li>Run multiple times to get distribution of outcomes</li>
<li>E.g. simulating average throughout</li>
</ul>
</div>
</div>
<div id="outline-container-orgbf8741a" class="outline-4">
<h4 id="orgbf8741a"><span class="section-number-4">13.6.5.</span> Simulation validation</h4>
<div class="outline-text-4" id="text-13-6-5">
<ul class="org-ul">
<li>Use real data to validate that the simulation is giving valid results
<ul class="org-ul">
<li>Problems:
<ul class="org-ul">
<li>Real average differs from simulated average</li>
<li>Real variance differs from simulated variance</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org10e247c" class="outline-3">
<h3 id="org10e247c"><span class="section-number-3">13.7.</span> M13L7: Prescriptive simulation</h3>
<div class="outline-text-3" id="text-13-7">
<ul class="org-ul">
<li>Once validated simulation, use it for "what-if" questions
<ul class="org-ul">
<li>e.g. what if $1000 is invested, what is the improvement?</li>
<li>where to place baggage tugs?</li>
</ul></li>
<li>Heuristic optimization can also be possible</li>
</ul>
</div>
<div id="outline-container-org392c6ab" class="outline-4">
<h4 id="org392c6ab"><span class="section-number-4">13.7.1.</span> Simulation comparisons</h4>
<div class="outline-text-4" id="text-13-7-1">
<p>
Can be run by hand:
</p>
<ul class="org-ul">
<li>e.g. 1 tug per gate
<ul class="org-ul">
<li>vs. 1 tug per two gates</li>
</ul></li>
<li>be careful, each could be influenced by which set of random numbers are chosen
<ul class="org-ul">
<li>Use the same random numbers for comparison</li>
</ul></li>
<li>Simulation can be a powerful tool but:
<ul class="org-ul">
<li>Model only as good as input's quality</li>
<li>Missing or incorrect information leads to incorrect answers</li>
</ul></li>
<li>Example: call center simulation
<ul class="org-ul">
<li>If it assumes all workers answer calls as quickly as each other, wrong, can lead to bad decisions</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgda3ca58" class="outline-4">
<h4 id="orgda3ca58"><span class="section-number-4">13.7.2.</span> Validation can be hard</h4>
<div class="outline-text-4" id="text-13-7-2">
<ul class="org-ul">
<li>Especially if it's something that doesn't exist</li>
</ul>
</div>
</div>
<div id="outline-container-org0ab326e" class="outline-4">
<h4 id="org0ab326e"><span class="section-number-4">13.7.3.</span> Simulation/validation should consider all processes</h4>
<div class="outline-text-4" id="text-13-7-3">
<ul class="org-ul">
<li>E.g. data collection</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgb0eda6f" class="outline-3">
<h3 id="orgb0eda6f"><span class="section-number-3">13.8.</span> M13L8: Markov chains</h3>
<div class="outline-text-3" id="text-13-8">
<ul class="org-ul">
<li>Based on states, e.g. cloudy, sunny, etc</li>
<li>For each state <i>i</i>,
<ul class="org-ul">
<li>p<sub>ij</sub> = transition probability from state <i>i</i> to state <i>j</i></li>
<li>P = {p<sub>ij</sub>} is the transition matrix</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orge2157f1" class="outline-4">
<h4 id="orge2157f1"><span class="section-number-4">13.8.1.</span> Answering questions with the transition matrix</h4>
<div class="outline-text-4" id="text-13-8-1">
<ul class="org-ul">
<li>What's the long-run probability of rainy days?</li>
<li>&pi; = (0.5, 0.25, 0.25) for (Sunny, Cloudy, Rainy)</li>
<li>&pi; &times; P = (0.525, 0.25, 0.225) the probabilities of (Sunny, Cloudy, Rainy) tomorrow</li>
<li>&pi; &times; P<sup>2</sup> &#x2026;</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org4cfa51d"></a>Long term probability?<br />
<div class="outline-text-5" id="text-13-8-1-1">
<ul class="org-ul">
<li>Use steady state to apply P and get the initial vector back
<ul class="org-ul">
<li>&pi; &times; P = &pi;</li>
</ul></li>
<li>Solve for &pi; P = &pi; and &sum;<sub>i</sub> &pi;<sub>i</sub> = 1</li>
<li>Not always a steady state</li>
<li><b><b>Steady state only exists when:</b></b>
<ol class="org-ol">
<li>possible to get from one state to all other states</li>
<li>no cyclic behaviour</li>
</ol></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org73f76ad" class="outline-4">
<h4 id="org73f76ad"><span class="section-number-4">13.8.2.</span> Key assumption</h4>
<div class="outline-text-4" id="text-13-8-2">
<ul class="org-ul">
<li>Memoryless:
<ul class="org-ul">
<li>State transitions only depend on <b>most recent</b> state
<ul class="org-ul">
<li>E.g. weather: tomorrow's only depends on today's</li>
</ul></li>
</ul></li>
<li>Most systems are not memoryless
<ul class="org-ul">
<li>But still useful because it's still useful e.g. for PageRank</li>
</ul></li>
<li>Other applications
<ol class="org-ol">
<li>Rank basketball teams</li>
<li>Urban sprawl, population, disease</li>
</ol></li>
<li>Markov chains can still work in long-run even if not memoryless in short-run</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org69eb982" class="outline-2">
<h2 id="org69eb982"><span class="section-number-2">14.</span> Module 14: Missing Data</h2>
<div class="outline-text-2" id="text-14">
</div>
<div id="outline-container-orgf349244" class="outline-3">
<h3 id="orgf349244"><span class="section-number-3">14.1.</span> M14L01: Intro to missing data</h3>
<div class="outline-text-3" id="text-14-1">
</div>
<div id="outline-container-orga420d23" class="outline-4">
<h4 id="orga420d23"><span class="section-number-4">14.1.1.</span> When is there missing data?</h4>
<div class="outline-text-4" id="text-14-1-1">
<ol class="org-ol">
<li>Broken collection equipment</li>
<li>Transmission breaks down</li>
<li>Human interaction (wrong forms, unavailable data, etc)</li>
</ol>
</div>
</div>
<div id="outline-container-orgf699bce" class="outline-4">
<h4 id="orgf699bce"><span class="section-number-4">14.1.2.</span> Data problems</h4>
<div class="outline-text-4" id="text-14-1-2">
<ul class="org-ul">
<li>Missing data</li>
<li>Incorrect data</li>
<li>There are often patterns in missing or wrong data</li>
<li>Extremely wrong: <i>outlier</i></li>
</ul>
</div>
</div>
<div id="outline-container-orgf289d5c" class="outline-4">
<h4 id="orgf289d5c"><span class="section-number-4">14.1.3.</span> Patterns in missing data</h4>
<div class="outline-text-4" id="text-14-1-3">
<ul class="org-ul">
<li>How easy is it to collect/observe data?</li>
<li>Income (higher income household might choose to omit)</li>
<li>Radar gun accuracy/reliability</li>

<li>If missing data is biased in some way, need additional methods to deal with it</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org034a0f7" class="outline-3">
<h3 id="org034a0f7"><span class="section-number-3">14.2.</span> M14L02: Methods not requiring imputation</h3>
<div class="outline-text-3" id="text-14-2">
</div>
<div id="outline-container-org9932aeb" class="outline-4">
<h4 id="org9932aeb"><span class="section-number-4">14.2.1.</span> Dealing with missing data</h4>
<div class="outline-text-4" id="text-14-2-1">
<ol class="org-ol">
<li>Discard records</li>
<li>Indicate with categorical variables</li>
<li>Estimate missing value</li>
</ol>
</div>
</div>
<div id="outline-container-org63042aa" class="outline-4">
<h4 id="org63042aa"><span class="section-number-4">14.2.2.</span> Discard records</h4>
<div class="outline-text-4" id="text-14-2-2">
<ul class="org-ul">
<li>Pros:
<ul class="org-ul">
<li>Easy to implement</li>
<li>Does not introduce errors</li>
</ul></li>
<li>Cons:
<ul class="org-ul">
<li>Data point is lost</li>
<li>Potentially censors or biases missing data (e.g. high income not reporting income)</li>
</ul></li>
<li>Check pattern of missing data!</li>
</ul>
</div>
</div>
<div id="outline-container-org36e6c8d" class="outline-4">
<h4 id="org36e6c8d"><span class="section-number-4">14.2.3.</span> Categorical variable approach</h4>
<div class="outline-text-4" id="text-14-2-3">
<ol class="org-ol">
<li>Qualitative field
<ol class="org-ol">
<li>Add category: `missing`</li>
</ol></li>
<li>Quantitative field
<ol class="org-ol">
<li>Set missing to \(0\)</li>
<li>Add new categorical variable `missing`</li>
<li>Create interaction terms. This become similar to a tree-model if interaction terms are created for all variables</li>
</ol></li>
</ol>
</div>
</div>
<div id="outline-container-orgb89d67a" class="outline-4">
<h4 id="orgb89d67a"><span class="section-number-4">14.2.4.</span> Summary</h4>
<div class="outline-text-4" id="text-14-2-4">
<p>
This lesson's approach avoids estimating the missing data.
</p>
</div>
</div>
</div>
<div id="outline-container-org46a865b" class="outline-3">
<h3 id="org46a865b"><span class="section-number-3">14.3.</span> M14L03: Imputation methods</h3>
<div class="outline-text-3" id="text-14-3">
</div>
<div id="outline-container-orge8008b2" class="outline-4">
<h4 id="orge8008b2"><span class="section-number-4">14.3.1.</span> Mid-range value</h4>
<div class="outline-text-4" id="text-14-3-1">
<p>
Mean or median (numeric) or mode (categorical)
</p>
<ul class="org-ul">
<li>Pros:
<ul class="org-ul">
<li>Will not be too wrong</li>
<li>Simple</li>
</ul></li>
<li>Cons:
<ul class="org-ul">
<li>Biased imputation if the missing data is biased</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgafbd343" class="outline-4">
<h4 id="orgafbd343"><span class="section-number-4">14.3.2.</span> Regression</h4>
<div class="outline-text-4" id="text-14-3-2">
<ul class="org-ul">
<li>Pros:
<ul class="org-ul">
<li>Reduce or eliminates bias.</li>
</ul></li>
<li>Cons:
<ul class="org-ul">
<li>Could be over-fitting as regression is used to fit model and to predict.</li>
<li>Complex to build, fit, validate, test</li>
<li>Doesn't capture all variability in the rest of the data.
<ul class="org-ul">
<li>The same imputed amount will be assigned to all with similar predictors.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org7cceeba" class="outline-4">
<h4 id="org7cceeba"><span class="section-number-4">14.3.3.</span> Regression with perturbation (imputation with variability)</h4>
<div class="outline-text-4" id="text-14-3-3">
<ul class="org-ul">
<li>Adds some randomness (perturbation) to each imputed value</li>
<li>E.g., normally distributed variation</li>
<li>Less accurate predictions on average, but:</li>
<li>More accurate variability</li>
</ul>
</div>
</div>
<div id="outline-container-org4471080" class="outline-4">
<h4 id="org4471080"><span class="section-number-4">14.3.4.</span> Imputation approaches</h4>
<div class="outline-text-4" id="text-14-3-4">
<ul class="org-ul">
<li>Data used twice (over-fits)</li>
<li>Limit to max 5% per factor</li>
<li>Does imputation cause additional error?
<ol class="org-ol">
<li>Imputation error</li>
<li>Perturbation error</li>
<li>Model error</li>
</ol></li>
<li>Yes, but regular data also has errors most times</li>
</ul>
</div>
</div>
<div id="outline-container-org4ef72ac" class="outline-4">
<h4 id="org4ef72ac"><span class="section-number-4">14.3.5.</span> Summary</h4>
<div class="outline-text-4" id="text-14-3-5">
<ul class="org-ul">
<li>Data is always imperfect
<ul class="org-ul">
<li>Errors</li>
<li>Outliers</li>
<li>Missing data</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org4747747" class="outline-2">
<h2 id="org4747747"><span class="section-number-2">15.</span> Module 15: Optimization</h2>
<div class="outline-text-2" id="text-15">
<p>
Key underlying part of descriptive and prescriptive analytics.
</p>
</div>
<div id="outline-container-org191020e" class="outline-3">
<h3 id="org191020e"><span class="section-number-3">15.1.</span> M15L01: Intro to Optimization</h3>
<div class="outline-text-3" id="text-15-1">
</div>
<div id="outline-container-orga689a52" class="outline-4">
<h4 id="orga689a52"><span class="section-number-4">15.1.1.</span> Examples</h4>
<div class="outline-text-4" id="text-15-1-1">
<ul class="org-ul">
<li>Schedule airplane mechanics</li>
<li>Plan crude oil shipments</li>
<li>Allocate server farms</li>
<li>Schedule machine shop</li>
<li>Route car routes</li>
<li>Define asset usage</li>
<li>Determine sports draft</li>
<li>Route and deliver worldwide oil</li>
<li>Plan electricity generation based on weather patterns</li>
</ul>
</div>
</div>
<div id="outline-container-org22ab7c4" class="outline-4">
<h4 id="org22ab7c4"><span class="section-number-4">15.1.2.</span> Optimization provides direction for an organization</h4>
<div class="outline-text-4" id="text-15-1-2">
<ul class="org-ul">
<li>Sits on top of descriptive and predictive analytics</li>
</ul>
</div>
</div>
<div id="outline-container-orgf556079" class="outline-4">
<h4 id="orgf556079"><span class="section-number-4">15.1.3.</span> Optimization software</h4>
<div class="outline-text-4" id="text-15-1-3">
<ul class="org-ul">
<li>Model building automatically in software is still not available</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf1efcf6" class="outline-3">
<h3 id="orgf1efcf6"><span class="section-number-3">15.2.</span> M15L02: Elements of Optimization Models</h3>
<div class="outline-text-3" id="text-15-2">
<dl class="org-dl">
<dt>Variables</dt><dd>decisions to be made</dd>
<dt>Constraints</dt><dd>restrictions on values of variables</dd>
<dt>Objective function</dt><dd>measure of quality of solution</dd>
<dt>Solution</dt><dd>value for each variable</dd>
<dt>Feasible solution</dt><dd>variable value that satisfy all constraints</dd>
<dt>Optimal solution</dt><dd>feasible solution with the <b><b>best</b></b> objective value</dd>
</dl>
</div>
</div>
<div id="outline-container-orgf33236a" class="outline-3">
<h3 id="orgf33236a"><span class="section-number-3">15.3.</span> M15L03: Optimization is an art</h3>
<div class="outline-text-3" id="text-15-3">
</div>
<div id="outline-container-org51de984" class="outline-4">
<h4 id="org51de984"><span class="section-number-4">15.3.1.</span> Examples</h4>
<div class="outline-text-4" id="text-15-3-1">
</div>
<ol class="org-ol">
<li><a id="org78b48e3"></a>US Army diet<br />
<div class="outline-text-5" id="text-15-3-1-1">
<ul class="org-ul">
<li>US Army diet problem: what to feed soldiers at minimum cost?
<ul class="org-ul">
<li>\(n\) foods</li>
<li>\(m\) nutritional value</li>
<li>\(a_{ij}\) amount of nutrition \(j\) per unit of food \(i\)</li>
<li>\(m_j\) min daily intake of nutrient \(j\)</li>
<li>\(M_j\) Max daily intake of nutrient \(j\)</li>
<li>\(c_i\) per-unit cost of food \(i\)</li>
</ul></li>
<li>Optimization model
<ul class="org-ul">
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>the amount of food \(i\) in daily diet</dd>
</dl></li>
<li>Constraints
<dl class="org-dl">
<dt>\(\sum_i a_{ij}x_i \gt m_j\)</dt><dd>for each nutrient \(j\)</dd>
<dt>\(\sum_i a_{ij}x_i\) &le; M<sub>j</sub></dt><dd>for each nutrient \(j\)</dd>
<dt>\(x_i \geq 0\) </dt><dd>for each food \(i\)</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Minimize \(\sum_i c_i x_i\)</li>
</ul></li>
</ul></li>
<li>Complexities in model
<ul class="org-ul">
<li>Variety in diets</li>
<li>Seasonal cost might differ</li>
<li>Food might not taste good in general</li>
<li>Food might not taste good in combination</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="orgb0fcca6"></a>Call center scheduling<br />
<div class="outline-text-5" id="text-15-3-1-2">
<ul class="org-ul">
<li>Meet forecast demand \(d_i\) for each day of week \(i\)
<ul class="org-ul">
<li>Workers work 5 days then rest 2 days</li>
<li>Minimize worker-days total</li>
</ul></li>
<li>Wrong model:
<ul class="org-ul">
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>number of people working on day \(i\)</dd>
</dl></li>
<li>Constraints
<dl class="org-dl">
<dt>\(x_i \geq d_i\)</dt><dd>meet demand</dd>
<dt>\(int(x_i)\)</dt><dd>\(x_i\) is integer for all days \(i\)</dd>
<dt>??</dt><dd>5-day requirement</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Minimize \(x_{\text{Sunday}} + x_{\text{Monday}} + ... + x_{\text{Saturday}}\)</li>
</ul></li>
<li>Difficult to model!</li>
</ul></li>
<li>Right model:
<ul class="org-ul">
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>number of people who <b>start</b> working on day \(i\)</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Minimize $5 &times; \(x_{\text{Sunday}} + x_{\text{Monday}} + ... + x_{\text{Saturday}}\)</li>
</ul></li>
<li>Constraints
<dl class="org-dl">
<dt>\(\sum_j \text{working on day i} x_j \geq d_i\)</dt><dd>meet demand
<ul class="org-ul">
<li>Example: \(x_{fri} + ... + x_{tue} \geq d_{tue}\)</li>
</ul></dd>
<dt>\(x_i \geq 0\)</dt><dd>non negative for all days \(i\)</dd>
<dt>\(int(x_i)\)</dt><dd>\(x_i\) is integer for all days \(i\)</dd>
</dl></li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org440d8bb" class="outline-3">
<h3 id="org440d8bb"><span class="section-number-3">15.4.</span> M15L04: Modeling with binary variables</h3>
<div class="outline-text-3" id="text-15-4">
</div>
<div id="outline-container-orgbce793b" class="outline-4">
<h4 id="orgbce793b"><span class="section-number-4">15.4.1.</span> Example: stock market investment</h4>
<div class="outline-text-4" id="text-15-4-1">
<p>
Invest to balance risk and return
</p>
<ul class="org-ul">
<li>Where:
<dl class="org-dl">
<dt>\(B\)</dt><dd>investment budget</dd>
<dt>\(n\)</dt><dd>number of stocks available</dd>
<dt>\(r_i\)</dt><dd>expected return of stock \(i\) relative to market</dd>
<dt>\(Q_{ij}\)</dt><dd>covariance of returns of stocks \(i\) and \(j\)</dd>
</dl></li>
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>amount invested in stock \(i\)</dd>
</dl></li>
<li>Constraints
<dl class="org-dl">
<dt>\(\sum_ix_i \leq B\)</dt><dd>can meet budget</dd>
<dt>\(x_i \geq 0\)</dt><dd>no shorting</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Maximize \(\sum_ir_ix_i - \theta \sum_i\sum_jQ_{ij}x_ix_j\)
<ul class="org-ul">
<li>first part is return</li>
<li>second part is risk</li>
</ul></li>
</ul></li>
<li>To consider: transaction fees
<ul class="org-ul">
<li>But no binary indicators if transaction fee is paid or not paid. Can create \(y_i = 1\) if invest, else 0</li>
<li>New objective function: Maximize \(\sum_ir_ix_i - \theta \sum_i\sum_jQ_{ij}x_ix_j - \sum_ity_i\)</li>
<li>New additional constraint: \(x_i \leq By_i\), which in effect means:
<ul class="org-ul">
<li>when \(y_i = 0\): \(x_i \leq 0\)</li>
<li>when \(y_i = 1\): \(x_i \leq B\)</li>
</ul></li>
</ul></li>
<li>To consider: minimum investment in each stock
<ul class="org-ul">
<li>New term \(m_i\): the minimum dollar amount invested in stock \(i\)</li>
<li>New constraint: \(x_i \geq m_iy_i\) for all stocks \(i\)</li>
</ul></li>
<li>To consider: personal constraints e.g. can only invest in Tesla; AMZN, GOOG, AAPL
<ul class="org-ul">
<li>\(y_{Tesla} = 1\) or \(y_{Amazon} + y_{Google} + y_{Apple} \geq 1\)</li>
</ul></li>
<li>Related constraints, e..g if invest in energy stock, must invest in at least 5
<ul class="org-ul">
<li>Change constraint: sum \(y_i\) for energy stocks \(\geq y_i\) for the 5 energy stocks</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgce9e97d" class="outline-4">
<h4 id="orgce9e97d"><span class="section-number-4">15.4.2.</span> Recap uses of integer variables in optimization</h4>
<div class="outline-text-4" id="text-15-4-2">
<ul class="org-ul">
<li>Fixed charges</li>
<li>Constraints in terms of choosing options</li>
<li>Constraints in requiring same or opposite choices</li>
<li>If/then constraints</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge1c5584" class="outline-3">
<h3 id="orge1c5584"><span class="section-number-3">15.5.</span> M15L05: Discovering the real questions</h3>
<div class="outline-text-3" id="text-15-5">
</div>
<div id="outline-container-org362d812" class="outline-4">
<h4 id="org362d812"><span class="section-number-4">15.5.1.</span> Real life</h4>
<div class="outline-text-4" id="text-15-5-1">
<ul class="org-ul">
<li>Is often less specific, with information isn't fully specified or available</li>
<li>Discovery is hard
<ol class="org-ol">
<li>Too many constraints to remember or recite</li>
<li>Easy to forget obscure ones</li>
<li>Easy to omit "obvious" ones
<ol class="org-ol">
<li>E.g. 5-day work week definition</li>
<li>E.g. partial shifts</li>
</ol></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org94fc2b2" class="outline-4">
<h4 id="org94fc2b2"><span class="section-number-4">15.5.2.</span> Summary</h4>
<div class="outline-text-4" id="text-15-5-2">
<ul class="org-ul">
<li>Need to discover details:
<ul class="org-ul">
<li>Constraints, objective function, etc</li>
</ul></li>
<li><i>Potentially</i>, build other models to determine inputs for optimization</li>
<li>Iterate between:
<ol class="org-ol">
<li>Build model</li>
<li>Optimize</li>
<li>Get feedback</li>
<li>Tweak/build model</li>
</ol></li>
<li>Applies to other analytics/data science modelling</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org520a1b1" class="outline-2">
<h2 id="org520a1b1"><span class="section-number-2">16.</span> Module 16: Advanced Models</h2>
<div class="outline-text-2" id="text-16">
<blockquote>
<p>
Midterm 2: modules 11-16 (from variable selection to optimization and advanced models) &#x2013; weeks 8-12
</p>
</blockquote>
</div>
<div id="outline-container-org5ab56af" class="outline-3">
<h3 id="org5ab56af"><span class="section-number-3">16.1.</span> M16L01: Non-parametric methods</h3>
<div class="outline-text-3" id="text-16-1">
<blockquote>
<p>
In this text, Joel Sokol, Director of the Master of Science and Analytics degree at Georgia Tech, explains three non-parametric statistical tests: McNamara's Test, Wilcoxon signed rank test, and Mann-Whitney test.
</p>

<p>
These tests are not advanced analytics methods, but they are not usually covered in basic statistics prerequisites.
</p>

<p>
McNamara's test is used to compare two competing treatments when they are tested on different patients, and there is no underlying distribution.
</p>

<p>
Wilcoxon signed rank test is used when we have no assumptions about what the response function is mathematically, and we only assume that it is continuous and symmetric. The test answers whether the median of the distribution is different from a specific value M.
</p>

<p>
Mann-Whitney test is used to compare two samples where the outcomes are not paired, and we assume that all the observations are independent of each other.
</p>
</blockquote>
</div>
<div id="outline-container-org318dc49" class="outline-4">
<h4 id="org318dc49"><span class="section-number-4">16.1.1.</span> Non-parametric tests: Statistics tests when the distribution is unknown</h4>
</div>
<div id="outline-container-org167948c" class="outline-4">
<h4 id="org167948c"><span class="section-number-4">16.1.2.</span> McNemar's test is paired</h4>
<div class="outline-text-4" id="text-16-1-2">
<ul class="org-ul">
<li>Compare results on <b>pairs</b> of responses</li>
<li>eg: two different treatments for a virus
<ul class="org-ul">
<li>Treatment A or B better?</li>
<li>Are the observations just luck?</li>
</ul></li>
<li>Analysis is using p-value similar to a 'normal' hypothesis test</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org69c6406"></a>Summary<br />
<div class="outline-text-5" id="text-16-1-2-1">
<ul class="org-ul">
<li>McNemar's (Binomial) test: Only consider when A and B are different.</li>
<li>Does not require or assume knowledge about the distribution.</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org77de03c" class="outline-4">
<h4 id="org77de03c"><span class="section-number-4">16.1.3.</span> Wilcoxon Signed Rank Test for Medians</h4>
<div class="outline-text-4" id="text-16-1-3">
<ul class="org-ul">
<li>Assumption:
<ol class="org-ol">
<li>Distribution is continuous</li>
<li>Distribution is symmetric</li>
</ol></li>
<li>Question:
<ul class="org-ul">
<li>Is the <b>median</b> of the distribution different from a value \(m\)?</li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org2f12271"></a>Procedure<br />
<div class="outline-text-5" id="text-16-1-3-1">
<ol class="org-ol">
<li>With responses y<sub>1</sub> to y<sub>n</sub></li>
<li>Rank |y<sub>1</sub>-y<sub>m</sub>|, &#x2026;., |y<sub>n</sub>-y<sub>m</sub>| from smallest to largest</li>
<li>\(W = \sum_{y_i>m}\text{rank}(y_i-m)\) is the sum of all ranks where y<sub>i</sub> &gt; m</li>
<li>p-value test for \(W\)</li>
</ol>
</div>
</li>
<li><a id="orgda66ad5"></a>Question<br />
<div class="outline-text-5" id="text-16-1-3-2">
<ol class="org-ol">
<li>Given pairs (y<sub>1</sub>, z<sub>1</sub>), &#x2026;, (y<sub>n</sub>, z<sub>n</sub>) from observations y and z</li>
<li>Use |y<sub>1</sub>-z<sub>1</sub>|, &#x2026;, |y<sub>n</sub>-z<sub>n</sub>| for rank test</li>
</ol>
</div>
</li>
<li><a id="org80ad8ae"></a>Comparison<br />
<div class="outline-text-5" id="text-16-1-3-3">
<ul class="org-ul">
<li>For numeric data, use the Wilcoxon test</li>
<li>For binary data, use McNemar's test</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org9771474" class="outline-4">
<h4 id="org9771474"><span class="section-number-4">16.1.4.</span> Mann-Whitney test</h4>
<div class="outline-text-4" id="text-16-1-4">
<ul class="org-ul">
<li>Use when there are two datasets but no paired samples</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org5590149"></a>Procedure<br />
<div class="outline-text-5" id="text-16-1-4-1">
<ol class="org-ol">
<li>Given independent observations y<sub>1</sub>, &#x2026;, y<sub>n</sub> and z<sub>1</sub>, &#x2026;, z<sub>m</sub></li>
<li>Rank all observations</li>
<li>U = smaller of two adjusted rank sums
\[
   U = min(U_y, U_z) \\
   U_y = \sum^n_{i=1}\text{rank}(y_i)-\frac{n(n+1)}{2} \\
   U_z = \sum^m_{j=1}\text{rank}(z_j)-\frac{m(m+1)}{2}
   \]</li>
<li>Find significance with software or a statistical table</li>
</ol>
</div>
</li>
</ol>
</div>
<div id="outline-container-orga22ed5c" class="outline-4">
<h4 id="orga22ed5c"><span class="section-number-4">16.1.5.</span> Summary from video</h4>
<div class="outline-text-4" id="text-16-1-5">

<div id="org2cd7eff" class="figure">
<p><img src="./img/m16-nonparam-tests-flow.png" alt="m16-nonparam-tests-flow.png" />
</p>
</div>
<ul class="org-ul">
<li>Use non-parametric tests when you know nothing about distribution</li>
<li># datasets = 2
<dl class="org-dl">
<dt>Paired Yes/No</dt><dd>use McNemar's test</dd>
<dt>Paired Numeric</dt><dd>use Wilcoxon signed rank test</dd>
<dt>Unpaired doubles</dt><dd>use Mann-Whitney test</dd>
</dl></li>
<li># datasets = 1
<dl class="org-dl">
<dt>Compare possible median</dt><dd>use Wilcoxon signed rank test</dd>
</dl></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org4de77c2" class="outline-3">
<h3 id="org4de77c2"><span class="section-number-3">16.2.</span> M16L01a: Matching tests for situations</h3>
<div class="outline-text-3" id="text-16-2">
</div>
<div id="outline-container-org6a6b727" class="outline-4">
<h4 id="org6a6b727"><span class="section-number-4">16.2.1.</span> Summary</h4>
<div class="outline-text-4" id="text-16-2-1">
<blockquote>
<p>
This lesson discusses how to choose the appropriate statistical test for different types of situations.
</p>

<p>
The different types of tests include parametric tests, non-parametric tests related to the median, and a specific type of non-parametric test that tracks successes and failures.
</p>

<p>
The lesson also covers two aspects of choosing the right statistical test: determining whether to use a one or two sample test, and deciding which type of test to use depending on the type of data involved.
</p>

<p>
Finally, the lesson provides an example to illustrate how to choose the appropriate test in a given situation.
</p>

<ol class="org-ol">
<li>Which type of test would you use if you are analyzing the mean of a single data set?
A. One sample parametric test
B. Two sample parametric test
C. One sample non-parametric test
D. Paired binomial-based test</li>

<li>When comparing two data sets, which test would you use if the data sets are not inherently paired?
A. Paired parametric test
B. Unpaired parametric test
C. Paired non-parametric test
D. Unpaired binomial-based test</li>

<li>If you are analyzing the median of two data sets, which type of test should you use?
A. Parametric test
B. Non-parametric test
C. Binomial-based test
D. Paired test</li>

<li>In a situation where you are analyzing binary outcomes such as successes or failures, which type of test should you use?
A. Parametric test
B. Non-parametric test
C. Binomial-based test
D. Paired test</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-org695c947" class="outline-4">
<h4 id="org695c947"><span class="section-number-4">16.2.2.</span> Summary from lecture</h4>
<div class="outline-text-4" id="text-16-2-2">

<div id="org87b8b71" class="figure">
<p><img src="./img/m16-np-testing-types.png" alt="m16-np-testing-types.png" />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org068a2d2" class="outline-3">
<h3 id="org068a2d2"><span class="section-number-3">16.3.</span> M16L02: Bayesian modeling</h3>
<div class="outline-text-3" id="text-16-3">
<blockquote>
<p>
The passage introduces Bayesian models and their usage in analytics. It explains the basics of Bayes rule, which is a rule of conditional probability, and provides an example of using Bayes theorem to calculate the probability of having a disease given a positive test. The passage also describes empirical Bayes modeling, which is commonly used when there is little data available for a specific case. An example of using empirical Bayes modeling to estimate the strength difference between two basketball teams is provided, which shows how the model can make a prediction based on a single observation and a broader set of relevant observations. The passage emphasizes that understanding the intuition behind Bayesian models is crucial in explaining them to decision-makers who may not have a mathematical background.
</p>

<ol class="org-ol">
<li>What is the purpose of the examples given in the passage?
A. To show that Bayesian models are more difficult than other models.
B. To demonstrate how counter-intuitive results can arise from Bayesian models.
C. To explain how to calculate the probability of having a disease given a positive test.
D. To provide examples of how to estimate the strength difference between basketball teams.</li>
<li>What is Bayes rule or Bayes theorem?
A. A rule of conditional probability.
B. A way to estimate the strength difference between basketball teams.
C. A formula to calculate the probability of having a disease given a positive test.
D. A model that predicts outcomes of the NCAA basketball tournament.</li>
<li>What is empirical Bayes modeling commonly used for?
A. When there is a lot of data available for a specific case.
B. When the overall distribution of something is not known or estimated.
C. When there is little data available for a specific case.
D. When there is only one observation available for a specific case.</li>
<li>What is the main takeaway from the passage?
A. Bayesian models are more complicated than other models.
B. Bayesian models can only be understood by decision-makers with a mathematical background.
C. Bayesian models can be very helpful, especially in the absence of lots of data.
D. Bayesian models are not useful for making predictions based on a single observation.</li>
</ol>
</blockquote>
</div>

<div id="outline-container-org2b985bd" class="outline-4">
<h4 id="org2b985bd"><span class="section-number-4">16.3.1.</span> Bayesian models</h4>
<div class="outline-text-4" id="text-16-3-1">
<ul class="org-ul">
<li>Conditional probability: Baye's rule
\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</li>
<li>Eg Medical test for disease
<ul class="org-ul">
<li>TP = 98%</li>
<li>FP = 8%</li>
<li>1% of population has disease</li>
<li>8.9% of population test +ve</li>
<li><b>Question</b>: if someone tests +ve, what is the probability they have disease?
<ul class="org-ul">
<li>A: has disease</li>
<li>B: tested +ve, hence</li>
<li>P(A|B) = 98%*1%/8.9% = 11%</li>
<li>It means that after testing +ve, only 11% chance of actually having disease</li>
<li>Because: many more people don't actually have the disease, so many more FP than TP.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9705022" class="outline-4">
<h4 id="org9705022"><span class="section-number-4">16.3.2.</span> Empirical Bayes modeling</h4>
<div class="outline-text-4" id="text-16-3-2">
<ul class="org-ul">
<li>Overall distribution is known, or is estimated
<ul class="org-ul">
<li>But only sample data is available</li>
</ul></li>
<li>Eg predicting outcomes of NCAA basketball
<ul class="org-ul">
<li>Let \(X\) = difference in points scored by home vs road team</li>
<li>X has normal distribution \(X\sim N(m+h,\sigma^2)\)</li>
<li>\(h\): home court advantage</li>
<li>\(m\): true diff in team strength, which is unknown</li>
<li>\(\sigma^2\): variance</li>
<li>Difference can be modelled as \(m\sim (0,\tau^2)\)</li>
<li>Observed data:
<ul class="org-ul">
<li>\(x\) = observed point distance</li>
<li>\(m\) = real difference, but \(m \neq x\)</li>
</ul></li>
<li>\[
    P(M=m|X=x) = \frac{P(X=x|M=m)P(M=m)}{P(X=x)} \\
    M|X = x\sim N(\frac{\tau^2}{\tau^2+\sigma^2}(x-h),
    \frac{\tau^2\sigma^2}{\tau^2+\sigma^2})
    \]</li>
<li>Get &sigma;, &tau;, \(h\) from past data and then:
<ul class="org-ul">
<li>\(\int^\infty_0 P(M=m|X=x)dm\)</li>
</ul></li>
<li>If home team won by 20 pts,
<ul class="org-ul">
<li>home court advantage \(h\) is &asymp; 4</li>
<li>std dev in team strength diff &tau; &asymp; 6</li>
<li>std error from variance &sigma; &asymp; 11</li>
</ul></li>
<li>Interpretation: most of the points is explained by randomness and only 3.5 pts is explained by actual difference in strength</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgbad2dd9" class="outline-4">
<h4 id="orgbad2dd9"><span class="section-number-4">16.3.3.</span> Lecture summary</h4>
<div class="outline-text-4" id="text-16-3-3">
<ul class="org-ul">
<li>Even a single observation, when combined with a broader set of observations, can make a deduction or prediction</li>
<li>Bayesian models work especially when we don't have lots of data</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org964fc1a" class="outline-3">
<h3 id="org964fc1a"><span class="section-number-3">16.4.</span> M16L03: Communities in graphs</h3>
<div class="outline-text-3" id="text-16-4">
</div>
<div id="outline-container-org8fb54a0" class="outline-4">
<h4 id="org8fb54a0"><span class="section-number-4">16.4.1.</span> Transcript summary</h4>
<div class="outline-text-4" id="text-16-4-1">
<p>
The lesson introduces a model called the Louvain algorithm for finding highly interconnected subpopulations in large interconnected populations, such as social media networks, disease outbreaks, computer viruses, language spread, and terrorist networks.
</p>

<p>
The lesson explains the standard terminology used in graph theory, including nodes, edges, cliques, and communities. The Louvain algorithm maximizes the modularity of a graph, a measure of how well the graph is separated into communities that are highly connected internally but not much between each other.
</p>

<p>
The algorithm has a few mostly repeated steps, including creating super-nodes and super-arcs between communities. Although the Louvain algorithm is a heuristic and not guaranteed to find the best partition of a graph, it often provides good solutions quickly and is useful for finding communities in large networks.
</p>

<ol class="org-ol">
<li>What is the Louvain algorithm used for?
A. Solving mathematically hard problems
B. Finding highly interconnected subpopulations in large interconnected populations
C. Separating a graph into communities that are highly connected between each other
D. Maximizing the weight of arcs in a graph</li>

<li>What is a clique in graph theory?
A. A small group of people who stick together and exclude others
B. A set of nodes that all have edges between each other
C. The total weight of all the arcs connected to a node
D. A measure of how well a graph is separated into communities</li>

<li>What is the modularity of a graph?
A. A measure of how well a graph is separated into communities that are highly connected internally but not much between each other
B. The total weight of all the arcs in a graph
C. The weight of an arc between two nodes in a graph
D. The weight of a node in a graph</li>

<li>Is the Louvain algorithm guaranteed to find the absolute best partition of a graph into communities?
A. Yes, it always finds the absolute best partition of a graph into communities.
B. No, it's not guaranteed to find the absolute best partition of a graph into communities because it's a heuristic.
C. It depends on the size of the graph.
D. It depends on the number of nodes in each community.</li>
</ol>
</div>
</div>
<div id="outline-container-orgbeb67a7" class="outline-4">
<h4 id="orgbeb67a7"><span class="section-number-4">16.4.2.</span> Uses</h4>
<div class="outline-text-4" id="text-16-4-2">
<ul class="org-ul">
<li>Marketing / social media</li>
<li>Disease outbreaks</li>
<li>Computer viruses</li>
<li>Words spread</li>
<li>Terror network communication</li>
</ul>
</div>
</div>
<div id="outline-container-org30acc15" class="outline-4">
<h4 id="org30acc15"><span class="section-number-4">16.4.3.</span> Specifically</h4>
<div class="outline-text-4" id="text-16-4-3">
<ul class="org-ul">
<li>Automated ways of finding highly-interconnected subpopulations</li>
</ul>
</div>
</div>
<div id="outline-container-orgbb31261" class="outline-4">
<h4 id="orgbb31261"><span class="section-number-4">16.4.4.</span> Definitions</h4>
<div class="outline-text-4" id="text-16-4-4">
<dl class="org-dl">
<dt>Community</dt><dd>set of circles highly connected within itself</dd>
<dt>Circles</dt><dd>nodes or vertices</dd>
<dt>Lines</dt><dd>arcs or edges</dd>
<dt>Clique</dt><dd>a set of nodes that all have edges between each other</dd>
</dl>
</div>
</div>
<div id="outline-container-orga85dc29" class="outline-4">
<h4 id="orga85dc29"><span class="section-number-4">16.4.5.</span> Louvain algorithm</h4>
<div class="outline-text-4" id="text-16-4-5">
<ul class="org-ul">
<li>Decomposes graph into communities</li>
<li>Maximises the modularity of a graph</li>
<li>Terms
<dl class="org-dl">
<dt>\(a_{ij}\)</dt><dd>weight of arc between nodes \(i\) and \(j\)</dd>
<dt>\(w_i\)</dt><dd>total weight of arcs connected to \(i\)</dd>
<dt>\(W\)</dt><dd>total weight of all the arcs</dd>
<dt>Modularity</dt><dd>\(\frac{1}{2W} \sum_{i,j \text{in the same community}}(a_{ij}-\frac{w_iw_j}{2W})\)
<ul class="org-ul">
<li>Measures how well the graph is separated into communities (modules) that are connected internally but not with each other</li>
</ul></dd>
</dl></li>
<li>Steps
<ol class="org-ol">
<li>Each node is its own community</li>
<li>Repeat the following
<ol class="org-ol">
<li>Make <b>biggest</b> modularity increase by moving node from its community to an adjacent node's community</li>
<li>Until no move increases modularity</li>
</ol></li>
<li>Each community is a super-node. Repeat step 1 using super-nodes.</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org8f73ea8" class="outline-4">
<h4 id="org8f73ea8"><span class="section-number-4">16.4.6.</span> Lecture summary</h4>
<div class="outline-text-4" id="text-16-4-6">
<ul class="org-ul">
<li>Finding communities in graphs</li>
<li>Louvain algorithm
<ul class="org-ul">
<li>Heuristic, hence:</li>
<li>Not guaranteed to find the absolute best partition</li>
<li>Gives very good solutions very quickly</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5dadb2e" class="outline-3">
<h3 id="org5dadb2e"><span class="section-number-3">16.5.</span> M16L04: Neural networks and deep learning</h3>
<div class="outline-text-3" id="text-16-5">
</div>
<div id="outline-container-orgcff567e" class="outline-4">
<h4 id="orgcff567e"><span class="section-number-4">16.5.1.</span> Transcript summary</h4>
<div class="outline-text-4" id="text-16-5-1">
<blockquote>
<p>
The lesson introduces two analytics models: neural networks and deep learning, which are often used for recognizing patterns that are difficult to specify using rules or algorithms.
</p>

<p>
Neural networks are modeled after the way neurons work in the brain, with input neurons, hidden neurons, and output neurons. The weights of the inputs are adjusted based on how wrong the outputs are, using algorithms like gradient descent.
</p>

<p>
Training neural networks is difficult, as they require a lot of training data, and it's hard to choose and tune the learning algorithm.
</p>

<p>
Deep learning is a similar approach to neural networks but with more layers, which has had success in natural language processing, speech recognition, and image recognition.
</p>

<p>
Although deep learning is a hot research topic, it's often used for processing text and language, and it's covered in an elective course.
</p>

<ol class="org-ol">
<li>Why are neural networks and deep learning used?
A. To specify patterns using rules or algorithms
B. To react to patterns that we don't understand
C. To separate input and output neurons
D. To adjust the weights of the inputs based on the output</li>

<li>What is the input level in an artificial neural network?
A. The output level on one side
B. The hidden level in the middle
C. The level where external inputs come into each input neuron
D. The level where simulated neurons calculate a weighted value of the inputs</li>

<li>What is the difference between neural networks and deep learning?
A. Neural networks have more layers than deep learning
B. Deep learning is a better approach than neural networks
C. Neural networks are used for speech recognition and image recognition, while deep learning is used for natural language processing
D. Deep learning has more layers than neural networks and is often a better approach</li>

<li>Why is it difficult to make a neural network model generalizable?
A. It requires a lot of training data
B. It's often hard to choose and tune the learning algorithm
C. It's harder compared to many other model types
D. All of the above</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-org8ed86a0" class="outline-4">
<h4 id="org8ed86a0"><span class="section-number-4">16.5.2.</span> Reacting to patterns that we don't understand</h4>
<div class="outline-text-4" id="text-16-5-2">
<ul class="org-ul">
<li>Examples
<ul class="org-ul">
<li>Neural networks</li>
<li>Deep learning</li>
</ul></li>
<li>Train system to react to patterns that human brains can react to</li>
<li>Cannot specify rules or algorithms exactly, without knowing what they're reacting to</li>
</ul>
</div>
</div>
<div id="outline-container-org8ab89f8" class="outline-4">
<h4 id="org8ab89f8"><span class="section-number-4">16.5.3.</span> Neural networks</h4>
<div class="outline-text-4" id="text-16-5-3">
<ul class="org-ul">
<li>Three levels of neurons:
<ol class="org-ol">
<li>Input level</li>
<li>Hidden level (might have several layers)</li>
<li>Output level (use inputs to find results)</li>
</ol></li>
<li>Each neuron:
<ol class="org-ol">
<li>Gets inputs from previous layer</li>
<li>Calculates function of weighted inputs</li>
<li>Gives it output to the next layer</li>
</ol></li>
<li>Important step:
<ul class="org-ul">
<li>The weights/functions are updated based on the correctness of the results, e.g. by gradient descent using the slope of the function</li>
</ul></li>
<li>Eventually, if working well, all weights will be adjusted so the correct output is generated.</li>
<li>Needs much training data</li>
<li>Difficult to train and tune the model:
<ul class="org-ul">
<li>Balance between changes that are too quick and too slow</li>
</ul></li>
<li>Harder than other model types to make generalizable (eg English vs other languages must be trained separately from scratch)</li>
</ul>
</div>
</div>
<div id="outline-container-org0686af7" class="outline-4">
<h4 id="org0686af7"><span class="section-number-4">16.5.4.</span> Deep learning</h4>
<div class="outline-text-4" id="text-16-5-4">
<ul class="org-ul">
<li>Old idea</li>
<li>New ability to make it work well</li>
<li>Very similar to neural network</li>
<li>But is many layers deep</li>
<li>Better approach than neural networks</li>
<li>Success in:
<ol class="org-ol">
<li>Natural language processing</li>
<li>Speech recognition</li>
<li>Image recognition</li>
</ol></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgf218af4" class="outline-3">
<h3 id="orgf218af4"><span class="section-number-3">16.6.</span> M16L05: Competitive models</h3>
<div class="outline-text-3" id="text-16-6">
</div>
<div id="outline-container-org18e0177" class="outline-4">
<h4 id="org18e0177"><span class="section-number-4">16.6.1.</span> Summary</h4>
<div class="outline-text-4" id="text-16-6-1">
<blockquote>
<p>
In this lesson, the topic of discussion is competitive decision-making, where analytics models consider all sides of a system in a situation involving competition and cooperation.
</p>

<p>
The models are used to determine the best action to take, assuming the process will change intelligently. The concept of game theory and its basic concepts are also introduced, along with a demo showcasing how the model works.
</p>

<p>
Different types of games and strategies, perfect and imperfect information, and zero-sum and non-zero-sum games are also discussed.
</p>

<p>
Lastly, the lesson covers the use of different optimization models to find the best decisions in competitive situations.
</p>

<ol class="org-ol">
<li>What is the main concept discussed in the lesson?
A) Deep learning
 B) Competitive decision-making
 C) Predictive models
 D) Descriptive models</li>

<li>What is the purpose of using analytics models in competitive decision-making?
A) To consider all sides of the system
B) To find hidden relationships in the data
C) To optimize a process that won't change
D) To predict what's going to happen in the future</li>

<li>What is the term used for a situation involving competition and cooperation?
A) Sequential game
B) Non-zero-sum game
C) Zero-sum game
D) Cooperative game theory</li>

<li>What is the purpose of using optimization models in competitive situations?
A) To find the best or optimal strategy
B) To determine the best thing to do assuming the process won't change
C) To find hidden relationships in the data
D) To tease out an understanding of reality hidden in the data.</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-orgfa1dc43" class="outline-4">
<h4 id="orgfa1dc43"><span class="section-number-4">16.6.2.</span> Us against data?</h4>
<div class="outline-text-4" id="text-16-6-2">
<ul class="org-ul">
<li>Descriptive models: gain an understanding of data</li>
<li>Predictive models: find hidden relationships and predict the future</li>
<li>Prescriptive models: find the best thing to do</li>
<li>Assuming the system does not react</li>
<li>What if system reacts intelligently?
<ul class="org-ul">
<li>Use analytics to consider all sides of the system</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6295ff3" class="outline-4">
<h4 id="org6295ff3"><span class="section-number-4">16.6.3.</span> Examples:</h4>
<div class="outline-text-4" id="text-16-6-3">
<ul class="org-ul">
<li>Past purchase data is used to set prices, but competitor change their prices</li>
<li>Company reaction to govt tax policy</li>
<li>Employee reaction to company incentive policy</li>
<li>Competitor reaction to proactively adjusted bid</li>
<li>Cooperative and competitive supply chain</li>
</ul>
</div>
</div>
<div id="outline-container-org80ea7d7" class="outline-4">
<h4 id="org80ea7d7"><span class="section-number-4">16.6.4.</span> Game theory</h4>
<div class="outline-text-4" id="text-16-6-4">
<ul class="org-ul">
<li>Competitive decision-making</li>
<li>Cooperative game theory:
<ul class="org-ul">
<li>Competition</li>
<li>Cooperation</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org72f78b9" class="outline-4">
<h4 id="org72f78b9"><span class="section-number-4">16.6.5.</span> Timing</h4>
<div class="outline-text-4" id="text-16-6-5">
<ul class="org-ul">
<li>Make decisions simultaneously
<ul class="org-ul">
<li>Can't change decision once made, eg sealed bid auction</li>
</ul></li>
<li>Strategy
<ul class="org-ul">
<li>Counter-strategy ad nauseum</li>
</ul></li>
<li>If sequential: i.e. decisions made sequentially</li>
</ul>
</div>
</div>
<div id="outline-container-orgb49fc2d" class="outline-4">
<h4 id="orgb49fc2d"><span class="section-number-4">16.6.6.</span> Types of strategy</h4>
<div class="outline-text-4" id="text-16-6-6">
<ul class="org-ul">
<li>Pure: just one choice</li>
<li>Mixed: randomize decisions according to probabilities
<ul class="org-ul">
<li>Example: rock paper scissors
<ul class="org-ul">
<li>Cannot always choose the same</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org008e9f9" class="outline-4">
<h4 id="org008e9f9"><span class="section-number-4">16.6.7.</span> Information levels</h4>
<div class="outline-text-4" id="text-16-6-7">
<ul class="org-ul">
<li>Perfect information:
<ul class="org-ul">
<li>Know everything about everyone else's situation, e.g. playing chess</li>
</ul></li>
<li>Imperfect:
<ul class="org-ul">
<li>Some know more than others</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgfc8c564" class="outline-4">
<h4 id="orgfc8c564"><span class="section-number-4">16.6.8.</span> Zero-sum vs non-zero-sum games</h4>
<div class="outline-text-4" id="text-16-6-8">
<ul class="org-ul">
<li>Zero-sum:
<ul class="org-ul">
<li>What one side gets, the other side loses</li>
<li>E.g. rock paper scissors</li>
</ul></li>
<li>Non-zero-sum:
<ul class="org-ul">
<li>Total benefit might be higher or lower</li>
<li>E.g. economics</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9553f95" class="outline-4">
<h4 id="org9553f95"><span class="section-number-4">16.6.9.</span> Lecture summary</h4>
<div class="outline-text-4" id="text-16-6-9">
<ul class="org-ul">
<li>How to determine best strategy? Optimization</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org68b62b4" class="outline-3">
<h3 id="org68b62b4"><span class="section-number-3">16.7.</span> M16L05a: Competitive model demo</h3>
<div class="outline-text-3" id="text-16-7">
</div>
<div id="outline-container-orgf713673" class="outline-4">
<h4 id="orgf713673"><span class="section-number-4">16.7.1.</span> Summary</h4>
<div class="outline-text-4" id="text-16-7-1">
<blockquote>
<p>
In this lesson, the concept of competitive decision-making using game theory is introduced. Game theory is used in situations where the outcome of a decision depends on the decisions of others.
</p>

<p>
The lesson explains the basics of game theory using the example of two gas stations competing for customers. The gas stations can set their prices to $2.50 or $2. If they both set the same price, they will split the demand half and half.
</p>

<p>
The lesson shows how the gas stations will arrive at a stable equilibrium with both choosing the lower price point. The lesson also explains that in some situations, competition can drive down prices or incentivize companies to differentiate their products to give consumers more choices.
</p>

<ol class="org-ol">
<li>What is the main topic of this lesson?
A. How to set prices for a new product
B. How to predict the future using data analytics
C. Competitive decision-making using game theory
D. The benefits of product differentiation for consumers</li>

<li>What is game theory used for?
A. Situations where the outcome of a decision depends on the decisions of others
B. Finding hidden relationships in data
C. Determining the best thing to do using data
D. Identifying trends in data to predict the future</li>

<li>What is the stable equilibrium in the gas station example?
A. Both gas stations charging $2.50
B. Both gas stations charging $2
C. BP charging $2 and Shell charging $2.50
D. BP charging $2.50 and Shell charging $2</li>

<li>What can competition do in some situations?
A. Drive down prices or incentivize companies to differentiate their products
B. Force companies to set their prices higher
C. Increase the demand for products
D. Result in higher profits for companies</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-org5118034" class="outline-4">
<h4 id="org5118034"><span class="section-number-4">16.7.2.</span> Stable equilibrium</h4>
<div class="outline-text-4" id="text-16-7-2">
<ul class="org-ul">
<li>Neither has incentive to change, hence&#x2026;
<ul class="org-ul">
<li>Outcome is <b>worse</b> than if they had colluded to both charge the higher price</li>
<li>Not always true but here it is</li>
</ul></li>
<li>This is prisoner's dilemma, where:
<ul class="org-ul">
<li>Even if agree on higher price, both still have incentive to cheat, hence both end up with lower price</li>
</ul></li>
<li>This isn't always true in game theory</li>
</ul>
</div>
</div>
<div id="outline-container-orge38b441" class="outline-4">
<h4 id="orge38b441"><span class="section-number-4">16.7.3.</span> Extension of example</h4>
<div class="outline-text-4" id="text-16-7-3">
<ul class="org-ul">
<li>Set at any price</li>
<li>May have incentive to charger higher price</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5992e21" class="outline-3">
<h3 id="org5992e21"><span class="section-number-3">16.8.</span> M16L06: Natural language processing</h3>
<div class="outline-text-3" id="text-16-8">
</div>
<div id="outline-container-orgbec5c66" class="outline-4">
<h4 id="orgbec5c66"><span class="section-number-4">16.8.1.</span> Summary</h4>
<div class="outline-text-4" id="text-16-8-1">
<blockquote>
<p>
In this lesson, Joel Sokol explains how natural language processing (NLP) is a type of data that requires different modeling techniques.
</p>

<p>
NLP models can help machines to recognize and understand human language, which can be useful in various fields such as healthcare, technical support, and legal document searching.
</p>

<p>
NLP includes several tasks such as speech to text, identifying the speaker's words and meaning, co-reference, grammatical tagging, sentiment analysis, and message construction.
</p>

<p>
While NLP is an important and growing application of analytics and data science, it can still be challenging due to the complexities of language, including idioms, metaphors, and multiple word definitions. The lesson concludes with a humorous anecdote about a call center operator with a voice that sounded like a machine, demonstrating that even humans can struggle with language understanding.
</p>

<ol class="org-ol">
<li>What is natural language processing?
A) A type of data that requires different modeling techniques
B) A process of analyzing structured data
C) A method of machine learning
D) A type of data that is easy to model</li>

<li>What are some fields where natural language processing can be useful?
A) Education and childcare
B) Agriculture and forestry
C) Healthcare and technical support
D) Transportation and logistics</li>

<li>What are some tasks included in natural language processing?
A) Identifying colors and shapes
B) Recognizing facial expressions
C) Speech to text and sentiment analysis
D) Tracking eye movements and blink rates</li>

<li>What is the main challenge of natural language processing?
A) The complexities of language, including idioms and metaphors
B) The lack of available data
C) The need for expensive hardware
D) The slow processing speed</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-orgb52efb6" class="outline-4">
<h4 id="orgb52efb6"><span class="section-number-4">16.8.2.</span> When?</h4>
<div class="outline-text-4" id="text-16-8-2">
<ul class="org-ul">
<li>Words and meaning of words</li>
<li>Industries
<ul class="org-ul">
<li>Healthcare</li>
<li>Tech support</li>
<li>Document search</li>
<li>Document classification</li>
<li>Sentiment analysis</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org4638c48" class="outline-4">
<h4 id="org4638c48"><span class="section-number-4">16.8.3.</span> Why hard?</h4>
<div class="outline-text-4" id="text-16-8-3">
<ul class="org-ul">
<li>Same word can have different meanings</li>
</ul>
</div>
</div>
<div id="outline-container-org37f67a2" class="outline-4">
<h4 id="org37f67a2"><span class="section-number-4">16.8.4.</span> Natural language processing</h4>
<div class="outline-text-4" id="text-16-8-4">
<ul class="org-ul">
<li>Speech to text</li>
<li>Recognizing names and co-references</li>
<li>Determining meaning in context</li>
<li>Understanding sentiment</li>
<li>Inversely, choose words to convey a message</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge315799" class="outline-3">
<h3 id="orge315799"><span class="section-number-3">16.9.</span> M16L07: Survival models</h3>
<div class="outline-text-3" id="text-16-9">
</div>
<div id="outline-container-orgbcdd98f" class="outline-4">
<h4 id="orgbcdd98f"><span class="section-number-4">16.9.1.</span> Summary</h4>
<div class="outline-text-4" id="text-16-9-1">
<blockquote>
<p>
This lesson introduces survival models, which are used to predict the probability of an event happening or not happening before a certain time.
</p>

<p>
These models are used in various applications, such as insurance, medical research, and machinery. The Cox proportional hazards model is also introduced, which estimates survival probability based on predictor variables.
</p>

<ol class="org-ol">
<li>What are survival models used for?
a) To predict the weather
b) To predict the probability of an event happening or not happening before a certain time
c) To predict the stock market
d) To predict lottery numbers</li>

<li>What is an example of medical research where survival models are used?
a) Predicting the price of medicine
b) Predicting the number of patients in a hospital
c) Predicting the probability of a transplant patient living for at least 10 more years after receiving an organ
d) Predicting the number of times a doctor will sneeze in a day</li>

<li>What is the Cox proportional hazards model?
a) A model used to predict the weather
b) A model used to predict stock market prices
c) A model used to estimate survival probability based on predictor variables
d) A model used to estimate the number of people in a city</li>

<li>What is censored data?
a) Data that is censored on social media
b) Data that is lost
c) Data that is hidden from view
d) Data where we either don't have data before or after a specific time, or where we only have data until we've observed enough events.</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-orgf6e4ee3" class="outline-4">
<h4 id="orgf6e4ee3"><span class="section-number-4">16.9.2.</span> What are survival models?</h4>
<div class="outline-text-4" id="text-16-9-2">
<ul class="org-ul">
<li>Predict the probability of an event happening (or not) before a certain time
<ul class="org-ul">
<li>Based on predictor variables</li>
</ul></li>
<li>Not just on probability distribution but from the values themselves</li>
</ul>
</div>
</div>
<div id="outline-container-orga90317f" class="outline-4">
<h4 id="orga90317f"><span class="section-number-4">16.9.3.</span> Uses of survival models</h4>
<div class="outline-text-4" id="text-16-9-3">
<ul class="org-ul">
<li>Insurance (e.g. life, auto, theft/loss, etc)</li>
<li>Medicine (effects of treatment)</li>
<li>Machinery/sensors (maintenance and replacement)</li>
</ul>
</div>
</div>
<div id="outline-container-orgc20e015" class="outline-4">
<h4 id="orgc20e015"><span class="section-number-4">16.9.4.</span> Cox proportional hazard model</h4>
<div class="outline-text-4" id="text-16-9-4">
<ul class="org-ul">
<li>Uses an exponential function to estimate survival probability</li>
<li>Given (for each data point):
<ul class="org-ul">
<li>Predictor variables x<sub>1</sub>, &#x2026;, x<sub>n</sub></li>
<li>Event time \(y\)</li>
<li>\(h(t) = h_0(t) e^{\beta_1 x_1 + ... + \beta_n x_n}\)
<dl class="org-dl">
<dt>\(h(t)\)</dt><dd>probability of event happening at time \(t\) given specific values of predictors</dd>
<dt>\(h_0(t)\)</dt><dd>the baseline probability of event happening at \(t\) if all predictor variables are 0</dd>
<dt>\(\beta_j\)</dt><dd>the coefficient for each predictor variable \(j\)</dd>
</dl></li>
<li>Expanding, this equals:
\(h_0(t)e^{\beta_1x_1}e^{\beta_2x_2}...
    e^{\beta_nx_n}\), hence:
<dl class="org-dl">
<dt>\(\beta_j = 0\)</dt><dd>x<sub>j</sub> has no effect</dd>
<dt>\(\beta_j > 0\)</dt><dd>x<sub>j</sub> is positive, has higher probability</dd>
<dt>\(\beta_j < 0\)</dt><dd>x<sub>j</sub> is negative, has lower probability</dd>
</dl></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5fa7c26" class="outline-4">
<h4 id="org5fa7c26"><span class="section-number-4">16.9.5.</span> Data&#x2026;</h4>
<div class="outline-text-4" id="text-16-9-5">
<p>
Can't tell how long patient will survive for
</p>
<ul class="org-ul">
<li><b>*Censored data</b>
<ul class="org-ul">
<li>No data before or after a specific time</li>
<li>No data after certain number of occurrences</li>
<li>Can be dealt with&#x2026;</li>
</ul></li>
</ul>
<p>
<b>*</b>
</p>
</div>
</div>
</div>
<div id="outline-container-org874d840" class="outline-3">
<h3 id="org874d840"><span class="section-number-3">16.10.</span> M16L08: Gradient boosting</h3>
<div class="outline-text-3" id="text-16-10">
</div>
<div id="outline-container-org2a665e3" class="outline-4">
<h4 id="org2a665e3"><span class="section-number-4">16.10.1.</span> Summary</h4>
<div class="outline-text-4" id="text-16-10-1">
<blockquote>
<p>
The lesson introduces the concept of gradient boosting, which is a way to improve the performance of a predictive model by adding other models to it.
</p>

<p>
Gradient boosting uses the gradient information to fit those models. The basic idea of gradient boosting is to start with a single predictive model, and then find another function that can be added to it to improve its performance.
</p>

<p>
The function that is added is trained to fit the errors in the predictions of the first model. The process is repeated until there is no significant improvement in performance or until a specific stopping criterion is reached.
</p>

<p>
Gradient boosting can be used with factor-based models, regression, classification, and tree-based models based on those.
</p>

<ol class="org-ol">
<li>What is gradient boosting?
A) A type of predictive model
B) A way to improve the performance of a predictive model by adding other models to it
C) A way to fit a single model to a large dataset
D) A way to visualize the results of a predictive model</li>

<li>What is the boosting part of the name gradient boosting?
A) The process of adding models together
B) The process of finding the gradient information
C) The process of fitting errors in the predictions
D) The process of using tree-based models</li>

<li>What is the gradient part of the name gradient boosting?
A) The process of adding models together
B) The process of finding the gradient information
C) The process of fitting errors in the predictions
D) The process of using tree-based models</li>

<li>What is the basic idea of gradient boosting?
A) To fit a single model to a large dataset
B) To start with a single predictive model and add other models to improve its performance
C) To use gradient information to fit models
D) To use tree-based models</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-org54c3a10" class="outline-4">
<h4 id="org54c3a10"><span class="section-number-4">16.10.2.</span> Computing topic, i.e.</h4>
<div class="outline-text-4" id="text-16-10-2">
<p>
Using additional models to augment your model
</p>
</div>
</div>
<div id="outline-container-org852045f" class="outline-4">
<h4 id="org852045f"><span class="section-number-4">16.10.3.</span> Basic idea</h4>
<div class="outline-text-4" id="text-16-10-3">
<ul class="org-ul">
<li>Instead of fitting a single model, we can start with one and augment its performance with other models</li>
<li>Gradient: we're using gradient information to fit other models</li>
</ul>
</div>
</div>
<div id="outline-container-org0e4a4b6" class="outline-4">
<h4 id="org0e4a4b6"><span class="section-number-4">16.10.4.</span> In detail</h4>
<div class="outline-text-4" id="text-16-10-4">
<ol class="org-ol">
<li>Fit the first model F(x)
<ul class="org-ul">
<li>Predictors: \(x\)</li>
<li>Response: \(y\)</li>
<li>Predictions: \(F(x)\)</li>
<li>Errors: \(y-F(x)\)</li>
</ul></li>
<li>Find \(H(x) = y-F(x)\)
<ul class="org-ul">
<li>If found: F+H is perfect fit for training data</li>
<li>For H(x):
<ul class="org-ul">
<li>Predictors: \(x\)</li>
<li>Response: <b>Negative gradient of quality metric evaluated at F's prediction</b>
<ul class="org-ul">
<li>Don't fit to response directly since F(x) is doing that already</li>
<li>Instead, this counteracts the errors, even better!</li>
<li>Quality metric = Loss function</li>
<li>H(x) often trained as tree-based model eg regression tree, classification tree</li>
</ul></li>
<li>For regression, this equals \(y-F(x)\), or \(-\nabla L(F(x))\)</li>
<li>Add &gamma;<sub>0</sub> H(x) to F(x) -&gt; F<sub>1</sub>(x)</li>
<li>&#x2026;</li>
</ul></li>
</ul></li>
<li>After k iterations,
\[
   F_k(x) = F_0(x) + \gamma_0 H_0(x) + ... +
   \gamma_k H_k(x)
   \]</li>
<li><b>Boosting</b> = adding the models together (F and H)</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgf6ec558" class="outline-3">
<h3 id="orgf6ec558"><span class="section-number-3">16.11.</span> M16L08a: Gradient boosting example</h3>
<div class="outline-text-3" id="text-16-11">
</div>
<div id="outline-container-orga15acd2" class="outline-4">
<h4 id="orga15acd2"><span class="section-number-4">16.11.1.</span> Summary</h4>
<div class="outline-text-4" id="text-16-11-1">
<blockquote>
<p>
The lesson explains how gradient boosting works as a way to augment the performance of factor-based models.
</p>

<p>
It involves starting with a single model and then adding other models to it that are trained to fit the errors in the initial model's predictions. The process is repeated until there isn't much improvement or until time runs out.
</p>

<p>
The lesson provides a simple example of one iteration of the process using a small dataset and regression trees.
</p>

<ol class="org-ol">
<li>Which of the following is true about gradient boosting?
A) It involves starting with many models and then combining them into a single model.
B) It is a modeling technique that can only be applied to tree-based models.
C) It works by adding other models to an initial model to improve its performance.
D) It involves training a single model to fit the errors in the initial model's predictions.</li>

<li>What is the loss function used in the example in this lesson?
A) Sum of squared errors
B) Mean squared error
C) Absolute error
D) Log loss</li>

<li>What is the formula for calculating the negative gradient of the loss function?
A) The partial derivative of the loss function with respect to the predicted response
B) The partial derivative of the predicted response with respect to the predictors
C) The negative of the partial derivative of the loss function with respect to the predicted response
D) The negative of the partial derivative of the predicted response with respect to the predictors</li>

<li>What is the optimal multiplier value used to update F in the example in this lesson?
A) 0.25
B) 0.50
C) 0.56
D) 0.75</li>
</ol>
</blockquote>
</div>
</div>
<div id="outline-container-org0322a52" class="outline-4">
<h4 id="org0322a52"><span class="section-number-4">16.11.2.</span> Detailed steps</h4>
<div class="outline-text-4" id="text-16-11-2">
<ol class="org-ol">
<li>L is the loss function</li>
<li>L=2</li>
<li>\[
   L = \sum^m_{i=1}(y_i-F_0 (x_i))^2 \\
   = (y_1-F_0(x_1))^2 + ... + (y_4-F_0(x_4))^2
   \]</li>
<li>Take partial derivative at each point</li>
<li>Plug in y and F<sub>0</sub> to get the gradient</li>
<li>To get the optimal gradient (&gamma;<sub>0</sub>), use optimization and solve the partial derivative</li>
<li>The output is two regression trees eg:
<ul class="org-ul">
<li>\(F_0(x_i) = x_{i1} < 2; x_{i1} \geq 2\)</li>
<li>\(H_0(x_i) = x_{i2} < 5; x_{i2} \geq 5\)</li>
</ul></li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: W</p>
<p class="date">Created: 2023-04-03 Mon 19:03</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
