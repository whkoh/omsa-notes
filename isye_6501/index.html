<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-04-02 Sun 14:41 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>ISYE 6501 Intro to Analytics Modeling Notes</title>
<meta name="author" content="W" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/readtheorg.css"/>
<script type="text/javascript" src="src/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="src/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">ISYE 6501 Intro to Analytics Modeling Notes</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org9dfa491">1. Module 01: Intro</a>
<ul>
<li><a href="#orgd081c8f">1.1. What's analytics?</a></li>
<li><a href="#org6069011">1.2. Modeling</a></li>
<li><a href="#org742c47b">1.3. Course structure</a></li>
<li><a href="#org8bd456d">1.4. Three different things are all models</a></li>
<li><a href="#org73ed04c">1.5. Hence these are all "models":</a></li>
</ul>
</li>
<li><a href="#org2aaf711">2. Module 02: Classification</a>
<ul>
<li><a href="#org7e6a3b4">2.1. M1L1: Intro to classification</a></li>
<li><a href="#org8c12235">2.2. M1L2: Choosing a Classifier</a>
<ul>
<li><a href="#org32071f6">2.2.1. Example: Loan payment (Income vs credit score)</a></li>
</ul>
</li>
<li><a href="#org6f900f8">2.3. M2L3 Data definitions</a>
<ul>
<li><a href="#orgd2f75e8">2.3.1. Data terminology</a></li>
<li><a href="#org592315f">2.3.2. Data types</a></li>
</ul>
</li>
<li><a href="#org7dd3641">2.4. M2L4: Support vector machines</a>
<ul>
<li><a href="#org16e4d72">2.4.1. When not possible to get full separation</a></li>
</ul>
</li>
<li><a href="#orgeebed1a">2.5. M2L5: What SVM means</a></li>
<li><a href="#orgcff7d7a">2.6. M2L6: Advanced SVM</a></li>
<li><a href="#org09a248f">2.7. M2L7: Scaling and standardization</a>
<ul>
<li><a href="#orge700ce4">2.7.1. Scaling data</a></li>
<li><a href="#org86a4a22">2.7.2. Standardization of data</a></li>
<li><a href="#org579a327">2.7.3. Choosing between scaling vs standardization</a></li>
</ul>
</li>
<li><a href="#orgcb0bebd">2.8. M2L8: K Nearest Neighbour model (KNN)</a></li>
</ul>
</li>
<li><a href="#org9a228fd">3. Module 03: Validation</a>
<ul>
<li><a href="#org01abf84">3.1. M3L1: Training, validation and test data</a></li>
<li><a href="#orgdfcbfdb">3.2. M3L2: Splitting data</a></li>
<li><a href="#org3905c66">3.3. M3L3: Cross-validation</a></li>
<li><a href="#orgb2b213a">3.4. M3L4: Summary</a></li>
</ul>
</li>
<li><a href="#org3438bc8">4. Module 04: Clustering</a>
<ul>
<li><a href="#orgcb7e185">4.1. M4L1: Introduction to clustering</a></li>
<li><a href="#orgdf6dfc5">4.2. M4L2: Distance Norms</a></li>
<li><a href="#org136cd87">4.3. M4L3: K-Means Clustering</a></li>
<li><a href="#org628d020">4.4. M4L4: Practical details for K-Means</a></li>
<li><a href="#orge9f70ee">4.5. M4L5: Clustering for prediction</a></li>
<li><a href="#orgfc9ee1d">4.6. M4L6: Clustering vs Classification</a></li>
</ul>
</li>
<li><a href="#org1d4e25f">5. Module 05: Data preparation</a>
<ul>
<li><a href="#org3db6af4">5.1. M5L1: Common techniques and problems</a></li>
<li><a href="#org338c66e">5.2. M5L2: Outliers</a></li>
<li><a href="#org3233992">5.3. M5L3: What to do with outliers?</a>
<ul>
<li><a href="#orgfe179d5">5.3.1. Bad data</a></li>
<li><a href="#orge886313">5.3.2. Real / correct data</a></li>
<li><a href="#org79c0a6f">5.3.3. Another way to handle outliers</a></li>
<li><a href="#org8e484f5">5.3.4. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org74c99ef">6. Module 06: Change detection</a>
<ul>
<li><a href="#org92d0791">6.1. M6L1: Examples</a></li>
<li><a href="#org0811a4d">6.2. M6L2: Cumulative sum for change detection</a>
<ul>
<li><a href="#orgd49c048">6.2.1. Interpretation</a></li>
</ul>
</li>
<li><a href="#org7bfb193">6.3. M6L3: Ethics: Honestly reporting our results</a></li>
</ul>
</li>
<li><a href="#orgec89109">7. Module 07: Time series</a>
<ul>
<li><a href="#orgbdb2d0b">7.1. M7L1: Introduction to exponential smoothing</a>
<ul>
<li><a href="#org4ee44ba">7.1.1. Random variation</a></li>
<li><a href="#org072537b">7.1.2. Definitions:</a></li>
<li><a href="#org82a3170">7.1.3. Exponential smoothing method</a></li>
</ul>
</li>
<li><a href="#orga27e618">7.2. M7L2: Trend and cyclic effects</a>
<ul>
<li><a href="#orgb903cd4">7.2.1. Trends</a></li>
<li><a href="#orgc63cc7d">7.2.2. Cyclical patterns</a></li>
<li><a href="#org131687f">7.2.3. Summary</a></li>
</ul>
</li>
<li><a href="#orgce59e18">7.3. M7L3: Etymology (what the name means)</a>
<ul>
<li><a href="#org801af83">7.3.1. Summary</a></li>
</ul>
</li>
<li><a href="#orgd677a7a">7.4. M7L4: Forecasting</a></li>
<li><a href="#org58db0cb">7.5. M3L5: ARIMA</a>
<ul>
<li><a href="#org3c6d735">7.5.1. (I): Differences</a></li>
<li><a href="#orgb5ea287">7.5.2. (II): Autogression</a></li>
<li><a href="#org3676cb1">7.5.3. (III): Moving Average</a></li>
<li><a href="#org1eab2ab">7.5.4. ARIMA model</a></li>
</ul>
</li>
<li><a href="#orgec642c0">7.6. M7L6: GARCH</a>
<ul>
<li><a href="#org9f1e48a">7.6.1. Variance</a></li>
<li><a href="#orgc4dafb8">7.6.2. GARCH</a></li>
<li><a href="#orgf3f2a4c">7.6.3. Summary - three models for time series analysis</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org8793c91">8. Module 08: Regression</a>
<ul>
<li><a href="#org4bc9bf0">8.1. M8L1: Intro to Regression</a>
<ul>
<li><a href="#org2a0bfee">8.1.1. What questions can regression answer?</a></li>
<li><a href="#org24eeae4">8.1.2. Simple linear regression</a></li>
</ul>
</li>
<li><a href="#orge97825d">8.2. M8L2: Maximum Likelihood and Information Criteria</a>
<ul>
<li><a href="#org53a5f1b">8.2.1. Likelihood</a></li>
<li><a href="#org6b1c999">8.2.2. Maximum likelihood fitting</a></li>
<li><a href="#orgaf6e261">8.2.3. Akaike Information Criterion</a></li>
<li><a href="#org4e7d920">8.2.4. Corrected AIC (AIC<sub>c</sub>)</a></li>
<li><a href="#orge130719">8.2.5. AIC<sub>c</sub> example</a></li>
<li><a href="#orgd8d7214">8.2.6. Bayesian Information Criterion</a></li>
<li><a href="#orgce103be">8.2.7. Summary</a></li>
</ul>
</li>
<li><a href="#orgd4b6632">8.3. M8L3: Using Regression</a>
<ul>
<li><a href="#orgac0237d">8.3.1. Regression coefficients</a></li>
</ul>
</li>
<li><a href="#org4abc55b">8.4. M8L4: Causation vs Correlation</a>
<ul>
<li><a href="#org340b0c4">8.4.1. Example: winter recreation</a></li>
<li><a href="#orgfb27a89">8.4.2. Example: tiredness vs scruffiness</a></li>
<li><a href="#org8fab6ab">8.4.3. How to tell causation?</a></li>
<li><a href="#org4824a18">8.4.4. Meaningless correlations</a></li>
</ul>
</li>
<li><a href="#orgd40d3c9">8.5. M8L5: Transformations and Interactions</a>
<ul>
<li><a href="#org601fb51">8.5.1. Transforming the data</a></li>
<li><a href="#org9900b16">8.5.2. Interaction terms, e.g. product of inputs</a></li>
</ul>
</li>
<li><a href="#orgbdc4c06">8.6. M6L6: Output</a>
<ul>
<li><a href="#org466911f">8.6.1. p-Values</a></li>
<li><a href="#org4c411ed">8.6.2. Confidence interval</a></li>
<li><a href="#org69b848e">8.6.3. T-statistic</a></li>
<li><a href="#org87111e0">8.6.4. Coefficient itself</a></li>
<li><a href="#org1d60c60">8.6.5. \(R^2\)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgfe1b301">9. Module 09: Advanced Data Preparation</a>
<ul>
<li><a href="#org99006cc">9.1. M9L1: Box-Cox Transformations</a></li>
<li><a href="#org4e787cc">9.2. M9L2: Detrending</a></li>
<li><a href="#org39a48f7">9.3. M9L3: Intro to PCA</a></li>
<li><a href="#org1563295">9.4. M9L4: Using PCA</a>
<ul>
<li><a href="#org9fc4bbb">9.4.1. Math of PCA</a></li>
<li><a href="#org84cae94">9.4.2. PCA as linear combination</a></li>
<li><a href="#orgd016d20">9.4.3. PCA for regression</a></li>
<li><a href="#org458b57b">9.4.4. Summary of PCA</a></li>
</ul>
</li>
<li><a href="#org679f029">9.5. M9L5: Eigenvalues and Eigenvectors</a>
<ul>
<li><a href="#org8840b7f">9.5.1. Initial example</a></li>
<li><a href="#org9c3bbf6">9.5.2. Important: know how eigenvalues and eigenvectors are important to PCA</a></li>
</ul>
</li>
<li><a href="#org5112b23">9.6. M9L6: PCA: The good and the bad</a>
<ul>
<li><a href="#org4557fdd">9.6.1. Example where PCA is good</a></li>
<li><a href="#org4a396e6">9.6.2. Example where PCA is bad</a></li>
<li><a href="#org2eac72f">9.6.3. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orged7abef">10. Module 10: Advanced Regression</a>
<ul>
<li><a href="#orgbbacef2">10.1. M10L01: Introduction to CART</a>
<ul>
<li><a href="#org9dd7787">10.1.1. Trees in regression</a></li>
<li><a href="#org7af396e">10.1.2. Recall</a></li>
<li><a href="#org69aa0d2">10.1.3. What if responses can be differentiated by a factor?</a></li>
<li><a href="#org6df34a6">10.1.4. Further splits are possible</a></li>
<li><a href="#org5f6f211">10.1.5. Disadvantages</a></li>
<li><a href="#org327b6cc">10.1.6. Other places to use trees</a></li>
<li><a href="#orga658fb9">10.1.7. Common questions</a></li>
<li><a href="#org8d1bcc2">10.1.8. Etymology of "tree"</a></li>
</ul>
</li>
<li><a href="#org9889ca2">10.2. M10L02: Branching</a>
<ul>
<li><a href="#org81e4018">10.2.1. Main questions</a></li>
<li><a href="#org8685c85">10.2.2. Branching methods</a></li>
<li><a href="#org4de7c31">10.2.3. Generic branching concept</a></li>
</ul>
</li>
<li><a href="#org29b6e63">10.3. M10L03: Random Forests</a>
<ul>
<li><a href="#orgec1024b">10.3.1. Intro summary</a></li>
<li><a href="#org2634561">10.3.2. Introducing randomness</a></li>
<li><a href="#org60fd83f">10.3.3. Note</a></li>
<li><a href="#orgeef2384">10.3.4. Summary of RF</a></li>
</ul>
</li>
<li><a href="#org03bb124">10.4. M10L04: Explainability and Interpretability</a>
<ul>
<li><a href="#org08703d8">10.4.1. Example: linear regression</a></li>
<li><a href="#org41f9cf1">10.4.2. Example: regression tree</a></li>
<li><a href="#org2300b3f">10.4.3. Example: random forests</a></li>
<li><a href="#orga1855b7">10.4.4. Comparisons</a></li>
<li><a href="#org771fbab">10.4.5. Tradeoff</a></li>
</ul>
</li>
<li><a href="#orgfed7a51">10.5. M10L05: Confusion Matrices</a>
<ul>
<li><a href="#org9199456">10.5.1. Details</a></li>
<li><a href="#orgc969d67">10.5.2. Definitions</a></li>
</ul>
</li>
<li><a href="#org8912c1e">10.6. M10L06: Situationally-Driven Comparisons</a>
<ul>
<li><a href="#org7689e48">10.6.1. Example: from spam detection</a></li>
<li><a href="#org80bed72">10.6.2. Evaluating quality / changing metrics</a></li>
</ul>
</li>
<li><a href="#orgf11a26d">10.7. L10L07: Advanced Topics in Regression</a>
<ul>
<li><a href="#org240b618">10.7.1. Poisson regression</a></li>
<li><a href="#org3cfd307">10.7.2. Regression splines</a></li>
<li><a href="#org14dd8ca">10.7.3. Bayesian regression</a></li>
<li><a href="#org03fe315">10.7.4. k-Nearest Neighbour Regression</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org13c8e83">11. Module 11: Variable Selection</a>
<ul>
<li><a href="#org7f95ce0">11.1. M11L1: Introduction</a>
<ul>
<li><a href="#org2641a1f">11.1.1. Why bother limiting factors?</a></li>
</ul>
</li>
<li><a href="#orgb81d08f">11.2. M11L2: Models for variable selection</a>
<ul>
<li><a href="#org111e993">11.2.1. Forward selection</a></li>
<li><a href="#orgdf06d75">11.2.2. Backward elimination</a></li>
<li><a href="#orgad6bf40">11.2.3. Stepwise regression</a></li>
<li><a href="#orgd8fb68b">11.2.4. Types of approaches</a></li>
<li><a href="#orgefea95d">11.2.5. Lasso approach</a></li>
<li><a href="#orgc902ac2">11.2.6. Elastic net</a></li>
<li><a href="#org27fa333">11.2.7. Ridge regression</a></li>
</ul>
</li>
<li><a href="#org745f438">11.3. M11L3: Lasso vs Ridge regression</a>
<ul>
<li><a href="#org5b6d930">11.3.1. The key difference</a></li>
</ul>
</li>
<li><a href="#org3046b91">11.4. M11L4: Bias-Variance tradeoff</a>
<ul>
<li><a href="#orgde6f0e2">11.4.1. Fit and real vs random patterns</a></li>
<li><a href="#org1ac5bf4">11.4.2. Summary</a></li>
</ul>
</li>
<li><a href="#orgfb9d64d">11.5. M11L5: Ridge regression / regularization</a>
<ul>
<li><a href="#org0739439">11.5.1. Ridge regression</a></li>
<li><a href="#org35aad9c">11.5.2. Coefficients -&gt; magnitude of effect</a></li>
<li><a href="#orgda51c01">11.5.3. Ridge regression limits the magnitude of the regression coefficient instead of the number of variables</a></li>
</ul>
</li>
<li><a href="#orge431918">11.6. M11L6: Choosing a variable selection model</a>
<ul>
<li><a href="#org40346f3">11.6.1. Lasso vs ridge vs elastic net</a></li>
<li><a href="#orgf4b5919">11.6.2. Elastic net</a></li>
<li><a href="#org5f89e85">11.6.3. Which one to use?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgcace7b7">12. Module 12: Design of Experiments</a>
<ul>
<li><a href="#org3914c8a">12.1. M12L1: Intro</a>
<ul>
<li><a href="#orgf2af912">12.1.1. Comparison and control</a></li>
<li><a href="#org8d05599">12.1.2. Blocking</a></li>
</ul>
</li>
<li><a href="#org70c5c15">12.2. M12L2: A/B testing</a>
<ul>
<li><a href="#org1975578">12.2.1. Required to use A/B testing</a></li>
</ul>
</li>
<li><a href="#orgfec5710">12.3. M12L3: Factorial design</a>
<ul>
<li><a href="#orgfae551e">12.3.1. Full factorial design</a></li>
<li><a href="#org0185e88">12.3.2. Fractional factorial design</a></li>
<li><a href="#orgad0ef19">12.3.3. Independent factors</a></li>
<li><a href="#org6aa21a4">12.3.4. Summary</a></li>
</ul>
</li>
<li><a href="#orgc727e4f">12.4. M12L4: Multi-armed bandits</a>
<ul>
<li><a href="#org63f8a0d">12.4.1. Exploration vs exploitation</a></li>
<li><a href="#org9ff1dd2">12.4.2. Multi-armed bandit</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf606a80">13. Module 13: Probability-based Models</a>
<ul>
<li><a href="#orga51a9c3">13.1. M13L1: Intro</a>
<ul>
<li><a href="#org7e1c9ad">13.1.1. Simple modelling</a></li>
<li><a href="#org8b6fc6a">13.1.2. Example on ticket owner not showing up</a></li>
<li><a href="#orge18719d">13.1.3. Summary</a></li>
</ul>
</li>
<li><a href="#org9d6f0d9">13.2. M13L2: Bernoulli, Binomial and Geometric Distributions</a>
<ul>
<li><a href="#org4ccc7ce">13.2.1. Bernoulli distribution</a></li>
<li><a href="#org94fbcca">13.2.2. Binomial distribution</a></li>
<li><a href="#org7f78acc">13.2.3. Geometric distribution</a></li>
</ul>
</li>
<li><a href="#org142e8bc">13.3. M13L3: Poisson, Weibull and Exponential Distributions</a>
<ul>
<li><a href="#org5a463e5">13.3.1. Poisson</a></li>
<li><a href="#orgb9e6b64">13.3.2. Exponential distribution</a></li>
<li><a href="#org903033d">13.3.3. Weibull</a></li>
<li><a href="#org76f34b2">13.3.4. Software can help but may be confusing</a></li>
</ul>
</li>
<li><a href="#org925091e">13.4. M13L4: Q-Q plots</a>
<ul>
<li><a href="#org6f6c297">13.4.1. Visualizing</a></li>
<li><a href="#org8877658">13.4.2. Types of Q-Q plots</a></li>
</ul>
</li>
<li><a href="#org9bd89f7">13.5. M13L5: Queuing</a>
<ul>
<li><a href="#orgf4147a1">13.5.1. Queuing example</a></li>
<li><a href="#org6e710b9">13.5.2. More complex example</a></li>
<li><a href="#orgf681a7c">13.5.3. Queuing models</a></li>
</ul>
</li>
<li><a href="#org7a13946">13.6. M13L6: Simulation basics</a>
<ul>
<li><a href="#org2f80003">13.6.1. Types of simulations</a></li>
<li><a href="#orga2f867d">13.6.2. Discrete-event stochastic simulations</a></li>
<li><a href="#orgeaaf0fb">13.6.3. Simulation software</a></li>
<li><a href="#org5a7a378">13.6.4. Replications</a></li>
<li><a href="#org71e9724">13.6.5. Simulation validation</a></li>
</ul>
</li>
<li><a href="#orgff16cd3">13.7. M13L7: Prescriptive simulation</a>
<ul>
<li><a href="#orgd5744da">13.7.1. Simulation comparisons</a></li>
<li><a href="#org413b5e2">13.7.2. Validation can be hard</a></li>
<li><a href="#org9211152">13.7.3. Simulation/validation should consider all processes</a></li>
</ul>
</li>
<li><a href="#org091c916">13.8. M13L8: Markov chains</a>
<ul>
<li><a href="#org6677cf7">13.8.1. Answering questions with the transition matrix</a></li>
<li><a href="#org8c7b126">13.8.2. Key assumption</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf3113d1">14. Module 14: Missing Data</a>
<ul>
<li><a href="#org2d0f7c5">14.1. M14L01: Intro to missing data</a>
<ul>
<li><a href="#org95827e4">14.1.1. When is there missing data?</a></li>
<li><a href="#orgcf208fc">14.1.2. Data problems</a></li>
<li><a href="#org162dfc6">14.1.3. Patterns in missing data</a></li>
</ul>
</li>
<li><a href="#orgc86477c">14.2. M14L02: Methods not requiring imputation</a>
<ul>
<li><a href="#orgd4616ff">14.2.1. Dealing with missing data</a></li>
<li><a href="#org1e2156c">14.2.2. Discard records</a></li>
<li><a href="#org9bc8390">14.2.3. Categorical variable approach</a></li>
<li><a href="#org5755eff">14.2.4. Summary</a></li>
</ul>
</li>
<li><a href="#orgd736b3c">14.3. M14L03: Imputation methods</a>
<ul>
<li><a href="#org1801d3a">14.3.1. Mid-range value</a></li>
<li><a href="#orga100b4a">14.3.2. Regression</a></li>
<li><a href="#orgb00e344">14.3.3. Regression with perturbation (imputation with variability)</a></li>
<li><a href="#orgb873e99">14.3.4. Imputation approaches</a></li>
<li><a href="#orgc587776">14.3.5. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org73f34bc">15. Module 15: Optimization</a>
<ul>
<li><a href="#org27c1695">15.1. M15L01: Intro to Optimization</a>
<ul>
<li><a href="#org5000dd2">15.1.1. Examples</a></li>
<li><a href="#org59ba009">15.1.2. Optimization provides direction for an organization</a></li>
<li><a href="#orgb1ff12d">15.1.3. Optimization software</a></li>
</ul>
</li>
<li><a href="#orga5942ba">15.2. M15L02: Elements of Optimization Models</a></li>
<li><a href="#orgd7bc939">15.3. M15L03: Optimization is an art</a>
<ul>
<li><a href="#org5017ef5">15.3.1. Examples</a></li>
</ul>
</li>
<li><a href="#orgf0c63ac">15.4. M15L04: Modeling with binary variables</a>
<ul>
<li><a href="#org4ebaaa8">15.4.1. Example: stock market investment</a></li>
<li><a href="#org0e137a9">15.4.2. Recap uses of integer variables in optimization</a></li>
</ul>
</li>
<li><a href="#org4a7eab0">15.5. M15L05: Discovering the real questions</a>
<ul>
<li><a href="#org5a10538">15.5.1. Real life</a></li>
<li><a href="#org735b0bb">15.5.2. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org725f9e2">16. Module 16: Advanced Models</a></li>
</ul>
</div>
</div>
<div id="outline-container-org9dfa491" class="outline-2">
<h2 id="org9dfa491"><span class="section-number-2">1.</span> Module 01: Intro</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-orgd081c8f" class="outline-3">
<h3 id="orgd081c8f"><span class="section-number-3">1.1.</span> What's analytics?</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Analytics answers these questions
</p>
<ol class="org-ol">
<li>Descriptive - what happened</li>
<li>Predictive - what will happen</li>
<li>Prescriptive - what action is best</li>
<li>General questions</li>
</ol>
</div>
</div>
<div id="outline-container-org6069011" class="outline-3">
<h3 id="org6069011"><span class="section-number-3">1.2.</span> Modeling</h3>
<div class="outline-text-3" id="text-1-2">
<ol class="org-ol">
<li>Describe real-life situation with math</li>
<li>Analyze math</li>
<li>Turn math answer back to real situation</li>
</ol>
</div>
</div>
<div id="outline-container-org742c47b" class="outline-3">
<h3 id="org742c47b"><span class="section-number-3">1.3.</span> Course structure</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Enough math intuition and detail
</p>
<ul class="org-ul">
<li>Models
<ul class="org-ul">
<li>Machine learning</li>
<li>Regression</li>
<li>Optimizaton</li>
</ul></li>
<li>Cross-cutting
<ul class="org-ul">
<li>Data prep</li>
<li>Output quality</li>
<li>Missing data</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8bd456d" class="outline-3">
<h3 id="org8bd456d"><span class="section-number-3">1.4.</span> Three different things are all models</h3>
<div class="outline-text-3" id="text-1-4">
<ol class="org-ol">
<li>Real life situation expressed as math</li>
<li>Analyse the math</li>
<li>Turn mathematical analyse to real-life solution</li>
</ol>
</div>
</div>
<div id="outline-container-org73ed04c" class="outline-3">
<h3 id="org73ed04c"><span class="section-number-3">1.5.</span> Hence these are all "models":</h3>
<div class="outline-text-3" id="text-1-5">
<ol class="org-ol">
<li>Regression</li>
<li>Regression on size, weight, distance</li>
<li>Regression estimate = 37+81*Size +76*Wt, etc</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org2aaf711" class="outline-2">
<h2 id="org2aaf711"><span class="section-number-2">2.</span> Module 02: Classification</h2>
<div class="outline-text-2" id="text-2">
<blockquote>
<p>
Definition: putting things into groups
</p>
</blockquote>
</div>
<div id="outline-container-org7e6a3b4" class="outline-3">
<h3 id="org7e6a3b4"><span class="section-number-3">2.1.</span> M1L1: Intro to classification</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Types of classification models
</p>
<ol class="org-ol">
<li>Number of groups</li>
<li>Number of dimensions
<ul class="org-ul">
<li>Can 1 dimension be sufficient to classify?</li>
</ul></li>
<li>Soft vs hard classifiers (is it 100% error-free?)</li>
</ol>
</div>
</div>
<div id="outline-container-org8c12235" class="outline-3">
<h3 id="org8c12235"><span class="section-number-3">2.2.</span> M1L2: Choosing a Classifier</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Definition of bad classification
</p>
<ul class="org-ul">
<li>Cost: is one type of mistake worse than the other?</li>
</ul>
</div>
<div id="outline-container-org32071f6" class="outline-4">
<h4 id="org32071f6"><span class="section-number-4">2.2.1.</span> Example: Loan payment (Income vs credit score)</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>Plot lines and find one that can separate default vs non-default.</li>
<li>How do we know the right lines are drawn?</li>
<li>We want to be as conservative as possible (less error prone)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org6f900f8" class="outline-3">
<h3 id="org6f900f8"><span class="section-number-3">2.3.</span> M2L3 Data definitions</h3>
<div class="outline-text-3" id="text-2-3">
</div>
<div id="outline-container-orgd2f75e8" class="outline-4">
<h4 id="orgd2f75e8"><span class="section-number-4">2.3.1.</span> Data terminology</h4>
<div class="outline-text-4" id="text-2-3-1">
<ol class="org-ol">
<li>Row = data point</li>
<li>Column = dimension, attribute, feature, predictor, covariate
<ol class="org-ol">
<li>Special column = response, outcome</li>
</ol></li>
</ol>
</div>
</div>
<div id="outline-container-org592315f" class="outline-4">
<h4 id="org592315f"><span class="section-number-4">2.3.2.</span> Data types</h4>
<div class="outline-text-4" id="text-2-3-2">
<ol class="org-ol">
<li>Structured data
<ol class="org-ol">
<li>Quantitative
<ul class="org-ul">
<li>Numbers with meaning</li>
</ul></li>
<li>Categorical
<ul class="org-ul">
<li>Numbers without meaning</li>
</ul></li>
<li>Binary data (subset of categorical)</li>
<li>Unrelated data</li>
<li>Time series data</li>
</ol></li>
<li>Unstructured
<ol class="org-ol">
<li>Text data</li>
</ol></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org7dd3641" class="outline-3">
<h3 id="org7dd3641"><span class="section-number-3">2.4.</span> M2L4: Support vector machines</h3>
<div class="outline-text-3" id="text-2-4">
<ul class="org-ul">
<li><b>Supervised</b> method (algorithm uses known results when training)</li>
<li>Terminology
<ul class="org-ul">
<li>m = number of data points</li>
<li>n = number of attributes</li>
<li>x<sub>ij</sub> = j attribute of i data point
<ul class="org-ul">
<li>e.g. x<sub>51</sub> = credit score of person 5; x<sub>52</sub> = income of person 5</li>
</ul></li>
<li>y<sub>i</sub> = response of data point i
<ul class="org-ul">
<li>e.g. 1 if data point is group 1</li>
<li>-1 if data point is group 2</li>
</ul></li>
<li>Line: \(a_1 x_1\) + \(a_2 x_2\) + &#x2026; + \(a_n x_n\) + \(a_0\) = 0</li>
<li>Note the intercept \(a_0\)</li>
</ul></li>
<li>In general: \(\sum_{j=1}^{n} a_j x_j + a_0 = 0\)</li>
<li>Separation problem: get max distance between lines</li>
<li>\(2\over{\sqrt(\sum_{j} \left(a_j\right)^2)}\)</li>
<li>i.e. Min<sub>a<sub>0</sub> &#x2026; a<sub>n</sub></sub>: \(\sum_{j=1}^{n}\left(a_j\right)^2\)</li>
<li>Subject to constraints</li>
</ul>
</div>
<div id="outline-container-org16e4d72" class="outline-4">
<h4 id="org16e4d72"><span class="section-number-4">2.4.1.</span> When not possible to get full separation</h4>
<div class="outline-text-4" id="text-2-4-1">
<ul class="org-ul">
<li>Then we minimize error</li>
<li>There's a trade-off between margin and error</li>
<li>Error for data point is:
\[
  \text{max} \{ 0, 1-(\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}
  \]</li>
<li>Total error is:
\[
  \sum_{i=1}^{m} \text{max} \{ 0, 1 - (\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}
  \]</li>
<li>Margin denominator: \(\sum_{j=1}^{n}(a_j)^2\)</li>

<li>We multiply margin by \(\lambda\) to <b>assign its importance of margin vs error</b>.</li>
<li>Hence, the full equation is:
\[
  \text{Minimize}_{a_0,...,a_n} \sum_{i=1}^{m} \text{max} \{ 0, 1 - (\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}  + \lambda \sum_{j=1}^{n}(a_j)^2
  \]</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgeebed1a" class="outline-3">
<h3 id="orgeebed1a"><span class="section-number-3">2.5.</span> M2L5: What SVM means</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li>Etymology
<ul class="org-ul">
<li>Vector = point</li>
<li><b>Support vector</b> = points that holds up (or, supports) a shape. Shape is correctly balanced on parallel lines</li>
<li>Model determines the "support vectors"</li>
<li>Automatically from data hence "<b>machine</b>"</li>
</ul></li>
<li>Support can be from top or side</li>
<li>Looking for max separation i.e. the support vector touches the data points</li>
<li>Classifier is in between the two support vectors</li>
</ul>
</div>
</div>
<div id="outline-container-orgcff7d7a" class="outline-3">
<h3 id="orgcff7d7a"><span class="section-number-3">2.6.</span> M2L6: Advanced SVM</h3>
<div class="outline-text-3" id="text-2-6">
<ul class="org-ul">
<li>The constant term a<sub>0</sub> can be used to adjust the intercept and hence tweak the SVM model.
<ul class="org-ul">
<li>If it's more costly to grant a bad loan, e.g.: \(\frac{2}{3}(a_0-1) + \frac{1}{3}(a_0+1)\)</li>
</ul></li>
<li>For soft classification, you can add a multiplier m<sub>j</sub> for each type of error:
<ul class="org-ul">
<li>m<sub>j</sub> &gt; 1 for more costly</li>
<li>m<sub>j</sub> &lt; 1 for less costly</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org09a248f" class="outline-3">
<h3 id="org09a248f"><span class="section-number-3">2.7.</span> M2L7: Scaling and standardization</h3>
<div class="outline-text-3" id="text-2-7">
<ul class="org-ul">
<li>Predictive factors may have different orders of magnitude, i.e.
<ul class="org-ul">
<li>Income in \(10^5\)</li>
<li>Credit score in \(10^2\)</li>
<li>Classifier is \(0 = a_0 + \sum_{j} a_j x_j\)</li>
<li>Maximise gap by minimizing: \(\sum_{j} a_j^2\)</li>
<li>Coefficients might be 10<sup>6</sup> + 5*income + 701*credit score
<ul class="org-ul">
<li>Sum of squared coefficients:
\(\sum_j a_j^2 = 5^2 + 700^2 = 490,025\)</li>
<li>Changing credit score by 1 increases the sum by 1,401:
\(\sum_j a_j^2 = 5^2 + 701^2 = 491,426\)</li>
</ul></li>
<li>Small change in one coefficient affects the sum a lot due to difference in scales.
<ul class="org-ul">
<li>As data has such different scale.</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="outline-container-orge700ce4" class="outline-4">
<h4 id="orge700ce4"><span class="section-number-4">2.7.1.</span> Scaling data</h4>
<div class="outline-text-4" id="text-2-7-1">
<ul class="org-ul">
<li>Common scale is between 0 and 1</li>
<li>Scale data by factor
\[
  x_{ij}^{\text{scaled}} = \frac{x_{ij}-x_{\text{min}j}}{x_{\text{max}j} - x_{\text{min}j}}
  \]</li>
<li>General scaling between a, b:
\[
  x_{ij}^{\text{scaled}[b,a]} = x_{ij}^{\text{scaled}[0,1]}(a-b)+b
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-org86a4a22" class="outline-4">
<h4 id="org86a4a22"><span class="section-number-4">2.7.2.</span> Standardization of data</h4>
<div class="outline-text-4" id="text-2-7-2">
<ul class="org-ul">
<li>Scale to normal distribution</li>
<li>Common scale is:
<ul class="org-ul">
<li>Mean = 0</li>
<li>SD = 1</li>
</ul></li>
<li>Factor j has:
<ul class="org-ul">
<li>mean \(\mu_j = \frac{\sum_{i=1}^n x_{ij}}{n}\)</li>
<li>SD \(\sigma_j\)</li>
</ul></li>
<li>For each data point \(i\):
\[
  x_{ij}^{\text{standardized}} = \frac{x_{ij}-\mu_j}{\sigma_j}
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-org579a327" class="outline-4">
<h4 id="org579a327"><span class="section-number-4">2.7.3.</span> Choosing between scaling vs standardization</h4>
<div class="outline-text-4" id="text-2-7-3">
<ul class="org-ul">
<li>Scale when:
<ul class="org-ul">
<li>Data is in bounded (defined) range, e.g.
<ul class="org-ul">
<li>Neural networks</li>
<li>Optimization models requiring bounded data</li>
<li>Batting averages (between 0 and 1)</li>
<li>RGB color scale (0-255)</li>
<li>SAT scores (200-800)</li>
</ul></li>
</ul></li>
<li>Standardization, examples:
<ul class="org-ul">
<li>PCA</li>
<li>Clustering</li>
</ul></li>
<li>Try both when not clear</li>
<li>Should be used throughout course even when not stated explicitly</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgcb0bebd" class="outline-3">
<h3 id="orgcb0bebd"><span class="section-number-3">2.8.</span> M2L8: K Nearest Neighbour model (KNN)</h3>
<div class="outline-text-3" id="text-2-8">
<ul class="org-ul">
<li><b>Classification</b></li>
<li>e.g. loan dataset with two predictors and a response</li>
<li>Assume each point has similar characteristics with its neighbors</li>
<li>Choice of number of points is denoted by \(k\)</li>
<li>Algorithm to find color (class) of a new point:
<ol class="org-ol">
<li>Pick \(k\) closest points (i.e., nearest neighbours) to the new one</li>
<li>The new point's class is the most common among the \(k\) neighbors</li>
</ol></li>
<li>Complexities
<ul class="org-ul">
<li>More than one distance metric (<i>c.f.</i> distance selection topic_).
<ul class="org-ul">
<li>Straight line is: \(\sqrt{\sum_{i=1}^n |x_i-y_i|^2}\)</li>
</ul></li>
<li>Attributes can be given more weight if more important, \(w_i\)
<ul class="org-ul">
<li>Weights to be found with other techniques e.g. regression</li>
</ul></li>
<li>Unimportant metrics can be removed
<ul class="org-ul">
<li><i>c.f.</i> variable selection topic</li>
<li>Choose good value of \(k\), <i>c.f.</i> validation @ <a href="#org9a228fd">3</a></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9a228fd" class="outline-2">
<h2 id="org9a228fd"><span class="section-number-2">3.</span> Module 03: Validation</h2>
<div class="outline-text-2" id="text-3">
<blockquote>
<p>
Check how good a model is
</p>
</blockquote>
</div>
<div id="outline-container-org01abf84" class="outline-3">
<h3 id="org01abf84"><span class="section-number-3">3.1.</span> M3L1: Training, validation and test data</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li><b>Cannot</b> calculate accuracy or effectiveness metrics from training dataset
<ul class="org-ul">
<li>Since model was trained on it</li>
<li>This doesn't allow separation of real effects from random effects</li>
</ul></li>
<li>When fitting a model, this captures both real and random effects
<ul class="org-ul">
<li>Real effects: exist in all datasets (or subsets)</li>
<li>Random effects: different in all datasets</li>
</ul></li>
<li>Use a <b>training</b> set of data to fit model</li>
<li>Use another <b>validation</b> set of data to judge model effectiveness</li>
<li>When comparing &gt;1 model, use a <b>test</b> dataset.
<ul class="org-ul">
<li>e.g. SVM and KNN, with 10 total models, we cannot use the effectiveness metric calculated on the validation set.</li>
</ul></li>
<li>Test data is required as high performing models have above average random effects
<ul class="org-ul">
<li>Too optimistic; it might have performed well but also likely received a boost from random effects</li>
</ul></li>
<li>Analogize with models equally good</li>
<li>Flowchart:
<img src="./img/validation01.png" alt="validation01.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-orgdfcbfdb" class="outline-3">
<h3 id="orgdfcbfdb"><span class="section-number-3">3.2.</span> M3L2: Splitting data</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>How much data goes to each set?
<ol class="org-ol">
<li>70 to 90% train, remaining test</li>
<li>50 to 70% train, remaining evenly split validation &amp; test</li>
</ol></li>
<li>Methods of splitting data
<ol class="org-ol">
<li>Random</li>
<li>Rotation (take turn selecting data points into training, test, valid across the sets of split data)
<ul class="org-ul">
<li>Advantage: in time series data, may avoid all datasets having early/late data</li>
<li>Need to ensure rotation doesn't introduce bias</li>
</ul></li>
<li>Combined:
60% of Monday data for training, 60^% of Tuesday data for training, etc.</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org3905c66" class="outline-3">
<h3 id="org3905c66"><span class="section-number-3">3.3.</span> M3L3: Cross-validation</h3>
<div class="outline-text-3" id="text-3-3">
<blockquote>
<p>
What happens with important data appears only in one data set e.g., validation?
</p>
</blockquote>
<ul class="org-ul">
<li>Use cross-validation!</li>
<li>k-fold cross validation
<ol class="org-ol">
<li>Split data for testing (e.g. 20%)</li>
<li>With remaining data, use it for both training and validation by splitting into 4 x 20%, then:
<ol class="org-ol">
<li>Train 1, 2, 3, Validate 4</li>
<li>Train 1, 2, 4, Validate 3</li>
<li>Train 1, 3, 4, Validate 2</li>
<li>Train 2, 3, 4, Validate 1</li>
</ol></li>
</ol></li>
<li>Summary of k-fold cross-validation:
<ul class="org-ul">
<li>Train model on all other parts</li>
<li>Evaluate model on remaining part</li>
<li>Average \(k\) evaluations to estimate the model quality.</li>
<li>\(10\) is commonly selected for \(k\).</li>
<li><b>But</b>, the model selected from cross-validation is not used. Coefficients should also not be averaged.</li>
<li>Once model is selected, <b>retrain</b> with all data</li>
</ul></li>
<li>Advantages of k-fold cross-validation:
<ol class="org-ol">
<li>Better uses data</li>
<li>Better estimates model quality</li>
<li>Choose model more effectively</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-orgb2b213a" class="outline-3">
<h3 id="orgb2b213a"><span class="section-number-3">3.4.</span> M3L4: Summary</h3>
<div class="outline-text-3" id="text-3-4">
<ol class="org-ol">
<li>Build model with training data</li>
<li>Pick model with validation data</li>
<li>Estimate performance with test data</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org3438bc8" class="outline-2">
<h2 id="org3438bc8"><span class="section-number-2">4.</span> Module 04: Clustering</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-orgcb7e185" class="outline-3">
<h3 id="orgcb7e185"><span class="section-number-3">4.1.</span> M4L1: Introduction to clustering</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li><b>Unsupervised</b> method (response not available for use in training)</li>
<li>Grouping data points</li>
<li>Might help discover attributes in the dataset</li>
<li>Example of use
<ul class="org-ul">
<li>Segmenting market of car buyers by:
<ol class="org-ol">
<li>Size</li>
<li>Price</li>
<li>Versatility, etc</li>
</ol></li>
<li>Personalized medicine</li>
<li>Locating facilities</li>
<li>Image analysis</li>
<li>Exploratory data analysis (different model for each attribute)</li>
</ul></li>
<li>Example: Miles driven vs. Age</li>
</ul>
</div>
</div>
<div id="outline-container-orgdf6dfc5" class="outline-3">
<h3 id="orgdf6dfc5"><span class="section-number-3">4.2.</span> M4L2: Distance Norms</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>Straight line distance (Euclidean)
\(\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}\)</li>
<li>Rectilinear distance (Manhattan, 1-norm)
\(|x_1-y_1| + |x_2-y_2|\)</li>
<li>Generalized p-norm (Minkowski)
\(\sqrt[p]{|x_1-y_1|^p+|x_2-y_2|^p}\)</li>
<li>&infin;-norm distance
\(\sqrt[\infty]{\sum_{i=1}^n|x_i-y_i|^{\infty}}\)
<ul class="org-ul">
<li>sum = \(|x_i-y_i|^{\infty}\)</li>
<li>\(\sqrt[\infty]{\text{max}_{i}^n|x_i-y_i|^{\infty}}\)</li>
<li>Largest term dominates the rest, hence simplifies to:</li>
<li>\(\text{max}_i |x_i-y_i|\)</li>
</ul></li>
<li>Analogize with warehouse picking robot. The operation that takes the longest dominates the total operation time.</li>
</ul>
</div>
</div>
<div id="outline-container-org136cd87" class="outline-3">
<h3 id="org136cd87"><span class="section-number-3">4.3.</span> M4L3: K-Means Clustering</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li><b>Unsupervised</b> technique</li>
<li>Steps to implement K-Means:
<ol class="org-ol">
<li>Plot data points on suitable axes (e.g., age vs temperature, sepal width vs sepal height)</li>
<li>Let:
<ul class="org-ul">
<li>\(x_{ij}\) = attribute \(j\) of data point \(i\)</li>
<li>\(y_{ik}\) = \(1\) iif data point \(i\) in cluster \(k\), else \(0\)</li>
<li>\(z_{jk}\) = coordinate \(j\) of cluster center \(k\)</li>
<li>Mathematically, but it takes too long:
\[
       \text{Min}_{y,z}\sum_i\sum_k \sqrt{\sum_{j} (x_{ij} - z_{jk})^2}
       \]
subject to: \(\sum_k y_{ik} = 1\) for each \(i\)</li>
</ul></li>
<li>Practical method:
<ul class="org-ul">
<li>Pick \(k\) cluster centers in data</li>
<li>Assign each point to nearest cluster center</li>
<li>Recalculate cluster center (centroid)
<ul class="org-ul">
<li>Now, data points might not belong to the right cluster</li>
</ul></li>
<li>Go back to assign, then re-calc, then assign, then re-calc iteratively until stable</li>
</ul></li>
<li>K-Means is a <b>heuristic</b>, i.e.:
<ul class="org-ul">
<li>it is fast and good</li>
<li><b>not guaranteed</b> to find global best solution.</li>
</ul></li>
<li>It is expectation-maximization (EM), and alternates between expectation (<i>finding cluster centers</i>) and maximization (<i>assigning points to clusters</i>)</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org628d020" class="outline-3">
<h3 id="org628d020"><span class="section-number-3">4.4.</span> M4L4: Practical details for K-Means</h3>
<div class="outline-text-3" id="text-4-4">
<p>
Algorithm just assigns outliers to nearest clusters.
</p>
<ul class="org-ul">
<li>Choosing <b>starting points</b>:
<ol class="org-ol">
<li>Run several times with different initial cluster centers</li>
<li>Algorithm is non-deterministic, <i>i.e.</i> can produce different results when run with different inputs</li>
<li>Choose the best solution from the results produced</li>
</ol></li>
<li>Handling <b>outliers</b>:
<ol class="org-ol">
<li>Discard, but may not be the 'right' answer</li>
<li>Ask why the outlier happens
<ul class="org-ul">
<li>What it means to discard or include the outlier</li>
<li>Ultimately, algorithm is just a guide. Best solution is what fits the situation.</li>
</ul></li>
</ol></li>
<li>Choosing <b>number of clusters</b>. Is adding a cluster always better?
<ul class="org-ul">
<li>It may increase the metric (total distance of each data point to their cluster center), hence clustering appears to work better.</li>
<li>However, it may defeat the purpose of clustering if every cluster just consists of one data point.</li>
</ul></li>
<li>Total distance can be compared to find the 'kink' or 'elbow'.
<ul class="org-ul">
<li>After this point, the marginal benefit of adding another cluster decreases.</li>
<li><p>
Elbow diagram:
</p>


<div id="org43aa62f" class="figure">
<p><img src="./img/04-elbow.png" alt="04-elbow.png" />
</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge9f70ee" class="outline-3">
<h3 id="orge9f70ee"><span class="section-number-3">4.5.</span> M4L5: Clustering for prediction</h3>
<div class="outline-text-3" id="text-4-5">
<blockquote>
<p>
Given a new point, which cluster should it be in?
</p>
</blockquote>
<ul class="org-ul">
<li>Is point inside cluster?</li>
<li>Otherwise, what's the nearest cluster center?</li>
<li>Asked another way: for the range of the dataset, which areas would we assign to each cluster if a new point appears there?
<ul class="org-ul">
<li>This is a <a href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi diagram</a>.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgfc9ee1d" class="outline-3">
<h3 id="orgfc9ee1d"><span class="section-number-3">4.6.</span> M4L6: Clustering vs Classification</h3>
<div class="outline-text-3" id="text-4-6">
<ul class="org-ul">
<li>Since both group data points&#x2026;</li>
<li>The difference is what we know about the data points.</li>
<li>For classification, the correct response is known, i.e.
<ul class="org-ul">
<li>supervised learning</li>
<li>model uses both attributes <b>and</b> response</li>
</ul></li>
<li>For clustering, the 'correct' classification is unknown
<ul class="org-ul">
<li>unsupervised learning</li>
<li>model decides clusters <b>only</b> based on the attributes</li>
</ul></li>
<li>Supervised learning is more common</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1d4e25f" class="outline-2">
<h2 id="org1d4e25f"><span class="section-number-2">5.</span> Module 05: Data preparation</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-org3db6af4" class="outline-3">
<h3 id="org3db6af4"><span class="section-number-3">5.1.</span> M5L1: Common techniques and problems</h3>
<div class="outline-text-3" id="text-5-1">
<ol class="org-ol">
<li>Scale data
<ul class="org-ul">
<li>Outliers?</li>
</ul></li>
<li>Extraneous (unnecessary data)
<ul class="org-ul">
<li>Complicates the model and</li>
<li>Makes it harder to interpret the solution</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org338c66e" class="outline-3">
<h3 id="org338c66e"><span class="section-number-3">5.2.</span> M5L2: Outliers</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>Types
<dl class="org-dl">
<dt>Point outliers</dt><dd>one / few points very different from others</dd>
<dt>Contextual outlier</dt><dd>Value far from other points in time (not in absolute value)</dd>
<dt>Collective outlier</dt><dd>Something missing in a range of points, but not sure exactly where. Outlier by omission.</dd>
</dl></li>
<li>How to detect?
<ul class="org-ul">
<li>Box-and-whisker plot if data can be plotted in 1-dimension
<ul class="org-ul">
<li>Box: 25/75th percentile
<ul class="org-ul">
<li>Line: 50th percentile</li>
</ul></li>
<li>Whiskers: 10/90th percentile, 5/95th, etc</li>
</ul></li>
<li>For multi-dimensional, no good way. We can still:
<ol class="org-ol">
<li>Fit a model.</li>
<li>Points with large error might be outlier</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3233992" class="outline-3">
<h3 id="org3233992"><span class="section-number-3">5.3.</span> M5L3: What to do with outliers?</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>Need to understand why there's outliers
<ol class="org-ol">
<li>Bad data
<ul class="org-ul">
<li>Sensor fail</li>
<li>Contaminated experiment</li>
<li>Wrong data input</li>
</ul></li>
<li>Unexpected, real, data
<ul class="org-ul">
<li>Need to understand more about the data, e.g.</li>
<li>Where it came from</li>
<li>How it was compiled</li>
<li>Unique situations</li>
</ul></li>
</ol></li>
</ul>
</div>
<div id="outline-container-orgfe179d5" class="outline-4">
<h4 id="orgfe179d5"><span class="section-number-4">5.3.1.</span> Bad data</h4>
<div class="outline-text-4" id="text-5-3-1">
<ul class="org-ul">
<li>Omit the points</li>
<li>Use imputation to replace the points</li>
</ul>
</div>
</div>
<div id="outline-container-orge886313" class="outline-4">
<h4 id="orge886313"><span class="section-number-4">5.3.2.</span> Real / correct data</h4>
<div class="outline-text-4" id="text-5-3-2">
<ul class="org-ul">
<li>Outliers are somewhat expected in large datasets</li>
<li>E.g., for normally-distributed data:
<ul class="org-ul">
<li>4% will be outside 2 &sigma;</li>
<li>1e6 data points = 2000 outside 3 &sigma;</li>
</ul></li>
<li>Removing <b>real</b> outliers might make model too optimistic. <i>e.g.</i> not account for actual shipments that take a long time from US to Africa</li>
<li>Outliers might be due to weather, political events</li>
</ul>
</div>
</div>
<div id="outline-container-org79c0a6f" class="outline-4">
<h4 id="org79c0a6f"><span class="section-number-4">5.3.3.</span> Another way to handle outliers</h4>
<div class="outline-text-4" id="text-5-3-3">
<ol class="org-ol">
<li>First build a logistic regression model
<ul class="org-ul">
<li>This estimated probability of outliers under different conditions</li>
</ul></li>
<li>Next, build the regular model i.e. estimate delivery time under <b>normal conditions</b>
<ul class="org-ul">
<li>Use data without outliers</li>
<li>Report different outcomes&#x2026;</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org8e484f5" class="outline-4">
<h4 id="org8e484f5"><span class="section-number-4">5.3.4.</span> Summary</h4>
<div class="outline-text-4" id="text-5-3-4">
<ul class="org-ul">
<li>Outliers aren't predictable</li>
<li>Investigate the data in case you're wrong</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org74c99ef" class="outline-2">
<h2 id="org74c99ef"><span class="section-number-2">6.</span> Module 06: Change detection</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org92d0791" class="outline-3">
<h3 id="org92d0791"><span class="section-number-3">6.1.</span> M6L1: Examples</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>Usually with time series data</li>
<li>Determine if action is needed, e.g.,
<ul class="org-ul">
<li>Time for machine maintenance?</li>
<li>Have sales increased?</li>
</ul></li>
<li>Determine impact of some past action, e.g.,
<ul class="org-ul">
<li>Did new tax / increase rate decrease sales?</li>
<li>Did price discount increase sales?</li>
</ul></li>
<li>Determine changes of current actions, e.g.
<ul class="org-ul">
<li>Did voting patterns change?</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org0811a4d" class="outline-3">
<h3 id="org0811a4d"><span class="section-number-3">6.2.</span> M6L2: Cumulative sum for change detection</h3>
<div class="outline-text-3" id="text-6-2">
<blockquote>
<p>
Answers whether mean of the observed distribution gone above a critical level
</p>
</blockquote>
<ul class="org-ul">
<li>x<sub>t</sub> is observed value at time \(t\)</li>
<li>&mu; is mean of \(x\), if no change in distribution</li>
<li>Hence, \((x_t - \mu)\) is how much the observation is above mean at time \(t\)</li>
<li>Detecting an increase
\[
  S_t = \text{max}\{ 0, s_{t-1}+(x_t-\mu-C) \}
  \]
<ul class="org-ul">
<li>Determine threshold \(T\) and ask whether S<sub>t</sub> ⩾ T?
<ul class="org-ul">
<li>If running total &lt; 0, it's irrelevant</li>
<li>There should still be some randomness</li>
<li>C is a term to control how faster S<sub>t</sub> increases</li>
</ul></li>
</ul></li>
<li>Detecting a decrease
\[
  S_t = \text{max}\{ 0, s_{t-1}+(\mu-x_t-C) \}
  \]
<ul class="org-ul">
<li>Is S<sub>t</sub> ⩾ T?</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgd49c048" class="outline-4">
<h4 id="orgd49c048"><span class="section-number-4">6.2.1.</span> Interpretation</h4>
<div class="outline-text-4" id="text-6-2-1">
<ul class="org-ul">
<li>Choices of model parameters
<dl class="org-dl">
<dt>T</dt><dd>the threshold, above which alarm is raised</dd>
<dt>C</dt><dd>the control term (smaller = more sensitive)</dd>
</dl></li>
<li>Consider / trade off:
<ol class="org-ol">
<li>How costly is it to delay detection? (false negative) -&gt; if it's costly, use small C</li>
<li>How costly is false positive? -&gt; if it's costly, use big C</li>
</ol></li>
<li>Use a control chart and plot S<sub>t</sub> vs t with \(T\) as a horizontal line
<img src="./img/06-control-chart.png" alt="06-control-chart.png" /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7bfb193" class="outline-3">
<h3 id="org7bfb193"><span class="section-number-3">6.3.</span> M6L3: Ethics: Honestly reporting our results</h3>
<div class="outline-text-3" id="text-6-3">
<ul class="org-ul">
<li>Be faithful to data</li>
<li>Have sound conclusions drawn from the model and not your own conceptions</li>
<li>Always be honest and true to your analysis</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgec89109" class="outline-2">
<h2 id="orgec89109"><span class="section-number-2">7.</span> Module 07: Time series</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-orgbdb2d0b" class="outline-3">
<h3 id="orgbdb2d0b"><span class="section-number-3">7.1.</span> M7L1: Introduction to exponential smoothing</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>Data for the same response is known for many time periods</li>
<li>Examples:
<ul class="org-ul">
<li>Temperature readings</li>
<li>Price of stocks</li>
<li>Daily sales of hamburgers</li>
<li>Blood pressure readings</li>
</ul></li>
<li>Variation in time series data:
<ol class="org-ol">
<li>Trends increase or decrease</li>
<li>Cyclical variables over a year or a week</li>
</ol></li>
</ul>
</div>
<div id="outline-container-org4ee44ba" class="outline-4">
<h4 id="org4ee44ba"><span class="section-number-4">7.1.1.</span> Random variation</h4>
<div class="outline-text-4" id="text-7-1-1">
<ul class="org-ul">
<li>No underlying reason for the variation</li>
</ul>
</div>
</div>
<div id="outline-container-org072537b" class="outline-4">
<h4 id="org072537b"><span class="section-number-4">7.1.2.</span> Definitions:</h4>
<div class="outline-text-4" id="text-7-1-2">
<ul class="org-ul">
<li>\(S_t\): expected <b>baseline</b> response at time period \(t\)</li>
<li>\(x_t\): the observed response at \(t\)</li>
<li>Seeing a increase over time, is it
<ol class="org-ol">
<li>A real increase?</li>
<li>Random?</li>
</ol></li>
<li>There are two ways to answer:
<ol class="org-ol">
<li>It's a real increase, hence \(S_t = x_t\)
<ul class="org-ul">
<li>the observed reading is real indicator of revised baseline</li>
</ul></li>
<li>It's random, hence \(S_t = S_{t-1}\)
<ul class="org-ul">
<li>today's baseline = yesterday's baseline</li>
</ul></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org82a3170" class="outline-4">
<h4 id="org82a3170"><span class="section-number-4">7.1.3.</span> Exponential smoothing method</h4>
<div class="outline-text-4" id="text-7-1-3">
<p>
Combines both, i.e.
\(S_t = \alpha x_t + (1-\alpha)S_{t-1}\)
</p>
<ul class="org-ul">
<li><p>
0 &lt; &alpha; &lt;1
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&alpha;</th>
<th scope="col" class="org-left">example value of &alpha;</th>
<th scope="col" class="org-left">randomness</th>
<th scope="col" class="org-left">trust</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">small</td>
<td class="org-left">&rarr; 0 (e.g. 0.01)</td>
<td class="org-left">high</td>
<td class="org-left">previous baseline i.e. \(S_{t-1}\)</td>
</tr>

<tr>
<td class="org-left">large</td>
<td class="org-left">&rarr; 1 (e.g. 0.99)</td>
<td class="org-left">low</td>
<td class="org-left">today's estimate i.e. \(x_t\)</td>
</tr>
</tbody>
</table></li>

<li>How to start? \(S_1 = x_1\)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga27e618" class="outline-3">
<h3 id="orga27e618"><span class="section-number-3">7.2.</span> M7L2: Trend and cyclic effects</h3>
<div class="outline-text-3" id="text-7-2">
<p>
Complexities!
</p>
<ul class="org-ul">
<li>Trends, increasing or decreasing</li>
<li>Cyclical patterns, e.g. annual, weekly, daily</li>
</ul>
</div>
<div id="outline-container-orgb903cd4" class="outline-4">
<h4 id="orgb903cd4"><span class="section-number-4">7.2.1.</span> Trends</h4>
<div class="outline-text-4" id="text-7-2-1">
<ul class="org-ul">
<li>\(T_t\): the trend at time period \(t\)</li>
<li>\(S_t = \alpha x_t + (1-\alpha)(S_{t-1}+T_{t-1})\)</li>
<li>\(T_t = \beta(S_t - S_{t-1}) + (1-\beta)T_{t-1}\)</li>
<li>Initial condition: \(T_1=0\)</li>
</ul>
</div>
</div>
<div id="outline-container-orgc63cc7d" class="outline-4">
<h4 id="orgc63cc7d"><span class="section-number-4">7.2.2.</span> Cyclical patterns</h4>
<div class="outline-text-4" id="text-7-2-2">
<ul class="org-ul">
<li>Make cycles additive: behaves like trend</li>
<li>Make cycles multiplicative: more notation required
<ul class="org-ul">
<li>L = length of cycle</li>
<li>\(C_t\) = the multiplicative seasonality factor
<ul class="org-ul">
<li>This inflates or deflates the observation</li>
</ul></li>
<li>New baseline formula
\[
    S_t = \frac{\alpha x_t}{C_{t-L}} + (1-\alpha)(S_{t-1}+T_{t-1})
    \]</li>
<li>Need to use the factor from \(L\) time periods ago
<ul class="org-ul">
<li>as that's the most recent cyclic factor we have from that part of the cycle</li>
</ul></li>
<li>Update the cyclic factor in a similar way i.e.:
<ul class="org-ul">
<li>\(C_t = \gamma(x_t/S_t) + (1-\gamma)(C_{t-L})\)</li>
<li>C<sub>1</sub>, &#x2026;, C<sub>L</sub> = 1
<ul class="org-ul">
<li>meaning there's no initial cyclic effect</li>
</ul></li>
<li>If C = 1.1 on Sunday:
<ul class="org-ul">
<li>sales are higher by 10% just because it's Sunday</li>
</ul></li>
</ul></li>
<li>Initial values: first \(L\) are set to 1. Multiplying by 1 = no effect</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org131687f" class="outline-4">
<h4 id="org131687f"><span class="section-number-4">7.2.3.</span> Summary</h4>
<div class="outline-text-4" id="text-7-2-3">
<ul class="org-ul">
<li>Exponential smoothing
<ul class="org-ul">
<li>Single</li>
<li>Double (with trend)</li>
<li>Triple (with trend and cyclic effects)
<ul class="org-ul">
<li>AKA Winter's method, or Holt-Winters</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgce59e18" class="outline-3">
<h3 id="orgce59e18"><span class="section-number-3">7.3.</span> M7L3: Etymology (what the name means)</h3>
<div class="outline-text-3" id="text-7-3">
<p>
Example equation when \(\alpha = \frac{1}{2}\):
\(S_t = 0.5 x_t + 0.5 S_{t-1}\)
</p>
</div>
<ol class="org-ol">
<li><a id="org67684d3"></a>Smoothing<br />
<div class="outline-text-5" id="text-7-3-0-1">
<ul class="org-ul">
<li>Note: when x<sub>t</sub> is high, S<sub>t</sub> is <b>not</b> as high, as \((1-\alpha)S_{t-1}\) pulls it down</li>
<li>Conversely: when x<sub>t</sub> is low, S<sub>t</sub> is <b>not</b> as low, as \((1-\alpha)S_{t-1}\) pulls it up</li>
<li>Peaks and valleys are smoothed out
<img src="./img/07-smoothed-graph.png" alt="07-smoothed-graph.png" /></li>
</ul>
</div>
</li>
<li><a id="org8239285"></a>Exponential<br />
<div class="outline-text-5" id="text-7-3-0-2">
<ul class="org-ul">
<li>Each \(S_{t-1}\) actually contains every previous value of x!
<ul class="org-ul">
<li>When written or expanded out, e.g.
\[
    S_t = \alpha x_t + (1-\alpha)S_{t-1}
    \]
\[
    S_{t} = \alpha x_t + (1-\alpha)[\alpha x_{t-1} + (1-\alpha)S_{t-2}]
    \]
\[
    S_{t} = \alpha x_t + (1-\alpha)\alpha x_{t-1} + (1-\alpha)^2S_{t-2}
    \]</li>
</ul></li>
<li>Each S<sub>t</sub> is weighed by (1-&alpha;) to an increasing <b>exponent</b></li>
<li>This means not only the current observation matters; instead, every past observation contributes to the current baseline estimate</li>
<li>However, more recent observations are more important as they have higher weight</li>
</ul>
</div>
</li>
</ol>
<div id="outline-container-org801af83" class="outline-4">
<h4 id="org801af83"><span class="section-number-4">7.3.1.</span> Summary</h4>
<div class="outline-text-4" id="text-7-3-1">
<ul class="org-ul">
<li>Exponential smoothing smooths out jumps in observed data</li>
<li>It's an exponential weighting of all past observations</li>
<li>More recent observations are more important to the current baseline estimate</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd677a7a" class="outline-3">
<h3 id="orgd677a7a"><span class="section-number-3">7.4.</span> M7L4: Forecasting</h3>
<div class="outline-text-3" id="text-7-4">
<ul class="org-ul">
<li>Recap: \(S_t = \alpha x_t + (1-\alpha)S_{t-1}\)</li>
<li>Prediction:
<ul class="org-ul">
<li>\(S_{t+1} = \alpha x_{t+1} + (1-\alpha)S_{t}\)</li>
<li>However x<sub>t+1</sub> is unknown</li>
<li>Best guess for x<sub>t+1</sub> is \(S_t\)</li>
</ul></li>
<li>Our forecast for \(t+1\) is hence (after substituting):
\[
  F_{t+1}=\alpha S_t + (1-\alpha) S_t \\
  F_{t+1} = S_t \\
  F_{t+k} = S_t \text{when } k=1, 2, ...
  \]
<ul class="org-ul">
<li>note that forecast error becomes larger for larger \(k\)</li>
</ul></li>
<li>If including trend:
\[
  S_t = \alpha x_t + (1-\alpha)(S_{t-1}+T_{t-1}) \\
  T_t = \beta (S_t-S_{t-1})+(1-\beta)T_{t-1} \\
  F_{t+1} = S_t + T_t \\
  F_{t+k} = S_t + kT_t, k=1,2,...
  \]
<dl class="org-dl">
<dt>Best estimate of next baseline</dt><dd>the most current baseline estimate</dd>
<dt>Best estimate of the trend</dt><dd>the most current trend estimate</dd>
</dl></li>
<li>If including multiplicative seasonality:
\[
  S_t = \alpha x_t/C_{t-L} + (1-\alpha)(S_{t-1}+T_{t-1})
  F_{t+1} = (S_t+T_t)C_{(t+1)-L}
  \]
<dl class="org-dl">
<dt>Best estimate of next time period seasonal factor</dt><dd>the corresponding (lagged) seasonal factor, i.e. \(C_{t+1}=C_{t+1-L}\)</dd>
</dl></li>
<li>Finding the right &alpha;, &beta;, &gamma;: use optimization, to be covered in future
<ul class="org-ul">
<li>\(\min{(F_t-x_t)^2}\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org58db0cb" class="outline-3">
<h3 id="org58db0cb"><span class="section-number-3">7.5.</span> M3L5: ARIMA</h3>
<div class="outline-text-3" id="text-7-5">
<p>
AutoRegressive Integrated Moving Average.
</p>
<ul class="org-ul">
<li>ARIMA <b>theory</b> is not covered in IAM.</li>
</ul>
</div>
<div id="outline-container-org3c6d735" class="outline-4">
<h4 id="org3c6d735"><span class="section-number-4">7.5.1.</span> (I): Differences</h4>
<div class="outline-text-4" id="text-7-5-1">
<ul class="org-ul">
<li>Exponential smoothing assumes <b>stationary</b> data, i.e.
<ul class="org-ul">
<li>mean, variance, other measures are constant over time</li>
</ul></li>
<li>ARIMA works for data that's not stationary
<ul class="org-ul">
<li>if differences in data are stationary
<dl class="org-dl">
<dt>1st order difference D<sub>(1)</sub></dt><dd>difference of consecutive observations, i.e. \(D_{(1)t}=(x_t-x_{t-1})\)</dd>
<dt>2nd order difference D<sub>(2)</sub></dt><dd>difference of the differences i.e.
\(D_{(2)t}=(x_t-x_{t-1})-(x_{t-1}-x_{t-2})\)</dd>
<dt>d<sup>th</sup> order difference D<sub>(d)</sub></dt><dd>diff&#x2026; d times</dd>
</dl></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb5ea287" class="outline-4">
<h4 id="orgb5ea287"><span class="section-number-4">7.5.2.</span> (II): Autogression</h4>
<div class="outline-text-4" id="text-7-5-2">
<ul class="org-ul">
<li>Predicting current values based on previous period's values</li>
<li>Regression: predicting value based on other factors</li>
<li>Auto: use earlier values to predict. Only works with time series</li>
<li>When used to forecast, exponential smoothing is an order-&infin; autoregressive model
<ul class="org-ul">
<li>All previous values are used to make current prediction</li>
</ul></li>
<li>Order-p autoregressive model: S<sub>t</sub> is function of \(\{x_t, x_{t-1}, ..., x_{t-(p-1)}\}\)
<ul class="org-ul">
<li>Only go back \(p\) periods</li>
</ul></li>
<li>ARIMA: combines autoregression and differencing
<ul class="org-ul">
<li>Autoregression on the differences</li>
<li>Use \(p\) time periods of previous observations to predict \(d^{th}\) order differences</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3676cb1" class="outline-4">
<h4 id="org3676cb1"><span class="section-number-4">7.5.3.</span> (III): Moving Average</h4>
<div class="outline-text-4" id="text-7-5-3">
<ul class="org-ul">
<li>Use previous errors &epsilon;<sub>t</sub> as predictors
<ul class="org-ul">
<li>\(\epsilon_t = (\hat{x_t}-x_t)\)</li>
</ul></li>
<li>Order-q moving average
<ul class="org-ul">
<li>go back \(q\) time periods</li>
<li>\(\epsilon_{t-1}, \epsilon_{t-2}, ..., \epsilon_{t-q}\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org1eab2ab" class="outline-4">
<h4 id="org1eab2ab"><span class="section-number-4">7.5.4.</span> ARIMA model</h4>
<div class="outline-text-4" id="text-7-5-4">
<p>
ARIMA (p,d,q) model
</p>
<ul class="org-ul">
<li>\(d^{th}\) order differences</li>
<li>\(p^{th}\) order autoregression</li>
<li>\(q^{th}\) order moving average</li>
<li><a id="orgaaa00f7"></a>Equation:
\[
  D_{(d)t} = \mu + \sum^p_{i=1}\alpha_i D_{(d)t-i} - \sum^q_{i=1} \theta_i (\hat{x}_{t-i}-x_{t-i})
  \]</li>
<li>Software can find \(d, p, q\)</li>
<li>Extensions
<ol class="org-ol">
<li>Add seasonality (out of scope for IAM)</li>
<li>Specific models:
<dl class="org-dl">
<dt>ARIMA(0,0,0)</dt><dd>white noise</dd>
<dt>ARIMA(0,1,0)</dt><dd>random walk</dd>
<dt>ARIMA(p,0,0)</dt><dd>AR (autoregressive) model</dd>
<dt>ARIMA(0,0,q)</dt><dd>MA (moving avg) model</dd>
<dt>ARIMA(0,1,1)</dt><dd>basic exponential smoothing model</dd>
</dl></li>
</ol></li>
<li>Can be used for short-term forecasting
<ul class="org-ul">
<li>ARIMA is better than ES when data is more stable with fewer peaks, valleys, outliers</li>
<li>ARIMA needs 40+ historical data points to work well</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgec642c0" class="outline-3">
<h3 id="orgec642c0"><span class="section-number-3">7.6.</span> M7L6: GARCH</h3>
<div class="outline-text-3" id="text-7-6">
<dl class="org-dl">
<dt>GARCH</dt><dd>Generalized Autoregressive Conditional Heteroskedasticity</dd>
</dl>
<p>
To estimate or forecast the variance
</p>
</div>
<div id="outline-container-org9f1e48a" class="outline-4">
<h4 id="org9f1e48a"><span class="section-number-4">7.6.1.</span> Variance</h4>
<div class="outline-text-4" id="text-7-6-1">
<ul class="org-ul">
<li>Estimates the amount of error</li>
<li>E.g. forecasting demand for trucks
<ul class="org-ul">
<li>tell you how much forecast might be higher/lower than the actual value you see (later) to plan accordingly</li>
</ul></li>
<li>In investment (portfolio optimization):
<ul class="org-ul">
<li>Balance the expected return in investment with amount of volatility.
<dl class="org-dl">
<dt>Riskier</dt><dd>higher expected return</dd>
<dt>Less risky</dt><dd>lower expected return</dd>
</dl></li>
<li>Variance is a proxy for amount of volatility or risk</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc4dafb8" class="outline-4">
<h4 id="orgc4dafb8"><span class="section-number-4">7.6.2.</span> GARCH</h4>
<div class="outline-text-4" id="text-7-6-2">
<p>
\[
\sigma^2_t = \omega + \sum^p_{i=1}\beta_i\sigma^2_{t-1}+\sum^q_{i=1} \gamma_i \epsilon^2_{t-i}
\]
It looks very similar to <a href="#orgaaa00f7">ARIMA Equation</a>, but:
<b>Differences</b>:
</p>
<dl class="org-dl">
<dt>GARCH deals with variances and squared errors</dt><dd>ARIMA deals with observations and linear errors</dd>
<dt>GARCH deals with raw variances</dt><dd>ARIMA deals with differences of variances</dd>
</dl>
</div>
</div>
<div id="outline-container-orgf3f2a4c" class="outline-4">
<h4 id="orgf3f2a4c"><span class="section-number-4">7.6.3.</span> Summary - three models for time series analysis</h4>
<div class="outline-text-4" id="text-7-6-3">
<ol class="org-ol">
<li>Exponential smoothing</li>
<li>ARIMA, a generalization of exponential smoothing</li>
<li>GARCH, an ARIMA-like model for analyzing variance</li>
</ol>
</div>
</div>
</div>
</div>
<div id="outline-container-org8793c91" class="outline-2">
<h2 id="org8793c91"><span class="section-number-2">8.</span> Module 08: Regression</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-org4bc9bf0" class="outline-3">
<h3 id="org4bc9bf0"><span class="section-number-3">8.1.</span> M8L1: Intro to Regression</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<div id="outline-container-org2a0bfee" class="outline-4">
<h4 id="org2a0bfee"><span class="section-number-4">8.1.1.</span> What questions can regression answer?</h4>
<div class="outline-text-4" id="text-8-1-1">
<ol class="org-ol">
<li>How do systems work? (descriptive)</li>
<li>What will happen in the future? (predictive)</li>
</ol>
</div>
</div>
<div id="outline-container-org24eeae4" class="outline-4">
<h4 id="org24eeae4"><span class="section-number-4">8.1.2.</span> Simple linear regression</h4>
<div class="outline-text-4" id="text-8-1-2">
<ul class="org-ul">
<li>Linear regression with one predictor, e.g. \(y = a_0 + a_1x+1\)
<ul class="org-ul">
<li>Date point \(i\)'s prediction error
\(= y_i - \hat{y}_i -(a_0+a_1x_1)\)</li>
<li>Sum of squared errors
\(=\sum^n_{i=1}(y_i - \hat{y}_i)^2\)
\(=\sum^n_{i=1}(y_i-(a_0+a_1x_1))^2\)</li>
</ul></li>
<li>Best fit regression line
<ul class="org-ul">
<li>Minimizes sum of squared errors</li>
<li>Defined by a<sub>0</sub> and a<sub>1</sub></li>
</ul></li>
<li>Underlying math
<ul class="org-ul">
<li>Minimize convex quadratic function</li>
<li>Set partial derivatives to 0</li>
<li>Solve simultaneous equations</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge97825d" class="outline-3">
<h3 id="orge97825d"><span class="section-number-3">8.2.</span> M8L2: Maximum Likelihood and Information Criteria</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<div id="outline-container-org53a5f1b" class="outline-4">
<h4 id="org53a5f1b"><span class="section-number-4">8.2.1.</span> Likelihood</h4>
<div class="outline-text-4" id="text-8-2-1">
<ul class="org-ul">
<li>Measure the probability density of a parameter set</li>
<li id="Maximum likelihood">the parameters that give the highest probability</li>
<li>Assuming:
<ol class="org-ol">
<li>Errors are normally distributed with mean 0, variance &sigma;<sup>2</sup>, independently and identically distributed</li>
<li>Observations are z<sub>1</sub> to z<sub>n</sub></li>
<li>Model estimates are y<sub>1</sub> to y<sub>n</sub></li>
</ol></li>
<li>Probability density of observing z<sub>i</sub> if true value y<sub>i</sub> is
\[
  \frac{1}{\sigma\sqrt(2\pi)}e^-\frac{(z_u-y_i)^2}{2\sigma^2}
  \]</li>
<li>Joint density over \(n\) terms
\[
  \prod^n_{i=1}\frac{1}{\sigma\sqrt(2\pi)}e^-\frac{(z_u-y_i)^2}{2\sigma^2} \\
  = (\frac{1}{\sigma\sqrt{2\pi}})^n e^-\frac{1}{2\sigma^2}\sum^n_{i=1}(z_i-y_i)^2
  \]</li>
<li>Hence <b>to minimize</b> \(\sum^n_{i=1}(z_i-y_i)^2\) over a<sub>0</sub>, &#x2026;, a<sub>m</sub>:
equals to minimizing \(\sum^n_{i=1}(z_i-(a_0 + \sum^m_{j=1}a_jx_{ij}))^2\)</li>
</ul>
</div>
</div>
<div id="outline-container-org6b1c999" class="outline-4">
<h4 id="org6b1c999"><span class="section-number-4">8.2.2.</span> Maximum likelihood fitting</h4>
<div class="outline-text-4" id="text-8-2-2">
<ul class="org-ul">
<li>Simplest example is regression with i.i.d. errors</li>
<li>Complex examples:
<ul class="org-ul">
<li>Different estimation formulas</li>
<li>Different error assumptions</li>
</ul></li>
<li>Good software can handle complex cases</li>
</ul>
</div>
</div>
<div id="outline-container-orgaf6e261" class="outline-4">
<h4 id="orgaf6e261"><span class="section-number-4">8.2.3.</span> Akaike Information Criterion</h4>
<div class="outline-text-4" id="text-8-2-3">
<dl class="org-dl">
<dt>L<sup>*</sup></dt><dd>maximum likelihood value</dd>
<dt>\(k\)</dt><dd>number of parameters being estimated</dd>
<dt>AIC</dt><dd>\(2k-2\log(L^{*})\)</dd>
<dt>Penalty term</dt><dd>balances likelihood with simplicity, helps avoid overfitting</dd>
</dl>
</div>
<ol class="org-ol">
<li><a id="org86f8d37"></a>For simple regression<br />
<div class="outline-text-5" id="text-8-2-3-1">
<dl class="org-dl">
<dt>AIC</dt><dd>\[
  2(m+1) - 2\log(\frac{1}{\sigma\sqrt(2\pi)}^ne^{-\frac{1}{2\sigma^2}}\sum^n_{i=1}(z_i-(a_0 + \sum^m_{j=1}a_jx_{ij}))^2)
  \]</dd>
<dt>Preference</dt><dd>smaller AIC models</dd>
<dt>Requires</dt><dd>infinitely many data points</dd>
</dl>
</div>
</li>
</ol>
</div>
<div id="outline-container-org4e7d920" class="outline-4">
<h4 id="org4e7d920"><span class="section-number-4">8.2.4.</span> Corrected AIC (AIC<sub>c</sub>)</h4>
<div class="outline-text-4" id="text-8-2-4">
<p>
Use for smaller datasets.
\[
AIC_c = AIC + \frac{2k(k+1)}{n-k-1} \\
= 2k-2\log(L^{*})+\frac{2k(k+1)}{n-k-1}
\]
</p>
</div>
</div>
<div id="outline-container-orge130719" class="outline-4">
<h4 id="orge130719"><span class="section-number-4">8.2.5.</span> AIC<sub>c</sub> example</h4>
<div class="outline-text-4" id="text-8-2-5">
<ul class="org-ul">
<li>Model 1: AIC 75; Model 2: AIC 80</li>
<li>Relative likelihood equals:
\[
  e^\frac{AIC_1-AIC_2}{2} \\
  = 8.2%
  \]</li>
<li>Hence, Model 2 (larger AIC) is 8.2% as likely as Model 1 to be better
<ul class="org-ul">
<li>Model 1 is probably better</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd8d7214" class="outline-4">
<h4 id="orgd8d7214"><span class="section-number-4">8.2.6.</span> Bayesian Information Criterion</h4>
<div class="outline-text-4" id="text-8-2-6">
<ul class="org-ul">
<li>BIC:
\[
  k\log(n)-2\log(L^{*})
  \]</li>
<li>Similar to AIC, but
<ul class="org-ul">
<li>bigger penalty term than AIC's penalty term</li>
<li>encourages models with fewer parameters</li>
</ul></li>
<li>Use BIC when there are <b>more data points</b> than parameters</li>
<li><p>
Rule of thumb for |BIC<sub>1</sub> - BIC<sub>2</sub>|
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">value</th>
<th scope="col" class="org-left">interpretation for smaller BIC model</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">&gt;10</td>
<td class="org-left">very likely better</td>
</tr>

<tr>
<td class="org-right">6-10</td>
<td class="org-left">likely better</td>
</tr>

<tr>
<td class="org-right">2-6</td>
<td class="org-left">somewhat likely better</td>
</tr>

<tr>
<td class="org-right">0-2</td>
<td class="org-left">slightly likely better</td>
</tr>
</tbody>
</table></li>
</ul>
</div>
</div>
<div id="outline-container-orgce103be" class="outline-4">
<h4 id="orgce103be"><span class="section-number-4">8.2.7.</span> Summary</h4>
<div class="outline-text-4" id="text-8-2-7">
<ul class="org-ul">
<li>No definite rules for AIC, BIC, maximum likelihood</li>
<li>Can look at all 3 to decide what's best</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd4b6632" class="outline-3">
<h3 id="orgd4b6632"><span class="section-number-3">8.3.</span> M8L3: Using Regression</h3>
<div class="outline-text-3" id="text-8-3">
</div>
<div id="outline-container-orgac0237d" class="outline-4">
<h4 id="orgac0237d"><span class="section-number-4">8.3.1.</span> Regression coefficients</h4>
<div class="outline-text-4" id="text-8-3-1">
<ul class="org-ul">
<li>a<sub>0</sub>, a<sub>1</sub>, &#x2026;, a<sub>m</sub> for the equation:</li>
<li>\(y=a_0+a_1x_1+...+a_mx_m\)</li>
<li>Example for baseball, descriptive question:
<ul class="org-ul">
<li>How many runs is associated with every homerun</li>
<li>Response: how many runs are scored by a team</li>
<li>Predictors:
<ol class="org-ol">
<li>Number of HR</li>
<li>Triples</li>
<li>Doubles</li>
<li>Singles</li>
<li>Outs</li>
<li>Double Plays</li>
<li>Stolen bases, etc</li>
</ol></li>
<li>Equation:
\[
    \text{Runs scored} = a_0 + a_1\text{Number of HR} + a_2\text{Number of triples} + ... + a_7\text{Number of stolen bases}
    \]</li>
<li>a<sub>1</sub> = 1.4
<ul class="org-ul">
<li>Means that every HR adds 1.4 runs scored on average, ceteris paribus</li>
</ul></li>
</ul></li>
<li>Example: height, predictive question:
<ul class="org-ul">
<li>How tall will a 2-year old be as an adult?</li>
<li>Response: a person's adult height</li>
<li>Predictors:
<ol class="org-ol">
<li>Father's height</li>
<li>Mother's height</li>
<li>Height at age 2</li>
<li>Male, female</li>
</ol></li>
<li>Equation:
\[
    \text{Adult height} = a_0 + a_1\text{Father's height} + a_2 \text{Mother's height} + ... + a_4\text{Male or female}
    \]</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org4abc55b" class="outline-3">
<h3 id="org4abc55b"><span class="section-number-3">8.4.</span> M8L4: Causation vs Correlation</h3>
<div class="outline-text-3" id="text-8-4">
<dl class="org-dl">
<dt>Causation</dt><dd>one thing causes another thing</dd>
<dt>Correlation</dt><dd>two things tend to happen / not happen together, but neither one causes the other</dd>
</dl>
</div>
<div id="outline-container-org340b0c4" class="outline-4">
<h4 id="org340b0c4"><span class="section-number-4">8.4.1.</span> Example: winter recreation</h4>
<div class="outline-text-4" id="text-8-4-1">
<ul class="org-ul">
<li>y: hours per day spent outdoors in winter</li>
<li>x<sub>1</sub>: city's average daily winter temperature</li>
<li>Equation: \(y=a_0+a_1x_1\)</li>
<li>Correlation between y and x<sub>1</sub>
<ul class="org-ul">
<li>with low p-value of a<sub>1</sub></li>
</ul></li>
<li>Does higher temperature in winter cause people to go outside?
<ul class="org-ul">
<li>Probably</li>
</ul></li>
<li>Reversing the equation:
<ul class="org-ul">
<li>y: hours per day spent outdoors in winter</li>
<li>x<sub>1</sub>: city's average daily winter temperature</li>
<li>Equation: \(x_1 = b_0 + b_1y\)</li>
<li>Same correlation between y, x<sub>1</sub>
<ul class="org-ul">
<li>Same p-value of b<sub>1</sub> and a<sub>1</sub></li>
</ul></li>
<li>Hence, does spending more time outside <b>cause</b> higher winter temperatures?
<ul class="org-ul">
<li>No</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgfb27a89" class="outline-4">
<h4 id="orgfb27a89"><span class="section-number-4">8.4.2.</span> Example: tiredness vs scruffiness</h4>
<div class="outline-text-4" id="text-8-4-2">
<ul class="org-ul">
<li>Neither one caused another, they're just related to a common tired factor, kids</li>
</ul>
</div>
</div>
<div id="outline-container-org8fab6ab" class="outline-4">
<h4 id="org8fab6ab"><span class="section-number-4">8.4.3.</span> How to tell causation?</h4>
<div class="outline-text-4" id="text-8-4-3">
<ul class="org-ul">
<li>When is there causation?
<ol class="org-ol">
<li>Cause before effect</li>
<li>Idea of causation makes sense</li>
<li>No outside factors can cause the relationship (hard to ensure this - need to consider <b>all</b> other factors)</li>
</ol></li>
<li>Be careful before claiming causation</li>
</ul>
</div>
</div>
<div id="outline-container-org4824a18" class="outline-4">
<h4 id="org4824a18"><span class="section-number-4">8.4.4.</span> Meaningless correlations</h4>
<div class="outline-text-4" id="text-8-4-4">
<ul class="org-ul">
<li>Per capita consumption of mozzarella with number of civil engineering doctorates awarded</li>
<li><a href="http://tylervigen.com/spurious-correlations">link</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd40d3c9" class="outline-3">
<h3 id="orgd40d3c9"><span class="section-number-3">8.5.</span> M8L5: Transformations and Interactions</h3>
<div class="outline-text-3" id="text-8-5">
<ul class="org-ul">
<li>Recall: \(y=a_0+a_1x_1+...+a_mx_m\)</li>
<li>What if the fit isn't linear for x?</li>
<li>Answer: transforming the data!</li>
</ul>
</div>
<div id="outline-container-org601fb51" class="outline-4">
<h4 id="org601fb51"><span class="section-number-4">8.5.1.</span> Transforming the data</h4>
<div class="outline-text-4" id="text-8-5-1">
<ul class="org-ul">
<li>Quadratic regression, e.g.
\[
  y = a_0 + a_1 x_1 + a_2 x_1^2
  \]</li>
<li>Trigonometric:
\[
  y = a_0 + a_2 \sin(x^2)
  \]</li>
<li>Response transform:
\[
  \log(y) = a_0 + a_1 x_1 + ... + a_m x_m
  \]</li>
<li>etc.</li>
<li>Box-Cox transforms can be automated</li>
</ul>
</div>
</div>
<div id="outline-container-org9900b16" class="outline-4">
<h4 id="org9900b16"><span class="section-number-4">8.5.2.</span> Interaction terms, e.g. product of inputs</h4>
<div class="outline-text-4" id="text-8-5-2">
<ul class="org-ul">
<li>Child's heights might be influenced by <b>product</b> of father and mother's heights (\(x_1x_2\))</li>
<li>\(y = a_0 + a_1 x_1 + a_2 x_2 + a_3 (x_1 x_2)\)</li>
<li><b>Treat x<sub>1</sub> x<sub>2</sub> as new input, x<sub>3</sub></b></li>
<li>Then find best fit coefficients in the last module</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgbdc4c06" class="outline-3">
<h3 id="orgbdc4c06"><span class="section-number-3">8.6.</span> M6L6: Output</h3>
<div class="outline-text-3" id="text-8-6">
</div>
<div id="outline-container-org466911f" class="outline-4">
<h4 id="org466911f"><span class="section-number-4">8.6.1.</span> p-Values</h4>
<div class="outline-text-4" id="text-8-6-1">
<ul class="org-ul">
<li>Estimates the <b>probability</b> that coefficient is actually 0
<ul class="org-ul">
<li>A hypothesis test</li>
</ul></li>
<li>If p-value is big (&gt;0.05), the coefficient is likely 0, hence remove its attribute from the model</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org374e58d"></a>Other thresholds<br />
<div class="outline-text-5" id="text-8-6-1-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Threshold</th>
<th scope="col" class="org-left">Number of factors included</th>
<th scope="col" class="org-left">Risk</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Higher (&gt;0.05)</td>
<td class="org-left">More factors included</td>
<td class="org-left">Irrelevant factors included</td>
</tr>

<tr>
<td class="org-left">Lower (&lt;0.05)</td>
<td class="org-left">Less factors included</td>
<td class="org-left">Relevant factors left out</td>
</tr>
</tbody>
</table>
</div>
</li>
<li><a id="org401442f"></a>Warnings<br />
<div class="outline-text-5" id="text-8-6-1-2">
<ul class="org-ul">
<li>With lots of data:
<ul class="org-ul">
<li>p-values can get small and seem significant even when attributes aren't related to response</li>
</ul></li>
<li>Even when meaningful, p-values only represent <b>probabilities</b>
<ol class="org-ol">
<li>With 100 attributes having p-value 0.02:</li>
<li>Each of them have 2% chance of <b>not</b> being significant</li>
<li>Hence on average 2/100 are actually irrelevant</li>
</ol></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org4c411ed" class="outline-4">
<h4 id="org4c411ed"><span class="section-number-4">8.6.2.</span> Confidence interval</h4>
<div class="outline-text-4" id="text-8-6-2">
<ul class="org-ul">
<li>Mostly given at 95% level around the coefficient</li>
<li>Range of where the coefficient probably lies</li>
<li>And how close that is to zero</li>
<li>Related to p-value</li>
</ul>
</div>
</div>
<div id="outline-container-org69b848e" class="outline-4">
<h4 id="org69b848e"><span class="section-number-4">8.6.3.</span> T-statistic</h4>
<div class="outline-text-4" id="text-8-6-3">
<ul class="org-ul">
<li>\(\frac{\text{Coefficient}}{\text{Std error}}\)</li>
<li>Related to p-value</li>
</ul>
</div>
</div>
<div id="outline-container-org87111e0" class="outline-4">
<h4 id="org87111e0"><span class="section-number-4">8.6.4.</span> Coefficient itself</h4>
<div class="outline-text-4" id="text-8-6-4">
<ul class="org-ul">
<li>If very small, then when multiplied by attribute, it's likely irrelevant</li>
</ul>
</div>
</div>
<div id="outline-container-org1d60c60" class="outline-4">
<h4 id="org1d60c60"><span class="section-number-4">8.6.5.</span> \(R^2\)</h4>
<div class="outline-text-4" id="text-8-6-5">
<ul class="org-ul">
<li>Estimate of how much variability can be explained by the model</li>
<li>E.g. R<sup>2</sup> = 0.59:
<ul class="org-ul">
<li>0.59 of data variability can be explained by the model</li>
<li>remaining 0.41 is either:
<ul class="org-ul">
<li>random variation</li>
<li>or other factors</li>
</ul></li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org4a8f6d9"></a>Adjusted \(R^2\)<br />
<div class="outline-text-5" id="text-8-6-5-1">
<ul class="org-ul">
<li>Accounts for (penalizes) the number of attributes used</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgfe1b301" class="outline-2">
<h2 id="orgfe1b301"><span class="section-number-2">9.</span> Module 09: Advanced Data Preparation</h2>
<div class="outline-text-2" id="text-9">
</div>
<div id="outline-container-org99006cc" class="outline-3">
<h3 id="org99006cc"><span class="section-number-3">9.1.</span> M9L1: Box-Cox Transformations</h3>
<div class="outline-text-3" id="text-9-1">
<ul class="org-ul">
<li>Models may require data to be normally distributed</li>
<li>What happens when this assumption isn't valid in the data?
<ul class="org-ul">
<li>Results will have bias in this case</li>
<li>Data exhibits heteroskedasicity</li>
<li>i.e., variances are not i.i.d.</li>
</ul></li>
<li>Another example is time series data, where later values have higher variance</li>
<li>Box-Cox is a logarithmic transformation that:
<ol class="org-ol">
<li>Stretches smaller range to increase variability</li>
<li>Shrinks larger range to reduce variability</li>
</ol></li>
<li>E.g. \(t(y)=\frac{y^\lambda-a}{\lambda}\)
<ul class="org-ul">
<li>t(y) can become close to normally distributed</li>
</ul></li>
<li>Need to remember to check for normality (e.g., with Normal Q-Q plot)</li>
</ul>
</div>
</div>
<div id="outline-container-org4e787cc" class="outline-3">
<h3 id="org4e787cc"><span class="section-number-3">9.2.</span> M9L2: Detrending</h3>
<div class="outline-text-3" id="text-9-2">
<ul class="org-ul">
<li>For time series data with trends, i.e. an increase or decrease over time
<ul class="org-ul">
<li>For example: increase in price of gold over time but need to account for inflation over time (value of $ decreases over time)</li>
<li>The trend if not correct can mess up a factor-based analysis</li>
<li>Can detrend:
<ul class="org-ul">
<li>Response</li>
<li>Predictors</li>
<li>Factor-based model (consider whenever using these models)
<ul class="org-ul">
<li>Regression, SVM, etc.</li>
</ul></li>
</ul></li>
</ul></li>
<li>How to detrend:
<ul class="org-ul">
<li>Factor by factor for one-dimensional regression, y=a<sub>0</sub>+a<sub>1x</sub>
<ul class="org-ul">
<li>Simple, works well to remove trend for factor-based analysis</li>
<li>This requires going factor by factor and fitting a linear regression model on it</li>
<li>E.g. for simple linear regression for gold prices:
<ul class="org-ul">
<li>Price = - 45600 + 23.2xYear</li>
<li>Detrend end price = Actual price -(-45600+23.2+year)</li>
<li>This produces a similar graph to the inflation-adjusted rate</li>
<li>Useful when we don’t know the response (as in most cases)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org39a48f7" class="outline-3">
<h3 id="org39a48f7"><span class="section-number-3">9.3.</span> M9L3: Intro to PCA</h3>
<div class="outline-text-3" id="text-9-3">
<ul class="org-ul">
<li>Works on high dimensional and correlated data
<ul class="org-ul">
<li>Which subset of features are important to predict response?</li>
<li>e.g. which stocks can predict how well the market performs the next day?
<ul class="org-ul">
<li>6K securities</li>
<li>Remove days that have major events</li>
</ul></li>
<li>Issues:
<ul class="org-ul">
<li>6K predictors need many many data points to avoid overfitting (need to reduce predictors)
<ul class="org-ul">
<li>However, even with unlimited data, the underlying situation could have changed over time</li>
<li>E.g. TSLA stock is good predictor now but it was only listed 5 years ago</li>
</ul></li>
<li>High correlation between predictors</li>
</ul></li>
</ul></li>
<li>PCA transforms data by:
<ul class="org-ul">
<li>Removing correlations within predictors</li>
<li>Ranking coordinates by importance
<ul class="org-ul">
<li>Most important are first</li>
</ul></li>
<li>By concentrating on first <b>n</b> principal components
<ul class="org-ul">
<li>This reduces random effects and</li>
<li>These PCs have higher signal to noise ratio</li>
</ul></li>
<li>Graphically:
<ul class="org-ul">
<li>rotate plot until it’s orthogonal to the correlation</li>
</ul></li>
<li>If D1 and D2 are the new PCs,
<ul class="org-ul">
<li>D1 (that explains more variance) will be the first factor</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org1563295" class="outline-3">
<h3 id="org1563295"><span class="section-number-3">9.4.</span> M9L4: Using PCA</h3>
<div class="outline-text-3" id="text-9-4">
</div>
<div id="outline-container-org9fc4bbb" class="outline-4">
<h4 id="org9fc4bbb"><span class="section-number-4">9.4.1.</span> Math of PCA</h4>
<div class="outline-text-4" id="text-9-4-1">
<ul class="org-ul">
<li>Definitions
<dl class="org-dl">
<dt>\(X\)</dt><dd>initial matrix of data</dd>
<dt>\(x_{ij}\)</dt><dd>j<sup>th</sup> factor of i<sup>th</sup> data point</dd>
<dt>Scale to:</dt><dd>\(\frac{1}{m}\sum_i x_{ij} = \mu_j = 0\)</dd>
</dl></li>
<li>To find all eigenvectors of X<sup>T</sup> X, where:
<dl class="org-dl">
<dt>V</dt><dd>Matrix of eigenvectors, sorted by eigenvalue</dd>
<dt>V</dt><dd>[V<sub>1</sub> V<sub>2</sub> &#x2026; ]</dd>
<dt>V<sub>j</sub></dt><dd>j<sup>th</sup> eigenvector of X<sup>T</sup> X</dd>
</dl></li>
<li>PCA is a linear combination:
<ul class="org-ul">
<li>1st component is XV<sub>1</sub>, then 2nd is XV<sub>2</sub>, &#x2026;</li>
<li>k<sup>th</sup> new factor for i<sup>th</sup> data point:
\[
    t_{ik} = \sum^m_{ik} x_{ij}v_{jk}
    \]</li>
<li>t<sub>ik</sub> is the factor after PCA</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org84cae94" class="outline-4">
<h4 id="org84cae94"><span class="section-number-4">9.4.2.</span> PCA as linear combination</h4>
<div class="outline-text-4" id="text-9-4-2">
<ul class="org-ul">
<li>It <b><b>removes</b></b> correlation between factors</li>
<li>In order to have fewer variables/factors in the model:
<ul class="org-ul">
<li>Choose to include only first <i>n</i> principal components</li>
</ul></li>
<li>PCA can also deal with non-linear functions, using kernels. This is similar to SVM modeling</li>
</ul>
</div>
</div>
<div id="outline-container-orgd016d20" class="outline-4">
<h4 id="orgd016d20"><span class="section-number-4">9.4.3.</span> PCA for regression</h4>
<div class="outline-text-4" id="text-9-4-3">
<ul class="org-ul">
<li>How to interpret the new model in terms of original factors?</li>
<li>Example: PCA finds \(L\) new factors (each \(t_{ik}\)), and regression coefficients b<sub>0</sub>, b<sub>1</sub>, &#x2026; b<sub>L</sub>:
\[
  y_i = b_0 + \sum^L_{k=1}b_k t_{ik} \\
  = b_0 + \sum^L_{k=1}b_k [\sum^m_{j=1} x_{ij} v{jk}] \\
  = b_0 + \sum^m_{j=1}x_{ij} [\sum^L_{k=1}b_kv_{jk}]
  \\
  = b_0 + \sum^m_{j=1}x_{ij}[a_j]
  \]</li>
<li>Each t vector does not have nice intuitive explanations as they are linear combinations of original factors.</li>
<li>Hence just plug in the transformation for each t factor:
\[
  a_j = \sum^L_{k=1}b_kv_{jk}
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-org458b57b" class="outline-4">
<h4 id="org458b57b"><span class="section-number-4">9.4.4.</span> Summary of PCA</h4>
<div class="outline-text-4" id="text-9-4-4">
<ul class="org-ul">
<li>Use PCA for high-dimensional and correlated data</li>
<li>PCA removes these correlations and ranks coordinates by importance (i.e., variability explained)
<ul class="org-ul">
<li>PC1 &gt; PC2 &gt; PC3, etc</li>
</ul></li>
<li>PCA can be transformed back to the original factor space to get intuitive explanations</li>
<li>PCA allows use of fewer variables
<ul class="org-ul">
<li>Pick the ones that explain the most variability</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org679f029" class="outline-3">
<h3 id="org679f029"><span class="section-number-3">9.5.</span> M9L5: Eigenvalues and Eigenvectors</h3>
<div class="outline-text-3" id="text-9-5">
</div>
<div id="outline-container-org8840b7f" class="outline-4">
<h4 id="org8840b7f"><span class="section-number-4">9.5.1.</span> Initial example</h4>
<div class="outline-text-4" id="text-9-5-1">
<ul class="org-ul">
<li>Definitions:
<dl class="org-dl">
<dt>\(A\)</dt><dd>a square matrix</dd>
<dt>\(v\)</dt><dd>a vector such that \(Av=\lambda v\)</dd>
<dt>\(V\)</dt><dd>eigenvector of \(A\)</dd>
<dt>\(\lambda\)</dt><dd>eigenvalue of \(A\), i.e. det(A-&lambda; I) = 0. Every &lambda; is eigenvalue of A</dd>
</dl></li>
<li>Given &lambda;, solve \(Av=\lambda v\) to find the eigenvector \(v\)</li>
</ul>
</div>
</div>
<div id="outline-container-org9c3bbf6" class="outline-4">
<h4 id="org9c3bbf6"><span class="section-number-4">9.5.2.</span> Important: know how eigenvalues and eigenvectors are important to PCA</h4>
<div class="outline-text-4" id="text-9-5-2">
<ul class="org-ul">
<li>With a scaled matrix \(X\) of data, and x<sub>ij</sub> is factor value for i<sup>th</sup> data point after scaling,</li>
<li>Find eigenvectors v<sub>1</sub> &#x2026; v<sub>n</sub> of \((X^TX)\)</li>
<li>Then, find the principal components:
<ol class="org-ol">
<li>Multiply \(X\) by the eigenvectors</li>
<li>\(Xv_1, Xv_2, ..., Xv_n\) are the principal components
<ul class="org-ul">
<li>i.e. the transformed set of orthogonal coordinate directions</li>
</ul></li>
</ol></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org5112b23" class="outline-3">
<h3 id="org5112b23"><span class="section-number-3">9.6.</span> M9L6: PCA: The good and the bad</h3>
<div class="outline-text-3" id="text-9-6">
<ul class="org-ul">
<li>Summary
<img src="./img/m9l6-pca-summary.png" alt="m9l6-pca-summary.png" /></li>
<li>D<sub>1</sub> has more explanatory power (vaariation)</li>
<li>But it may not be the most helpful for explanatory/predictive modeling</li>
<li><b>PCA depends only on the independent variables</b>, not the response variable
<ul class="org-ul">
<li>It's possible response is affected by variables with low variability instead of those with high variability!</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org4557fdd" class="outline-4">
<h4 id="org4557fdd"><span class="section-number-4">9.6.1.</span> Example where PCA is good</h4>
<div class="outline-text-4" id="text-9-6-1">
<ul class="org-ul">
<li>Assume PCA is used for classification</li>
<li>PC1 has most of the variance and PC1 can classify red and blue points
<img src="./img/m9l6-pca-good.png" alt="m9l6-pca-good.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-org4a396e6" class="outline-4">
<h4 id="org4a396e6"><span class="section-number-4">9.6.2.</span> Example where PCA is bad</h4>
<div class="outline-text-4" id="text-9-6-2">
<ul class="org-ul">
<li>PC1, though it has more variance, cannot classify the red and blue points</li>
<li>PC2 has less variance but it can classify the points exactly
<img src="./img/m9l6-pca-bad.png" alt="m9l6-pca-bad.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-org2eac72f" class="outline-4">
<h4 id="org2eac72f"><span class="section-number-4">9.6.3.</span> Summary</h4>
<div class="outline-text-4" id="text-9-6-3">
<ul class="org-ul">
<li>We still use PCA (or try to!) as dimensions have higher variation specifically because they contain more information</li>
<li>However, this is not always true</li>
<li>PCA is a helpful approach to try</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orged7abef" class="outline-2">
<h2 id="orged7abef"><span class="section-number-2">10.</span> Module 10: Advanced Regression</h2>
<div class="outline-text-2" id="text-10">
<blockquote>
<p>
Midterm 1 covers up to Module 10
</p>
</blockquote>
</div>
<div id="outline-container-orgbbacef2" class="outline-3">
<h3 id="orgbbacef2"><span class="section-number-3">10.1.</span> M10L01: Introduction to CART</h3>
<div class="outline-text-3" id="text-10-1">
<blockquote>
<p>
Classification and Regression Trees
</p>
</blockquote>
</div>
<div id="outline-container-org9dd7787" class="outline-4">
<h4 id="org9dd7787"><span class="section-number-4">10.1.1.</span> Trees in regression</h4>
<div class="outline-text-4" id="text-10-1-1">
</div>
<ol class="org-ol">
<li><a id="orge352852"></a>Uses<br />
<div class="outline-text-5" id="text-10-1-1-1">
<ol class="org-ol">
<li>Classification</li>
<li>Decision tree</li>
</ol>
</div>
</li>
</ol>
</div>
<div id="outline-container-org7af396e" class="outline-4">
<h4 id="org7af396e"><span class="section-number-4">10.1.2.</span> Recall</h4>
<div class="outline-text-4" id="text-10-1-2">
<p>
In simple linear regression, e.g.:
impact of marketing email on recipient spending.
</p>
<ul class="org-ul">
<li>Predictors:
<ol class="org-ol">
<li>Demographics e.g. age, sex, number of children, income</li>
<li>Purchasing factors e.g. amount spent per month</li>
<li>Binary factor e.g. was email received and opened</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org69aa0d2" class="outline-4">
<h4 id="org69aa0d2"><span class="section-number-4">10.1.3.</span> What if responses can be differentiated by a factor?</h4>
<div class="outline-text-4" id="text-10-1-3">
<p>
(The above example of simple linear regression assumes every data point behaves the same way)
If each group instead have their own characteristics and responses, two regressions can thus be fitted, e.g.:
</p>
<ol class="org-ol">
<li>25 years or younger
\(\text{Money spent}=50+13.75\times\text{Number of Children}+0\times\text{Income over 30,000}+\text{...}\)</li>
<li>older than 25
\(\text{Money spent}=32+28.13\times\text{Number of children}+7.13\times\text{Income over 30,000}+\text{...}\)</li>
</ol>
</div>
</div>
<div id="outline-container-org6df34a6" class="outline-4">
<h4 id="org6df34a6"><span class="section-number-4">10.1.4.</span> Further splits are possible</h4>
<div class="outline-text-4" id="text-10-1-4">
<ul class="org-ul">
<li>Each branch is further split</li>
<li>Each ending is a <i>"leaf"</i>
<ul class="org-ul">
<li><i>Descriptively</i>: Each leaf's coefficients explains behaviour in that leaf</li>
<li><i>Predictively</i>: Each leaf's regression model can be used to predict a new point in that branch.</li>
</ul></li>
<li>Each branch can run \(R^2\) and those with low \(R^2\) can be investigated/improved.</li>
</ul>
</div>
</div>
<div id="outline-container-org5f6f211" class="outline-4">
<h4 id="org5f6f211"><span class="section-number-4">10.1.5.</span> Disadvantages</h4>
<div class="outline-text-4" id="text-10-1-5">
<ul class="org-ul">
<li>Lots of computations and regressions</li>
<li>Fewer and fewer data points in each node</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgcb51025"></a>Hence:<br />
<div class="outline-text-5" id="text-10-1-5-1">
<p>
Simplify the regression by just using the constant term input
</p>
<ul class="org-ul">
<li>e.g. \(y=a_0\) instead of \(y=a_0+a_1x+\text{...}\)</li>
<li>This is the mean response over all data points in the node, i.e.
\[
  a_0 = \frac{\sum_i\text{in node }y_i}{\text{count of data points in node}} \\
  = \text{avg response in node}
  \]</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org327b6cc" class="outline-4">
<h4 id="org327b6cc"><span class="section-number-4">10.1.6.</span> Other places to use trees</h4>
<div class="outline-text-4" id="text-10-1-6">
<ul class="org-ul">
<li>The branching concept can be applied to:
<ul class="org-ul">
<li>Logistic regression model
<ul class="org-ul">
<li>fraction of node's data points with True response</li>
</ul></li>
<li>Classification model
<ul class="org-ul">
<li>Most common classification among node's data points</li>
</ul></li>
<li>Decision model
<ul class="org-ul">
<li>Each leaf is the decision "do I send a marketing email?"</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga658fb9" class="outline-4">
<h4 id="orga658fb9"><span class="section-number-4">10.1.7.</span> Common questions</h4>
<div class="outline-text-4" id="text-10-1-7">
<ol class="org-ol">
<li>How to choose the branches?</li>
<li>When to stop branching?</li>
<li>Why is this called a regression tree?</li>
</ol>
</div>
</div>
<div id="outline-container-org8d1bcc2" class="outline-4">
<h4 id="org8d1bcc2"><span class="section-number-4">10.1.8.</span> Etymology of "tree"</h4>
<div class="outline-text-4" id="text-10-1-8">

<div id="org32e28fe" class="figure">
<p><img src="./img/m1001-tree.png" alt="m1001-tree.png" />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org9889ca2" class="outline-3">
<h3 id="org9889ca2"><span class="section-number-3">10.2.</span> M10L02: Branching</h3>
<div class="outline-text-3" id="text-10-2">
</div>
<div id="outline-container-org81e4018" class="outline-4">
<h4 id="org81e4018"><span class="section-number-4">10.2.1.</span> Main questions</h4>
<div class="outline-text-4" id="text-10-2-1">
<ol class="org-ol">
<li>Which factors are used to decide on branching?</li>
<li>How to split data?</li>
</ol>
<p>
In practice, no good algorithm to help decide. Instead, branch on 1 factor at a time.
</p>
</div>
</div>
<div id="outline-container-org8685c85" class="outline-4">
<h4 id="org8685c85"><span class="section-number-4">10.2.2.</span> Branching methods</h4>
<div class="outline-text-4" id="text-10-2-2">
<ol class="org-ol">
<li>Start with half of data and run a regression</li>
<li>Split the data into 2 halves based on some factor we can branch from (e.g. age &gt;25)</li>
<li>For each leaf:
<ol class="org-ol">
<li>Calculate variance of response amongst all data points in each leaf</li>
<li>Test splitting on each factor to see how much lower total variance of two branches would be vs. the least variance.</li>
<li>Choose the factor with lowest total variance.</li>
<li>Make split iif:
<ol class="org-ol">
<li>Enough data points in each branch</li>
<li>Decrease is lower than threshold &delta;</li>
</ol></li>
<li>Otherwise, don't split the leaf</li>
</ol></li>
<li>Go backwards to <b>prune</b> using the 2nd half of data not used in initial branching. For each pair of leaves created in each branch:
<ol class="org-ol">
<li>Use the other half of data in each branch to see if estimation error was improved by branching
<ol class="org-ol">
<li>If error increases/no change, then remove branch</li>
<li>Else, keep the branch</li>
</ol></li>
</ol></li>
</ol>
</div>
</div>
<div id="outline-container-org4de7c31" class="outline-4">
<h4 id="org4de7c31"><span class="section-number-4">10.2.3.</span> Generic branching concept</h4>
<div class="outline-text-4" id="text-10-2-3">
<blockquote>
<p>
Overfitting can be costly; make sure the benefit of each branch is greater than its cost
</p>
</blockquote>
<p>
Key ideas
</p>
<ol class="org-ol">
<li>Use a metric related to model quality</li>
<li>Find 'best factor' to branch with</li>
<li><b>Check</b>: did this improve the model?
<ol class="org-ol">
<li>If not, prune the branch back.</li>
</ol></li>
</ol>
<p>
Rejecting potential branches
</p>
<ol class="org-ol">
<li>Low improvement benefit</li>
<li>Some side of branch has too few data points after branching
<ol class="org-ol">
<li>Each leaf should contain &ge;5% of original data (we don't want to over-fit the model)</li>
</ol></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org29b6e63" class="outline-3">
<h3 id="org29b6e63"><span class="section-number-3">10.3.</span> M10L03: Random Forests</h3>
<div class="outline-text-3" id="text-10-3">
</div>
<div id="outline-container-orgec1024b" class="outline-4">
<h4 id="orgec1024b"><span class="section-number-4">10.3.1.</span> Intro summary</h4>
<div class="outline-text-4" id="text-10-3-1">
<ul class="org-ul">
<li>Introduce randomness</li>
<li>Generate lots of random trees
<ul class="org-ul">
<li>Each has its strengths and weaknesses</li>
</ul></li>
<li>Key concept: average better than single tree</li>
</ul>
</div>
</div>
<div id="outline-container-org2634561" class="outline-4">
<h4 id="org2634561"><span class="section-number-4">10.3.2.</span> Introducing randomness</h4>
<div class="outline-text-4" id="text-10-3-2">
<blockquote>
<p>
via bootstrapping
</p>
</blockquote>
<ul class="org-ul">
<li>With \(n\) number of original data points, we make trees each with \(n\) points.
<ul class="org-ul">
<li>However, some points can be picked multiple times while others get picked 0 times.</li>
</ul></li>
<li>When branching:
<ul class="org-ul">
<li>Not as before (before: we choose 1 factor at a time)</li>
<li>In RF: pick a small number of factors \(X\)</li>
<li>Choose the best factor in that set to branch on</li>
<li>Common number of factors used: \(1+\log(n)\)</li>
</ul></li>
<li>No need to prune tree</li>
</ul>
</div>
</div>
<div id="outline-container-org60fd83f" class="outline-4">
<h4 id="org60fd83f"><span class="section-number-4">10.3.3.</span> Note</h4>
<div class="outline-text-4" id="text-10-3-3">
<ul class="org-ul">
<li>Each tree has slightly different data</li>
<li>Will end up with lots of different trees (500-1000 are common)</li>
<li>Each tree gives a slightly different regression model</li>
<li>Which one to use?
<ul class="org-ul">
<li>Regression trees: use the <b>average</b> predicted response</li>
<li>Classification trees: use the <b>most common</b> predicted response</li>
</ul></li>
<li>Benefits of RF:
<ul class="org-ul">
<li>Better overall estimate</li>
<li>Average between tree can somewhat address over-fitting</li>
</ul></li>
<li>Disadvantages of RF:
<ul class="org-ul">
<li>Harder to explain and interpret results</li>
<li>Cannot explain how variables interact, or how some sequence of branches is helpful/meaningful (which can be found in single tree)</li>
<li>Can't give specific model from the data</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgeef2384" class="outline-4">
<h4 id="orgeef2384"><span class="section-number-4">10.3.4.</span> Summary of RF</h4>
<div class="outline-text-4" id="text-10-3-4">
<ul class="org-ul">
<li>Method: introduce randomness into the trees</li>
<li>Good as 'black box' predictor</li>
<li>Cannot give much detailed insight</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org03bb124" class="outline-3">
<h3 id="org03bb124"><span class="section-number-3">10.4.</span> M10L04: Explainability and Interpretability</h3>
<div class="outline-text-3" id="text-10-4">
<blockquote>
<p>
How easy or not it is to understand how models create their output?
</p>
</blockquote>
</div>
<div id="outline-container-org08703d8" class="outline-4">
<h4 id="org08703d8"><span class="section-number-4">10.4.1.</span> Example: linear regression</h4>
<div class="outline-text-4" id="text-10-4-1">
<p>
\[y=a_0 + \sum^n_{j=1}a_j x_{ij}\]
To answer "how is the value of \(y\) affected by different values of the predictor?" with:
</p>
<dl class="org-dl">
<dt>y</dt><dd>Number of tickets sold this year</dd>
<dt>x<sub>1</sub></dt><dd>Salary of top 4 stars</dd>
<dt>x<sub>2</sub></dt><dd>Number of movies with similar plots this year</dd>
<dt>x<sub>3</sub></dt><dd>Rated <b>R</b> or more restrictive (1=yes)</dd>
<dt>x<sub>4</sub></dt><dd>Number of days left in the year</dd>
<dt>a<sub>0</sub></dt><dd>1,000,000</dd>
<dt>a<sub>1</sub></dt><dd>0.25</dd>
<dt>a<sub>2</sub></dt><dd>-1,000,000</dd>
<dt>a<sub>3</sub></dt><dd>-1,000,000</dd>
<dt>a<sub>4</sub></dt><dd>20,000</dd>
</dl>
<p>
The interpretation is thus:
</p>
<ul class="org-ul">
<li>Baseline is 1,000,000 tickets (a<sub>0</sub>)</li>
<li>Salary of star, each dollar increases number of tickets sold by $0.25 (a<sub>1</sub>)</li>
<li>Similar movie: each similar movie decreases number of tickets sold by 1,000,000 (a<sub>2</sub>)</li>
<li>Restrictive rating: decreases number of tickets sold by 1,000,000</li>
<li>Days left in year: each day increases number of tickets sold by 20,000</li>
</ul>
</div>
</div>
<div id="outline-container-org41f9cf1" class="outline-4">
<h4 id="org41f9cf1"><span class="section-number-4">10.4.2.</span> Example: regression tree</h4>
<div class="outline-text-4" id="text-10-4-2">
<ul class="org-ul">
<li>With the same values above, it becomes a long if<sub>else</sub> statement</li>
<li>Can describe detail of tree but it's not helpful for understanding</li>
</ul>
</div>
</div>
<div id="outline-container-org2300b3f" class="outline-4">
<h4 id="org2300b3f"><span class="section-number-4">10.4.3.</span> Example: random forests</h4>
<div class="outline-text-4" id="text-10-4-3">
<ul class="org-ul">
<li>If one tree is hard to explain, 500 are even worse</li>
<li>Although random forests give relative branching importance of each variable,
<ul class="org-ul">
<li>They do not say <b>how</b></li>
<li>Hence RF are not precise for interpretability or explainability</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga1855b7" class="outline-4">
<h4 id="orga1855b7"><span class="section-number-4">10.4.4.</span> Comparisons</h4>
<div class="outline-text-4" id="text-10-4-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Model</th>
<th scope="col" class="org-left">Explainability</th>
<th scope="col" class="org-left">Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Linear regression</td>
<td class="org-left">Higher</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">Regression tree</td>
<td class="org-left">Medium</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">Random forest</td>
<td class="org-left">Lower</td>
<td class="org-left">Sometimes higher</td>
</tr>
</tbody>
</table>

<p>
More explainable models:
</p>
<ul class="org-ul">
<li>help us understand "why"</li>
<li>help decision makers to choose between models</li>
<li>can be a legal requirement, e.g. in finance</li>
</ul>
<p>
However, less explainable models can give better results at times as they can identify and model more complex patterns
</p>
</div>
</div>
<div id="outline-container-org771fbab" class="outline-4">
<h4 id="org771fbab"><span class="section-number-4">10.4.5.</span> Tradeoff</h4>
<div class="outline-text-4" id="text-10-4-5">
<p>
Pay attention to tradeoffs when proposing a model:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Explainability</th>
<th scope="col" class="org-left">Value</th>
<th scope="col" class="org-left">Adoption</th>
<th scope="col" class="org-left">Legal requirement</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Less</td>
<td class="org-left">Potentially more</td>
<td class="org-left">?</td>
<td class="org-left">?</td>
</tr>

<tr>
<td class="org-left">More</td>
<td class="org-left">?</td>
<td class="org-left">More likely</td>
<td class="org-left">Might be required</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-orgfed7a51" class="outline-3">
<h3 id="orgfed7a51"><span class="section-number-3">10.5.</span> M10L05: Confusion Matrices</h3>
<div class="outline-text-3" id="text-10-5">
<blockquote>
<p>
Answers: How to measure how well a classification-type model works?
</p>
</blockquote>
<p>
This is a confusion matrix:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Model</th>
<th scope="col" class="org-left">Classification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Yes</td>
<td class="org-left">No</td>
</tr>

<tr>
<td class="org-left">True</td>
<td class="org-left">Yes</td>
<td class="org-left">Correct</td>
<td class="org-left">Wrong</td>
</tr>

<tr>
<td class="org-left">Classification</td>
<td class="org-left">No</td>
<td class="org-left">Wrong</td>
<td class="org-left">Correct</td>
</tr>
</tbody>
</table>

<p>
It shows how much the model is confusing the two categories.
</p>
</div>
<div id="outline-container-org9199456" class="outline-4">
<h4 id="org9199456"><span class="section-number-4">10.5.1.</span> Details</h4>
<div class="outline-text-4" id="text-10-5-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Model</th>
<th scope="col" class="org-left">Classification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Yes</td>
<td class="org-left">No</td>
</tr>

<tr>
<td class="org-left">True</td>
<td class="org-left">Yes</td>
<td class="org-left">True Pos</td>
<td class="org-left">False Neg</td>
</tr>

<tr>
<td class="org-left">Classification</td>
<td class="org-left">No</td>
<td class="org-left">False Pos</td>
<td class="org-left">True Neg</td>
</tr>
</tbody>
</table>
<ul class="org-ul">
<li>Positive: model <b>says</b> it's in the category</li>
<li>Negative: model <b>says</b> it's NOT in the category</li>
<li>True: model got it right</li>
<li>False: model got it wrong</li>
</ul>
</div>
</div>
<div id="outline-container-orgc969d67" class="outline-4">
<h4 id="orgc969d67"><span class="section-number-4">10.5.2.</span> Definitions</h4>
<div class="outline-text-4" id="text-10-5-2">
<dl class="org-dl">
<dt>Sensitivity</dt><dd>TP/(TP+FN), i.e. TP / All actual positives</dd>
<dt>Specificity</dt><dd>TN/(TN+FP), i.e. TN/ All actual negatives</dd>
</dl>
<p>
Others: don't memorize, just refer.
</p>
</div>
</div>
</div>
<div id="outline-container-org8912c1e" class="outline-3">
<h3 id="org8912c1e"><span class="section-number-3">10.6.</span> M10L06: Situationally-Driven Comparisons</h3>
<div class="outline-text-3" id="text-10-6">
</div>
<div id="outline-container-org7689e48" class="outline-4">
<h4 id="org7689e48"><span class="section-number-4">10.6.1.</span> Example: from spam detection</h4>
<div class="outline-text-4" id="text-10-6-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Model</th>
<th scope="col" class="org-right">Classification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-right">Yes</td>
<td class="org-right">No</td>
</tr>

<tr>
<td class="org-left">True</td>
<td class="org-left">Yes</td>
<td class="org-right">490</td>
<td class="org-right">10</td>
</tr>

<tr>
<td class="org-left">Classification</td>
<td class="org-left">No</td>
<td class="org-right">100</td>
<td class="org-right">400</td>
</tr>
</tbody>
</table>
<ul class="org-ul">
<li>Cost: $0 for correct classification
<ul class="org-ul">
<li>$0.04 to read spam</li>
<li>$1 to miss a real message</li>
</ul></li>
<li>If 50% of email is spam, the total cost is &sum;:
<ol class="org-ol">
<li>490 &times; $0 + 440 &times; $0 = 0</li>
<li>10 &times; $1 = $10</li>
<li>100 &times; $0.04 = $4, i.e.</li>
</ol></li>
</ul>
<p>
$0.014 per email
</p>
<ul class="org-ul">
<li>If 40% of email is spam: total cost is &sum;:
<ol class="org-ol">
<li>490 &times; 0.6/0.5 &times; 0 + 400 &times; 0.4/0.5 \ times 0 = $0</li>
<li>10 &times; 0.6/0.5 &times; $1 = $12</li>
<li>100 &times; 0.4/0.5 &times; $0.04 = $3.2</li>
</ol></li>
</ul>
<p>
$0.0152 per email
</p>
</div>
</div>
<div id="outline-container-org80bed72" class="outline-4">
<h4 id="org80bed72"><span class="section-number-4">10.6.2.</span> Evaluating quality / changing metrics</h4>
<div class="outline-text-4" id="text-10-6-2">
<ul class="org-ul">
<li>E.g. make model stricter that can reject more spam</li>
<li>This can make model reject more spam, but also cause more false negatives (which are much more costly)
Hence overall cost is higher at $52 ($0.104 per email)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf11a26d" class="outline-3">
<h3 id="orgf11a26d"><span class="section-number-3">10.7.</span> L10L07: Advanced Topics in Regression</h3>
<div class="outline-text-3" id="text-10-7">
</div>
<div id="outline-container-org240b618" class="outline-4">
<h4 id="org240b618"><span class="section-number-4">10.7.1.</span> Poisson regression</h4>
<div class="outline-text-4" id="text-10-7-1">
<p>
Use when response follows a Poisson distribution i.e.
\[
f(z) = \frac{\lambda^Z e^{-z}}{z!}
\]
Examples:
</p>
<ul class="org-ul">
<li>Count of arrivals at airport security</li>
<li>Arrival rate might be function of <b>time</b></li>
<li>Hence, estimate &lambda;(x)</li>
</ul>
</div>
</div>
<div id="outline-container-org3cfd307" class="outline-4">
<h4 id="org3cfd307"><span class="section-number-4">10.7.2.</span> Regression splines</h4>
<div class="outline-text-4" id="text-10-7-2">
<p>
Spline: function of polynomials that connect to each other
<img src="./img/10-07-spline.png" alt="10-07-spline.png" />
</p>
<ul class="org-ul">
<li>Different functions are fitted to different parts of the data set</li>
<li>Hence, smoothens connections between parts</li>
<li>"Order-k" regression spline means that polynomials are all order k.</li>
<li>Example: multi-adaptive regression splines (MARS)
<ul class="org-ul">
<li>Called "Earth" in many stats libraries</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org14dd8ca" class="outline-4">
<h4 id="org14dd8ca"><span class="section-number-4">10.7.3.</span> Bayesian regression</h4>
<div class="outline-text-4" id="text-10-7-3">
<ul class="org-ul">
<li>Start with:
<ul class="org-ul">
<li>Data AND</li>
<li>Estimate of how regression coefficients and random error is distributed</li>
</ul></li>
<li>Example: to predict how tall a child will be as an adult, based on:
<ul class="org-ul">
<li>Data: heights of child's parents</li>
<li>Expert opinion: starting distribution, coefficients of father's and mother's heights are normally distributed between 0.8 and 1.2</li>
</ul></li>
<li>Then use Baye's theorem to update estimate</li>
<li><b>Helpful when data is lacking</b>:
<ul class="org-ul">
<li>Combines expert opinion with the data we do have.</li>
<li>Can replace expert opinion with a broad prior distribution (e.g., uniform over a large interval) as seed data</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org03fe315" class="outline-4">
<h4 id="org03fe315"><span class="section-number-4">10.7.4.</span> k-Nearest Neighbour Regression</h4>
<div class="outline-text-4" id="text-10-7-4">
<ul class="org-ul">
<li>Similar to KNN for classification</li>
<li>Hence, <b>KNN can be used for both regression and classification</b></li>
<li>Implementation:
<ul class="org-ul">
<li>No estimate of prediction function (function-less)</li>
<li>Plot all data</li>
<li>To predict response for a new point:
<ul class="org-ul">
<li>Average response of \(k\) closest data points</li>
</ul></li>
<li>Can be made fancier, e.g.:
<ul class="org-ul">
<li>Weight each dimension of distance</li>
<li>Removing dimensions that are not predictive</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org13c8e83" class="outline-2">
<h2 id="org13c8e83"><span class="section-number-2">11.</span> Module 11: Variable Selection</h2>
<div class="outline-text-2" id="text-11">
<ul class="org-ul">
<li>Factor based models:
<ol class="org-ol">
<li>Classification</li>
<li>Clustering</li>
<li>Regression</li>
</ol></li>
</ul>
</div>
<div id="outline-container-org7f95ce0" class="outline-3">
<h3 id="org7f95ce0"><span class="section-number-3">11.1.</span> M11L1: Introduction</h3>
<div class="outline-text-3" id="text-11-1">
</div>
<div id="outline-container-org2641a1f" class="outline-4">
<h4 id="org2641a1f"><span class="section-number-4">11.1.1.</span> Why bother limiting factors?</h4>
<div class="outline-text-4" id="text-11-1-1">
<ol class="org-ol">
<li>Prevents overfitting
<ul class="org-ul">
<li>When number of factors close to number of data points
<ul class="org-ul">
<li>Cause bad estimates</li>
</ul></li>
<li>Model fits too closely to the random effects</li>
</ul></li>
<li>Simplicity
<ul class="org-ul">
<li>Simple models better than complex models
<ul class="org-ul">
<li>Less data required</li>
<li>Less chance of insignificant factors</li>
<li>Easier to interpret</li>
</ul></li>
<li>Factors can be illegal to use
<ul class="org-ul">
<li>race, sex, religion, marital status cannot be used to make credit decisions</li>
<li>factors correlated to these also cannot be used</li>
</ul></li>
</ul></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgb81d08f" class="outline-3">
<h3 id="orgb81d08f"><span class="section-number-3">11.2.</span> M11L2: Models for variable selection</h3>
<div class="outline-text-3" id="text-11-2">
</div>
<div id="outline-container-org111e993" class="outline-4">
<h4 id="org111e993"><span class="section-number-4">11.2.1.</span> Forward selection</h4>
<div class="outline-text-4" id="text-11-2-1">
<ul class="org-ul">
<li>Start with no factors, then add
<img src="file:///Users/whkoh/git-repos/omsa-notes/isye_6501/img/m11-fwd-sel.png" alt="m11-fwd-sel.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-orgdf06d75" class="outline-4">
<h4 id="orgdf06d75"><span class="section-number-4">11.2.2.</span> Backward elimination</h4>
<div class="outline-text-4" id="text-11-2-2">
<ul class="org-ul">
<li>Start with all factors, then eliminate
<img src="file:///Users/whkoh/git-repos/omsa-notes/isye_6501/img/m11-backw-elim.png" alt="m11-backw-elim.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-orgad6bf40" class="outline-4">
<h4 id="orgad6bf40"><span class="section-number-4">11.2.3.</span> Stepwise regression</h4>
<div class="outline-text-4" id="text-11-2-3">
<ul class="org-ul">
<li>Combines forward selection and backward elimination
<img src="file:///Users/whkoh/git-repos/omsa-notes/isye_6501/img/m11-stepwise.png" alt="m11-stepwise.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-orgd8fb68b" class="outline-4">
<h4 id="orgd8fb68b"><span class="section-number-4">11.2.4.</span> Types of approaches</h4>
<div class="outline-text-4" id="text-11-2-4">
<ul class="org-ul">
<li>Greedy
<ul class="org-ul">
<li>Decisions are made stp by step</li>
<li>Known as <i>Greedy Algorithm</i></li>
<li>At each step, take one thing that looks best
<ul class="org-ul">
<li>Doesn't consider future options</li>
</ul></li>
</ul></li>
<li>Global (see below)</li>
</ul>
</div>
</div>
<div id="outline-container-orgefea95d" class="outline-4">
<h4 id="orgefea95d"><span class="section-number-4">11.2.5.</span> Lasso approach</h4>
<div class="outline-text-4" id="text-11-2-5">
<ul class="org-ul">
<li>Add constraint to standard regression equation
<ul class="org-ul">
<li>Still min SSE
\[
    \sum^m_{i=1}(y_i - (a_0 + \sum^n_{j=1}a_jx_{ij}))^2
    \]
 <b>and</b> keep:</li>
<li>Sum of coefficients less than threshold T \(\sum_{j=1}^n|a_j| \leq \tau_{\text{Lasso}}\)</li>
</ul></li>
<li>Gives regression a budget to use on coefficients
<ul class="org-ul">
<li>Most important coefficients kept</li>
<li>Others given 0</li>
</ul></li>
<li>Important to scale data and pick T correctly</li>
<li><b>Scaling</b> is important (e.g. age in years will be much bigger than age in days)</li>
<li>Picking \(T\) depends on:
<ol class="org-ol">
<li>Number of variables</li>
<li>Quality of model</li>
<li>Best tradeoff is to use LASSO method with different T values and assess</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-orgc902ac2" class="outline-4">
<h4 id="orgc902ac2"><span class="section-number-4">11.2.6.</span> Elastic net</h4>
<div class="outline-text-4" id="text-11-2-6">
<ul class="org-ul">
<li>Constraint combination of abs. values of coefficients and their squares
\(\bar{\lambda}\sum_{j=1}^n|a_j| +(1-\bar{\lambda})\sum_{j=1}^na_j^2 \leq T\)</li>
<li>Important to scale data and pick T, \(\bar{\lambda}\) correctly</li>
</ul>
</div>
</div>
<div id="outline-container-org27fa333" class="outline-4">
<h4 id="org27fa333"><span class="section-number-4">11.2.7.</span> Ridge regression</h4>
<div class="outline-text-4" id="text-11-2-7">
<ul class="org-ul">
<li>Take out absolute value term from elastic net</li>
<li>Unlike Lasso, Ridge regression <b><b>does not</b></b> do variable selection</li>
<li>It can lead to better predictive models</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org745f438" class="outline-3">
<h3 id="org745f438"><span class="section-number-3">11.3.</span> M11L3: Lasso vs Ridge regression</h3>
<div class="outline-text-3" id="text-11-3">
<ul class="org-ul">
<li>Ridge regression is very similar to lasso
<ul class="org-ul">
<li>Lasso does variable selection, ridge does not</li>
</ul></li>
<li>The restriction for ridge regression is:
\(\sum_{j=1}^n(a_j)^2 \leq \tau_{\text{Ridge}}\)</li>
</ul>
</div>
<div id="outline-container-org5b6d930" class="outline-4">
<h4 id="org5b6d930"><span class="section-number-4">11.3.1.</span> The key difference</h4>
<div class="outline-text-4" id="text-11-3-1">
<ul class="org-ul">
<li>The constraint or restriction is different</li>
<li>Graphically on which points are <b>allowed</b>:
<img src="./img/m11-lasso-ridge.png" alt="m11-lasso-ridge.png" />
<ul class="org-ul">
<li>Lasso is a diamond</li>
<li>Ridge is a circle</li>
</ul></li>
<li>Which points are <b>the best</b>?
<ul class="org-ul">
<li>The total error area is a circle</li>
<li>Lasso regression shape is diamond so it is more likely to hit a point where one of the variables (of a<sub>1</sub> and a<sub>2</sub>) is zero, hence selecting the <b>other</b> variable</li>
<li>Ridge regression shape is a circle, hence it is extremely unlikely that both circles will coincide to remove one of the variables (a<sub>1</sub> or a<sub>2</sub>)</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org3046b91" class="outline-3">
<h3 id="org3046b91"><span class="section-number-3">11.4.</span> M11L4: Bias-Variance tradeoff</h3>
<div class="outline-text-3" id="text-11-4">
</div>
<div id="outline-container-orgde6f0e2" class="outline-4">
<h4 id="orgde6f0e2"><span class="section-number-4">11.4.1.</span> Fit and real vs random patterns</h4>
<div class="outline-text-4" id="text-11-4-1">
<ul class="org-ul">
<li>There is a natural tradeoff between more and less fit:
<dl class="org-dl">
<dt>Less fit</dt><dd>bad (less fit to real patterns); good (less fit to random patterns); underfit</dd>
<dt>More fit</dt><dd>good (better fit to real patterns); bad (more fit to random patterns); overfit</dd>
</dl></li>
<li>Put another way:
<ul class="org-ul">
<li>Less variables = less fit = underfit to real patterns
<ul class="org-ul">
<li>Less relationship between constant and response</li>
<li>Smaller coefficients</li>
<li><b>High bias</b>: misses or minimizes real effects</li>
<li><b>Low variance</b>: less diff between predictions</li>
</ul></li>
<li>More variables = more fit = overfit to random patterns
<ul class="org-ul">
<li><b>Low bias</b>: real effects ok</li>
<li><b>High variance</b>: more diff between predictions (though.. random patterns)</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org1ac5bf4" class="outline-4">
<h4 id="org1ac5bf4"><span class="section-number-4">11.4.2.</span> Summary</h4>
<div class="outline-text-4" id="text-11-4-2">
<ul class="org-ul">
<li>Difficult to model well (high fit to real; low to random)</li>
<li>Easy to model badly (choose some random variable)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgfb9d64d" class="outline-3">
<h3 id="orgfb9d64d"><span class="section-number-3">11.5.</span> M11L5: Ridge regression / regularization</h3>
<div class="outline-text-3" id="text-11-5">
</div>
<div id="outline-container-org0739439" class="outline-4">
<h4 id="org0739439"><span class="section-number-4">11.5.1.</span> Ridge regression</h4>
<div class="outline-text-4" id="text-11-5-1">
<ul class="org-ul">
<li>Reduces the <b>size</b> of coefficients if the error points start from outside the ridge regression threshold circle</li>
<li>Does not work if the error points are already inside the threshold circle
<ul class="org-ul">
<li>In this case, reduce the size of &tau;<sub>\text</sub>{Ridge} until it reaches point outside the circle</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org35aad9c" class="outline-4">
<h4 id="org35aad9c"><span class="section-number-4">11.5.2.</span> Coefficients -&gt; magnitude of effect</h4>
<div class="outline-text-4" id="text-11-5-2">
<ul class="org-ul">
<li>We want to reduce the amount of fit</li>
<li>This is accomplished by reducing the magnitude of the regression coefficients</li>
<li>Ideally, reduce only fit to random patterns, however this is impossible, hence reduce fit to all</li>
<li>Reducing magnitude -&gt; reduces variance -&gt; reduce fit</li>
</ul>
</div>
</div>
<div id="outline-container-orgda51c01" class="outline-4">
<h4 id="orgda51c01"><span class="section-number-4">11.5.3.</span> Ridge regression limits the magnitude of the regression coefficient instead of the number of variables</h4>
<div class="outline-text-4" id="text-11-5-3">
<ul class="org-ul">
<li>This technique is also known as regularization</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge431918" class="outline-3">
<h3 id="orge431918"><span class="section-number-3">11.6.</span> M11L6: Choosing a variable selection model</h3>
<div class="outline-text-3" id="text-11-6">
<ul class="org-ul">
<li>Recap on methods of variable selection:
<ul class="org-ul">
<li>Good for initial analysis but often lacks performance
<ul class="org-ul">
<li>forward</li>
<li>backward</li>
<li>stepwise regression</li>
</ul></li>
<li>Slower, better performing
<ul class="org-ul">
<li>lasso</li>
<li>elastic net</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="outline-container-org40346f3" class="outline-4">
<h4 id="org40346f3"><span class="section-number-4">11.6.1.</span> Lasso vs ridge vs elastic net</h4>
<div class="outline-text-4" id="text-11-6-1">
<ul class="org-ul">
<li>Elastic net is like lasso + ridge
<ul class="org-ul">
<li>Start with lasso adds absolute value term in constraint;</li>
<li>Ridge adds quadratic (squared) term;</li>
</ul></li>
<li>Lasso: some coefficients forced to 0 to simplify model</li>
<li>Ridge: coefficients shrink towards 0 to reduce variance in estimate</li>
</ul>
</div>
</div>
<div id="outline-container-orgf4b5919" class="outline-4">
<h4 id="orgf4b5919"><span class="section-number-4">11.6.2.</span> Elastic net</h4>
<div class="outline-text-4" id="text-11-6-2">
<ul class="org-ul">
<li>Benefits:
<ul class="org-ul">
<li>Has variable selection like Lasso</li>
<li>Has predictive benefits like Ridge</li>
</ul></li>
<li>Downsides:
<ul class="org-ul">
<li>Rules out some correlated variables like Lasso (only one is kept but it may not be the best one)</li>
<li>Underestimates very predictive variables like Ridge</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5f89e85" class="outline-4">
<h4 id="org5f89e85"><span class="section-number-4">11.6.3.</span> Which one to use?</h4>
<div class="outline-text-4" id="text-11-6-3">
<ul class="org-ul">
<li>No good rule of thumb. Compare and contrast.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orgcace7b7" class="outline-2">
<h2 id="orgcace7b7"><span class="section-number-2">12.</span> Module 12: Design of Experiments</h2>
<div class="outline-text-2" id="text-12">
</div>
<div id="outline-container-org3914c8a" class="outline-3">
<h3 id="org3914c8a"><span class="section-number-3">12.1.</span> M12L1: Intro</h3>
<div class="outline-text-3" id="text-12-1">
<p>
What if dataset is hard to get/requires some process to get?
Examples:
</p>
<ol class="org-ol">
<li>determining which ad is better for advertising OMSA.</li>
<li>which similar or related product to show to users?</li>
<li>how to get representative sample of all relevant factors?</li>
<li>combinations of medical treatments</li>
<li>maximizing agricultural productiveness</li>
</ol>
</div>
<div id="outline-container-orgf2af912" class="outline-4">
<h4 id="orgf2af912"><span class="section-number-4">12.1.1.</span> Comparison and control</h4>
<div class="outline-text-4" id="text-12-1-1">
<ul class="org-ul">
<li>Answering whether red used cars sell for higher prices than blue used cars?</li>
<li>Control other factors:
<ol class="org-ol">
<li>Color</li>
<li>Age</li>
<li>Sports vs family car</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org8d05599" class="outline-4">
<h4 id="org8d05599"><span class="section-number-4">12.1.2.</span> Blocking</h4>
<div class="outline-text-4" id="text-12-1-2">
<ul class="org-ul">
<li>A blocking factor creates variation</li>
<li>E.g. sports car vs family car</li>
<li>Sports car more likely to be red</li>
<li>Analyzing red sports cars vs red family cars have less variance than all red cars</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org70c5c15" class="outline-3">
<h3 id="org70c5c15"><span class="section-number-3">12.2.</span> M12L2: A/B testing</h3>
<div class="outline-text-3" id="text-12-2">
<p>
Choosing the best out of alternatives. Example:  banner ads: how to decide which version to show?
</p>
<ul class="org-ul">
<li>Show two different ads and how often each ad was clicked</li>
<li>This is binomial data; use hypothesis testing to test for statistical significance.</li>
</ul>
</div>
<div id="outline-container-org1975578" class="outline-4">
<h4 id="org1975578"><span class="section-number-4">12.2.1.</span> Required to use A/B testing</h4>
<div class="outline-text-4" id="text-12-2-1">
<ol class="org-ol">
<li>Data can be collected quickly</li>
<li>Data must be representative</li>
<li>Data collected is small vs. entire population (cost: does not make sense to spend 2000/2500 on building model. Remaining 500 too little to exploit.)</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgfec5710" class="outline-3">
<h3 id="orgfec5710"><span class="section-number-3">12.3.</span> M12L3: Factorial design</h3>
<div class="outline-text-3" id="text-12-3">
</div>
<div id="outline-container-orgfae551e" class="outline-4">
<h4 id="orgfae551e"><span class="section-number-4">12.3.1.</span> Full factorial design</h4>
<div class="outline-text-4" id="text-12-3-1">
<ul class="org-ul">
<li>Test every combination and use ANOVA to determine the importance of each factor</li>
<li>Explodes with number of combinations, e.g. 7 factors x 3 choices = 3<sup>7</sup> = 2187 combinations</li>
</ul>
</div>
</div>
<div id="outline-container-org0185e88" class="outline-4">
<h4 id="org0185e88"><span class="section-number-4">12.3.2.</span> Fractional factorial design</h4>
<div class="outline-text-4" id="text-12-3-2">
<ul class="org-ul">
<li>Test subset of combinations</li>
<li>Balanced design
<ul class="org-ul">
<li>Test each choice the same # of times</li>
<li>Test each pair of choices the same # of times</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgad0ef19" class="outline-4">
<h4 id="orgad0ef19"><span class="section-number-4">12.3.3.</span> Independent factors</h4>
<div class="outline-text-4" id="text-12-3-3">
<ul class="org-ul">
<li>Factors need to be independent</li>
<li>Test subset of combinations
<ul class="org-ul">
<li>Use regression to estimate effects</li>
</ul></li>
<li>But there still some interaction factors, e.g. white background can't be used with white font color</li>
</ul>
</div>
</div>
<div id="outline-container-org6aa21a4" class="outline-4">
<h4 id="org6aa21a4"><span class="section-number-4">12.3.4.</span> Summary</h4>
<div class="outline-text-4" id="text-12-3-4">
<ul class="org-ul">
<li>Factorial methods can be very useful before data is collected</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc727e4f" class="outline-3">
<h3 id="orgc727e4f"><span class="section-number-3">12.4.</span> M12L4: Multi-armed bandits</h3>
<div class="outline-text-3" id="text-12-4">
<ul class="org-ul">
<li>What if there are &gt; 2 possible alternatives</li>
</ul>
</div>
<div id="outline-container-org63f8a0d" class="outline-4">
<h4 id="org63f8a0d"><span class="section-number-4">12.4.1.</span> Exploration vs exploitation</h4>
<div class="outline-text-4" id="text-12-4-1">
<ul class="org-ul">
<li>With 10 alternatives, 1000 tests on each alternative:
<ul class="org-ul">
<li>10000 test total, but only 1 is best</li>
<li>So 9000 tests lost value</li>
</ul></li>
<li>Trade-off between having more information and immediate value
<dl class="org-dl">
<dt>Exploration</dt><dd>more information</dd>
<dt>Exploitation</dt><dd>immediate value</dd>
</dl></li>
</ul>
</div>
</div>
<div id="outline-container-org9ff1dd2" class="outline-4">
<h4 id="org9ff1dd2"><span class="section-number-4">12.4.2.</span> Multi-armed bandit</h4>
<div class="outline-text-4" id="text-12-4-2">
<ul class="org-ul">
<li>Finding the slot machine with the highest payout requires testing them all</li>
<li>Each slot machine is a 'single-armed bandit'</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgea82595"></a>Implementation<br />
<div class="outline-text-5" id="text-12-4-2-1">
<ol class="org-ol">
<li>Start with K alternatives, no information
<ul class="org-ul">
<li>Equal probability of selecting each alternative</li>
</ul></li>
<li>Repeat
<ul class="org-ul">
<li>Choose an alternative to test
<ul class="org-ul">
<li>Based on probability of each alternative being best</li>
</ul></li>
<li>After test, update probabilities of each one being best</li>
<li>Until the best alternative is clear</li>
</ul></li>
</ol>
</div>
</li>
<li><a id="org64b4fea"></a>Parameters<br />
<div class="outline-text-5" id="text-12-4-2-2">
<ul class="org-ul">
<li>Number of tests between recalculating probabilities</li>
<li>How to update probabilities</li>
<li>How to pick an alternative to test based on probabilities and / or expected values</li>
</ul>
</div>
</li>
<li><a id="org6aab150"></a>Summary<br />
<div class="outline-text-5" id="text-12-4-2-3">
<ul class="org-ul">
<li>No simple rule</li>
<li>Usually better than fix/large number of tests</li>
<li>Learn faster along the fly and create more value while doing so</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgf606a80" class="outline-2">
<h2 id="orgf606a80"><span class="section-number-2">13.</span> Module 13: Probability-based Models</h2>
<div class="outline-text-2" id="text-13">
</div>
<div id="outline-container-orga51a9c3" class="outline-3">
<h3 id="orga51a9c3"><span class="section-number-3">13.1.</span> M13L1: Intro</h3>
<div class="outline-text-3" id="text-13-1">
</div>
<div id="outline-container-org7e1c9ad" class="outline-4">
<h4 id="org7e1c9ad"><span class="section-number-4">13.1.1.</span> Simple modelling</h4>
<div class="outline-text-4" id="text-13-1-1">
<ul class="org-ul">
<li>Examples:
<ul class="org-ul">
<li>Airline security flows</li>
<li>Will season ticket owners show up?</li>
<li>Staffing fast food outlets</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8b6fc6a" class="outline-4">
<h4 id="org8b6fc6a"><span class="section-number-4">13.1.2.</span> Example on ticket owner not showing up</h4>
<div class="outline-text-4" id="text-13-1-2">
<ul class="org-ul">
<li>How long should we wait before selling seat upgrade?</li>
<li>Fan can pay more if they get the seat earlier, however, this increases risk that the ticket owner will arrive</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org92c211f"></a>Factors<br />
<div class="outline-text-5" id="text-13-1-2-1">
<ul class="org-ul">
<li>About ticket holder (age, children, past data)</li>
<li>About the team (standings, players, etc)</li>
<li>About the game (opponent, star players, etc)</li>
<li>Day factors (week, season, holiday)</li>
</ul>
</div>
</li>
<li><a id="org564c240"></a>Simple model can still work better<br />
<div class="outline-text-5" id="text-13-1-2-2">
<ul class="org-ul">
<li>Probability-distribution analysis can work just as well e.g. ticket holder X tends to arrive after about 60% of other fans</li>
<li>Less dependency vs other factors</li>
<li>Just use this instead of collecting other data</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orge18719d" class="outline-4">
<h4 id="orge18719d"><span class="section-number-4">13.1.3.</span> Summary</h4>
<div class="outline-text-4" id="text-13-1-3">
<p>
Other examples that can work:
</p>
<ul class="org-ul">
<li>Broken equipment</li>
<li>Website purchases</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9d6f0d9" class="outline-3">
<h3 id="org9d6f0d9"><span class="section-number-3">13.2.</span> M13L2: Bernoulli, Binomial and Geometric Distributions</h3>
<div class="outline-text-3" id="text-13-2">
</div>
<div id="outline-container-org4ccc7ce" class="outline-4">
<h4 id="org4ccc7ce"><span class="section-number-4">13.2.1.</span> Bernoulli distribution</h4>
<div class="outline-text-4" id="text-13-2-1">
<ul class="org-ul">
<li>E.g., flipping a coin that's not 50:50</li>
<li>Can specify:
<dl class="org-dl">
<dt>\(p\)</dt><dd>probability it comes up heads</dd>
<dt>$$1-p</dt><dd>probability that it comes up tails</dd>
</dl></li>
<li>By itself, talks about 1 data point</li>
<li>How to relate to other data points?</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgf738d57"></a>Example<br />
<div class="outline-text-5" id="text-13-2-1-1">
<ul class="org-ul">
<li>P(Sends donations) = p</li>
<li>p does not differ from month to month</li>
<li>Number of donations each month is binomially distributed</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org94fbcca" class="outline-4">
<h4 id="org94fbcca"><span class="section-number-4">13.2.2.</span> Binomial distribution</h4>
<div class="outline-text-4" id="text-13-2-2">
<ul class="org-ul">
<li>Probability of getting \(x\) successes from \(n\) iid Bernoulli (\(p\)) trials</li>
<li><b><b>Large</b></b> \(n\):
<ul class="org-ul">
<li>Converges to normal distribution
<ul class="org-ul">
<li>Useful for predicting errors</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org7f78acc" class="outline-4">
<h4 id="org7f78acc"><span class="section-number-4">13.2.3.</span> Geometric distribution</h4>
<div class="outline-text-4" id="text-13-2-3">
<ul class="org-ul">
<li>Probability of having \(x\) Bernoulli (\(p\)) failures until first success?
<ul class="org-ul">
<li>Equivalently: having x Bernoulli (\(1-p\)) success until first failure</li>
</ul></li>
<li>Need to define \(p\) and \(1-p\) carefully</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgc6e5561"></a>Can also answer questions about process<br />
<div class="outline-text-5" id="text-13-2-3-1">
<ul class="org-ul">
<li>If it fits geometric distribution, then hits are i.i.d. Bernoulli trials</li>
<li>If it does not fit, hits are not i.i.d., and need to consider other factors</li>
<li>Are airport screeners more likely to screen if there hasn't been a screening in a while?
<ul class="org-ul">
<li>Observe the graph and see whether it fits a geometric distribution</li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org142e8bc" class="outline-3">
<h3 id="org142e8bc"><span class="section-number-3">13.3.</span> M13L3: Poisson, Weibull and Exponential Distributions</h3>
<div class="outline-text-3" id="text-13-3">
</div>
<div id="outline-container-org5a463e5" class="outline-4">
<h4 id="org5a463e5"><span class="section-number-4">13.3.1.</span> Poisson</h4>
<div class="outline-text-4" id="text-13-3-1">
<ul class="org-ul">
<li>Good at modelling random  arrivals
<dl class="org-dl">
<dt>&lambda;</dt><dd>the average number of arrivals per time period</dd>
</dl></li>
<li>Arrivals are i.i.d.</li>
</ul>
</div>
</div>
<div id="outline-container-orgb9e6b64" class="outline-4">
<h4 id="orgb9e6b64"><span class="section-number-4">13.3.2.</span> Exponential distribution</h4>
<div class="outline-text-4" id="text-13-3-2">
<ul class="org-ul">
<li>Related to Poisson</li>
<li>If arrivals are Poisson(&lambda;):
<ul class="org-ul">
<li>Time between successive arrivals is distributed by exponential(&lambda;) distribution</li>
</ul></li>
<li>Poisson # of arrivals &lt;==&gt; exponential inter-arrival time</li>
</ul>
</div>
</div>
<div id="outline-container-org903033d" class="outline-4">
<h4 id="org903033d"><span class="section-number-4">13.3.3.</span> Weibull</h4>
<div class="outline-text-4" id="text-13-3-3">
<ul class="org-ul">
<li>Models the <b>time</b> between failures</li>
<li>Whereas geometric models the <b>number of tries</b> between failures</li>
<li>\(k < 1\)
<ul class="org-ul">
<li>Modelling when failure rate <b>decreases</b> with time</li>
<li>"Worst things fail first"</li>
</ul></li>
<li>\(k > 1\)
<ul class="org-ul">
<li>Modelling when failure rate <b>increases</b> with time</li>
<li>"Things that wear out" e.g. tires</li>
</ul></li>
<li>\(k = 1\)
<ul class="org-ul">
<li>Modelling when failure rate is constant with time</li>
<li>This is equal to the <b>exponential distribution</b>
<ul class="org-ul">
<li>With different notation</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org76f34b2" class="outline-4">
<h4 id="org76f34b2"><span class="section-number-4">13.3.4.</span> Software can help but may be confusing</h4>
</div>
</div>
<div id="outline-container-org925091e" class="outline-3">
<h3 id="org925091e"><span class="section-number-3">13.4.</span> M13L4: Q-Q plots</h3>
<div class="outline-text-3" id="text-13-4">
</div>
<div id="outline-container-org6f6c297" class="outline-4">
<h4 id="org6f6c297"><span class="section-number-4">13.4.1.</span> Visualizing</h4>
<div class="outline-text-4" id="text-13-4-1">
<ul class="org-ul">
<li>Whether 2 distributions (different datasets) are about the same</li>
<li>Whether a dataset is distributed similarly to a probability distribution
<dl class="org-dl">
<dt>Horizontal axis</dt><dd>data</dd>
<dt>Vertical axis</dt><dd>theoretical values of percentiles of a probability distribution</dd>
</dl></li>
<li>Statistical tests work but can hide details about ranges, overall etc.</li>
</ul>
</div>
</div>
<div id="outline-container-org8877658" class="outline-4">
<h4 id="org8877658"><span class="section-number-4">13.4.2.</span> Types of Q-Q plots</h4>
<div class="outline-text-4" id="text-13-4-2">
<ul class="org-ul">
<li>Understand how to read the plots rather than memorize shapes</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9bd89f7" class="outline-3">
<h3 id="org9bd89f7"><span class="section-number-3">13.5.</span> M13L5: Queuing</h3>
<div class="outline-text-3" id="text-13-5">
<ul class="org-ul">
<li>Telemarketing example with autodialer in marketing</li>
</ul>
</div>
<div id="outline-container-orgf4147a1" class="outline-4">
<h4 id="orgf4147a1"><span class="section-number-4">13.5.1.</span> Queuing example</h4>
<div class="outline-text-4" id="text-13-5-1">
<ul class="org-ul">
<li>Qn: how many employees should we have?</li>
<li>Variables:
<ul class="org-ul">
<li>Number of people who answer the autodialer</li>
<li>Duration of call once it starts</li>
</ul></li>
<li>Probability distributions:
<ul class="org-ul">
<li>Call arrives to queue:
<ul class="org-ul">
<li>Based on probability distribution of time between arrivals</li>
</ul></li>
<li>Call finish:
<ul class="org-ul">
<li>Based on probability distribution of talking time</li>
</ul></li>
</ul></li>
<li>Call arrival e.g. poisson</li>
<li>Call duration e.g. exponential</li>
</ul>
</div>
</div>
<div id="outline-container-org6e710b9" class="outline-4">
<h4 id="org6e710b9"><span class="section-number-4">13.5.2.</span> More complex example</h4>
<div class="outline-text-4" id="text-13-5-2">
<ul class="org-ul">
<li>New factors:
<ul class="org-ul">
<li>Limited number of calls in queue</li>
<li>Additional employee</li>
</ul></li>
<li>New concept: <b>memoryless property</b>
<ul class="org-ul">
<li>This means it doesn't matter what happened in the past, only what's happening <b>now</b></li>
<li>E.g. memoryless exponential distribution
<ul class="org-ul">
<li>Regardless of current call duration, the <i>remaining</i> call time distribution = <i>initial</i> distribution of call time using the distribution</li>
<li>Therefore can discover from the distribution</li>
</ul></li>
<li>E.g. memoryless Posson distribution</li>
</ul></li>
<li>If data fits exponential distribution =&gt; It is memoryless</li>
<li>Otherwise, not fitting exponential distribution =&gt; not memoryless</li>
</ul>
</div>
</div>
<div id="outline-container-orgf681a7c" class="outline-4">
<h4 id="orgf681a7c"><span class="section-number-4">13.5.3.</span> Queuing models</h4>
<div class="outline-text-4" id="text-13-5-3">
<ul class="org-ul">
<li>Parameters:
<dl class="org-dl">
<dt>A</dt><dd>General arrival distribution</dd>
<dt>S</dt><dd>General service distribution</dd>
<dt>c</dt><dd>Number of servers</dd>
<dt>K</dt><dd>Size of queue</dd>
<dt>N</dt><dd>Population size</dd>
<dt>D</dt><dd>Queuing discipline</dd>
</dl></li>
<li>Kendall notation M/M/1 queue</li>
<li>Potential extensions:
<ul class="org-ul">
<li>Hangups, balking etc</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7a13946" class="outline-3">
<h3 id="org7a13946"><span class="section-number-3">13.6.</span> M13L6: Simulation basics</h3>
<div class="outline-text-3" id="text-13-6">
</div>
<div id="outline-container-org2f80003" class="outline-4">
<h4 id="org2f80003"><span class="section-number-4">13.6.1.</span> Types of simulations</h4>
<div class="outline-text-4" id="text-13-6-1">
<ul class="org-ul">
<li>Random behaviour?
<ul class="org-ul">
<li>Deterministic (no randomness)
<ul class="org-ul">
<li>Same inputs give identical outputs</li>
</ul></li>
<li>Stochastic (includes randoness)
<ul class="org-ul">
<li>Outputs may differ even for identical inputs</li>
</ul></li>
</ul></li>
<li>Time
<ul class="org-ul">
<li>Continuous-time
<ul class="org-ul">
<li>Changes happen continuously</li>
<li>E.g. chemical processes, disease spread</li>
<li>Use differential equation models</li>
</ul></li>
<li>Discrete event simulations
<ul class="org-ul">
<li>The <b>focus</b></li>
<li>Example: call center simulations</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga2f867d" class="outline-4">
<h4 id="orga2f867d"><span class="section-number-4">13.6.2.</span> Discrete-event stochastic simulations</h4>
<div class="outline-text-4" id="text-13-6-2">
<ul class="org-ul">
<li>Use when systems have high variability</li>
<li>Averages are not good enough</li>
</ul>
</div>
</div>
<div id="outline-container-orgeaaf0fb" class="outline-4">
<h4 id="orgeaaf0fb"><span class="section-number-4">13.6.3.</span> Simulation software</h4>
<div class="outline-text-4" id="text-13-6-3">
<ul class="org-ul">
<li>Elements include:
<dl class="org-dl">
<dt>Entities</dt><dd>things that move through simulations, e.g. bags, people</dd>
<dt>Modules</dt><dd>represent part of process, e.g. queues, storage</dd>
<dt>Actions</dt><dd>thing to do</dd>
<dt>Resources</dt><dd>e.g. workers</dd>
<dt>Decision points</dt><dd>can affect flow</dd>
</dl></li>
<li>Can output statisntics for tracking</li>
<li>Random numbers are important!</li>
</ul>
</div>
</div>
<div id="outline-container-org5a7a378" class="outline-4">
<h4 id="org5a7a378"><span class="section-number-4">13.6.4.</span> Replications</h4>
<div class="outline-text-4" id="text-13-6-4">
<ul class="org-ul">
<li>The number of runs of simulation</li>
<li>One run is insufficient due to the random nature; not representative</li>
<li>Run multiple times to get distribution of outcomes</li>
<li>E.g. simulating average throughout</li>
</ul>
</div>
</div>
<div id="outline-container-org71e9724" class="outline-4">
<h4 id="org71e9724"><span class="section-number-4">13.6.5.</span> Simulation validation</h4>
<div class="outline-text-4" id="text-13-6-5">
<ul class="org-ul">
<li>Use real data to validate that the simulation is giving valid results
<ul class="org-ul">
<li>Problems:
<ul class="org-ul">
<li>Real average differs from simulated average</li>
<li>Real variance differs from simulated variance</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgff16cd3" class="outline-3">
<h3 id="orgff16cd3"><span class="section-number-3">13.7.</span> M13L7: Prescriptive simulation</h3>
<div class="outline-text-3" id="text-13-7">
<ul class="org-ul">
<li>Once validated simulation, use it for "what-if" questions
<ul class="org-ul">
<li>e.g. what if $1000 is invested, what is the improvement?</li>
<li>where to place baggage tugs?</li>
</ul></li>
<li>Heuristic optimization can also be possible</li>
</ul>
</div>
<div id="outline-container-orgd5744da" class="outline-4">
<h4 id="orgd5744da"><span class="section-number-4">13.7.1.</span> Simulation comparisons</h4>
<div class="outline-text-4" id="text-13-7-1">
<p>
Can be run by hand:
</p>
<ul class="org-ul">
<li>e.g. 1 tug per gate
<ul class="org-ul">
<li>vs. 1 tug per two gates</li>
</ul></li>
<li>be careful, each could be influenced by which set of random numbers are chosen
<ul class="org-ul">
<li>Use the same random numbers for comparison</li>
</ul></li>
<li>Simulation can be a powerful tool but:
<ul class="org-ul">
<li>Model only as good as input's quality</li>
<li>Missing or incorrect information leads to incorrect answers</li>
</ul></li>
<li>Example: call center simulation
<ul class="org-ul">
<li>If it assumes all workers answer calls as quickly as each other, wrong, can lead to bad decisions</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org413b5e2" class="outline-4">
<h4 id="org413b5e2"><span class="section-number-4">13.7.2.</span> Validation can be hard</h4>
<div class="outline-text-4" id="text-13-7-2">
<ul class="org-ul">
<li>Especially if it's something that doesn't exist</li>
</ul>
</div>
</div>
<div id="outline-container-org9211152" class="outline-4">
<h4 id="org9211152"><span class="section-number-4">13.7.3.</span> Simulation/validation should consider all processes</h4>
<div class="outline-text-4" id="text-13-7-3">
<ul class="org-ul">
<li>E.g. data collection</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org091c916" class="outline-3">
<h3 id="org091c916"><span class="section-number-3">13.8.</span> M13L8: Markov chains</h3>
<div class="outline-text-3" id="text-13-8">
<ul class="org-ul">
<li>Based on states, e.g. cloudy, sunny, etc</li>
<li>For each state <i>i</i>,
<ul class="org-ul">
<li>p<sub>ij</sub> = transition probability from state <i>i</i> to state <i>j</i></li>
<li>P = {p<sub>ij</sub>} is the transition matrix</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org6677cf7" class="outline-4">
<h4 id="org6677cf7"><span class="section-number-4">13.8.1.</span> Answering questions with the transition matrix</h4>
<div class="outline-text-4" id="text-13-8-1">
<ul class="org-ul">
<li>What's the long-run probability of rainy days?</li>
<li>&pi; = (0.5, 0.25, 0.25) for (Sunny, Cloudy, Rainy)</li>
<li>&pi; &times; P = (0.525, 0.25, 0.225) the probabilities of (Sunny, Cloudy, Rainy) tomorrow</li>
<li>&pi; &times; P<sup>2</sup> &#x2026;</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org0e0cb2a"></a>Long term probability?<br />
<div class="outline-text-5" id="text-13-8-1-1">
<ul class="org-ul">
<li>Use steady state to apply P and get the initial vector back
<ul class="org-ul">
<li>&pi; &times; P = &pi;</li>
</ul></li>
<li>Solve for &pi; P = &pi; and &sum;<sub>i</sub> &pi;<sub>i</sub> = 1</li>
<li>Not always a steady state</li>
<li><b><b>Steady state only exists when:</b></b>
<ol class="org-ol">
<li>possible to get from one state to all other states</li>
<li>no cyclic behaviour</li>
</ol></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org8c7b126" class="outline-4">
<h4 id="org8c7b126"><span class="section-number-4">13.8.2.</span> Key assumption</h4>
<div class="outline-text-4" id="text-13-8-2">
<ul class="org-ul">
<li>Memoryless:
<ul class="org-ul">
<li>State transitions only depend on <b>most recent</b> state
<ul class="org-ul">
<li>E.g. weather: tomorrow's only depends on today's</li>
</ul></li>
</ul></li>
<li>Most systems are not memoryless
<ul class="org-ul">
<li>But still useful because it's still useful e.g. for PageRank</li>
</ul></li>
<li>Other applications
<ol class="org-ol">
<li>Rank basketball teams</li>
<li>Urban sprawl, population, disease</li>
</ol></li>
<li>Markov chains can still work in long-run even if not memoryless in short-run</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf3113d1" class="outline-2">
<h2 id="orgf3113d1"><span class="section-number-2">14.</span> Module 14: Missing Data</h2>
<div class="outline-text-2" id="text-14">
</div>
<div id="outline-container-org2d0f7c5" class="outline-3">
<h3 id="org2d0f7c5"><span class="section-number-3">14.1.</span> M14L01: Intro to missing data</h3>
<div class="outline-text-3" id="text-14-1">
</div>
<div id="outline-container-org95827e4" class="outline-4">
<h4 id="org95827e4"><span class="section-number-4">14.1.1.</span> When is there missing data?</h4>
<div class="outline-text-4" id="text-14-1-1">
<ol class="org-ol">
<li>Broken collection equipment</li>
<li>Transmission breaks down</li>
<li>Human interaction (wrong forms, unavailable data, etc)</li>
</ol>
</div>
</div>
<div id="outline-container-orgcf208fc" class="outline-4">
<h4 id="orgcf208fc"><span class="section-number-4">14.1.2.</span> Data problems</h4>
<div class="outline-text-4" id="text-14-1-2">
<ul class="org-ul">
<li>Missing data</li>
<li>Incorrect data</li>
<li>There are often patterns in missing or wrong data</li>
<li>Extremely wrong: <i>outlier</i></li>
</ul>
</div>
</div>
<div id="outline-container-org162dfc6" class="outline-4">
<h4 id="org162dfc6"><span class="section-number-4">14.1.3.</span> Patterns in missing data</h4>
<div class="outline-text-4" id="text-14-1-3">
<ul class="org-ul">
<li>How easy is it to collect/observe data?</li>
<li>Income (higher income household might choose to omit)</li>
<li>Radar gun accuracy/reliability</li>

<li>If missing data is biased in some way, need additional methods to deal with it</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc86477c" class="outline-3">
<h3 id="orgc86477c"><span class="section-number-3">14.2.</span> M14L02: Methods not requiring imputation</h3>
<div class="outline-text-3" id="text-14-2">
</div>
<div id="outline-container-orgd4616ff" class="outline-4">
<h4 id="orgd4616ff"><span class="section-number-4">14.2.1.</span> Dealing with missing data</h4>
<div class="outline-text-4" id="text-14-2-1">
<ol class="org-ol">
<li>Discard records</li>
<li>Indicate with categorical variables</li>
<li>Estimate missing value</li>
</ol>
</div>
</div>
<div id="outline-container-org1e2156c" class="outline-4">
<h4 id="org1e2156c"><span class="section-number-4">14.2.2.</span> Discard records</h4>
<div class="outline-text-4" id="text-14-2-2">
<ul class="org-ul">
<li>Pros:
<ul class="org-ul">
<li>Easy to implement</li>
<li>Does not introduce errors</li>
</ul></li>
<li>Cons:
<ul class="org-ul">
<li>Data point is lost</li>
<li>Potentially censors or biases missing data (e.g. high income not reporting income)</li>
</ul></li>
<li>Check pattern of missing data!</li>
</ul>
</div>
</div>
<div id="outline-container-org9bc8390" class="outline-4">
<h4 id="org9bc8390"><span class="section-number-4">14.2.3.</span> Categorical variable approach</h4>
<div class="outline-text-4" id="text-14-2-3">
<ol class="org-ol">
<li>Qualitative field
<ol class="org-ol">
<li>Add category: `missing`</li>
</ol></li>
<li>Quantitative field
<ol class="org-ol">
<li>Set missing to \(0\)</li>
<li>Add new categorical variable `missing`</li>
<li>Create interaction terms. This become similar to a tree-model if interaction terms are created for all variables</li>
</ol></li>
</ol>
</div>
</div>
<div id="outline-container-org5755eff" class="outline-4">
<h4 id="org5755eff"><span class="section-number-4">14.2.4.</span> Summary</h4>
<div class="outline-text-4" id="text-14-2-4">
<p>
This lesson's approach avoids estimating the missing data.
</p>
</div>
</div>
</div>
<div id="outline-container-orgd736b3c" class="outline-3">
<h3 id="orgd736b3c"><span class="section-number-3">14.3.</span> M14L03: Imputation methods</h3>
<div class="outline-text-3" id="text-14-3">
</div>
<div id="outline-container-org1801d3a" class="outline-4">
<h4 id="org1801d3a"><span class="section-number-4">14.3.1.</span> Mid-range value</h4>
<div class="outline-text-4" id="text-14-3-1">
<p>
Mean or median (numeric) or mode (categorical)
</p>
<ul class="org-ul">
<li>Pros:
<ul class="org-ul">
<li>Will not be too wrong</li>
<li>Simple</li>
</ul></li>
<li>Cons:
<ul class="org-ul">
<li>Biased imputation if the missing data is biased</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga100b4a" class="outline-4">
<h4 id="orga100b4a"><span class="section-number-4">14.3.2.</span> Regression</h4>
<div class="outline-text-4" id="text-14-3-2">
<ul class="org-ul">
<li>Pros:
<ul class="org-ul">
<li>Reduce or eliminates bias.</li>
</ul></li>
<li>Cons:
<ul class="org-ul">
<li>Could be over-fitting as regression is used to fit model and to predict.</li>
<li>Complex to build, fit, validate, test</li>
<li>Doesn't capture all variability in the rest of the data.
<ul class="org-ul">
<li>The same imputed amount will be assigned to all with similar predictors.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb00e344" class="outline-4">
<h4 id="orgb00e344"><span class="section-number-4">14.3.3.</span> Regression with perturbation (imputation with variability)</h4>
<div class="outline-text-4" id="text-14-3-3">
<ul class="org-ul">
<li>Adds some randomness (perturbation) to each imputed value</li>
<li>E.g., normally distributed variation</li>
<li>Less accurate predictions on average, but:</li>
<li>More accurate variability</li>
</ul>
</div>
</div>
<div id="outline-container-orgb873e99" class="outline-4">
<h4 id="orgb873e99"><span class="section-number-4">14.3.4.</span> Imputation approaches</h4>
<div class="outline-text-4" id="text-14-3-4">
<ul class="org-ul">
<li>Data used twice (over-fits)</li>
<li>Limit to max 5% per factor</li>
<li>Does imputation cause additional error?
<ol class="org-ol">
<li>Imputation error</li>
<li>Perturbation error</li>
<li>Model error</li>
</ol></li>
<li>Yes, but regular data also has errors most times</li>
</ul>
</div>
</div>
<div id="outline-container-orgc587776" class="outline-4">
<h4 id="orgc587776"><span class="section-number-4">14.3.5.</span> Summary</h4>
<div class="outline-text-4" id="text-14-3-5">
<ul class="org-ul">
<li>Data is always imperfect
<ul class="org-ul">
<li>Errors</li>
<li>Outliers</li>
<li>Missing data</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org73f34bc" class="outline-2">
<h2 id="org73f34bc"><span class="section-number-2">15.</span> Module 15: Optimization</h2>
<div class="outline-text-2" id="text-15">
<p>
Key underlying part of descriptive and prescriptive analytics.
</p>
</div>
<div id="outline-container-org27c1695" class="outline-3">
<h3 id="org27c1695"><span class="section-number-3">15.1.</span> M15L01: Intro to Optimization</h3>
<div class="outline-text-3" id="text-15-1">
</div>
<div id="outline-container-org5000dd2" class="outline-4">
<h4 id="org5000dd2"><span class="section-number-4">15.1.1.</span> Examples</h4>
<div class="outline-text-4" id="text-15-1-1">
<ul class="org-ul">
<li>Schedule airplane mechanics</li>
<li>Plan crude oil shipments</li>
<li>Allocate server farms</li>
<li>Schedule machine shop</li>
<li>Route car routes</li>
<li>Define asset usage</li>
<li>Determine sports draft</li>
<li>Route and deliver worldwide oil</li>
<li>Plan electricity generation based on weather patterns</li>
</ul>
</div>
</div>
<div id="outline-container-org59ba009" class="outline-4">
<h4 id="org59ba009"><span class="section-number-4">15.1.2.</span> Optimization provides direction for an organization</h4>
<div class="outline-text-4" id="text-15-1-2">
<ul class="org-ul">
<li>Sits on top of descriptive and predictive analytics</li>
</ul>
</div>
</div>
<div id="outline-container-orgb1ff12d" class="outline-4">
<h4 id="orgb1ff12d"><span class="section-number-4">15.1.3.</span> Optimization software</h4>
<div class="outline-text-4" id="text-15-1-3">
<ul class="org-ul">
<li>Model building automatically in software is still not available</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga5942ba" class="outline-3">
<h3 id="orga5942ba"><span class="section-number-3">15.2.</span> M15L02: Elements of Optimization Models</h3>
<div class="outline-text-3" id="text-15-2">
<dl class="org-dl">
<dt>Variables</dt><dd>decisions to be made</dd>
<dt>Constraints</dt><dd>restrictions on values of variables</dd>
<dt>Objective function</dt><dd>measure of quality of solution</dd>
<dt>Solution</dt><dd>value for each variable</dd>
<dt>Feasible solution</dt><dd>variable value that satisfy all constraints</dd>
<dt>Optimal solution</dt><dd>feasible solution with the <b><b>best</b></b> objective value</dd>
</dl>
</div>
</div>
<div id="outline-container-orgd7bc939" class="outline-3">
<h3 id="orgd7bc939"><span class="section-number-3">15.3.</span> M15L03: Optimization is an art</h3>
<div class="outline-text-3" id="text-15-3">
</div>
<div id="outline-container-org5017ef5" class="outline-4">
<h4 id="org5017ef5"><span class="section-number-4">15.3.1.</span> Examples</h4>
<div class="outline-text-4" id="text-15-3-1">
</div>
<ol class="org-ol">
<li><a id="org937f494"></a>US Army diet<br />
<div class="outline-text-5" id="text-15-3-1-1">
<ul class="org-ul">
<li>US Army diet problem: what to feed soldiers at minimum cost?
<ul class="org-ul">
<li>\(n\) foods</li>
<li>\(m\) nutritional value</li>
<li>\(a_{ij}\) amount of nutrition \(j\) per unit of food \(i\)</li>
<li>\(m_j\) min daily intake of nutrient \(j\)</li>
<li>\(M_j\) Max daily intake of nutrient \(j\)</li>
<li>\(c_i\) per-unit cost of food \(i\)</li>
</ul></li>
<li>Optimization model
<ul class="org-ul">
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>the amount of food \(i\) in daily diet</dd>
</dl></li>
<li>Constraints
<dl class="org-dl">
<dt>\(\sum_i a_{ij}x_i \gt m_j\)</dt><dd>for each nutrient \(j\)</dd>
<dt>\(\sum_i a_{ij}x_i\) &le; M<sub>j</sub></dt><dd>for each nutrient \(j\)</dd>
<dt>\(x_i \geq 0\) </dt><dd>for each food \(i\)</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Minimize \(\sum_i c_i x_i\)</li>
</ul></li>
</ul></li>
<li>Complexities in model
<ul class="org-ul">
<li>Variety in diets</li>
<li>Seasonal cost might differ</li>
<li>Food might not taste good in general</li>
<li>Food might not taste good in combination</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="orgb535121"></a>Call center scheduling<br />
<div class="outline-text-5" id="text-15-3-1-2">
<ul class="org-ul">
<li>Meet forecast demand \(d_i\) for each day of week \(i\)
<ul class="org-ul">
<li>Workers work 5 days then rest 2 days</li>
<li>Minimize worker-days total</li>
</ul></li>
<li>Wrong model:
<ul class="org-ul">
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>number of people working on day \(i\)</dd>
</dl></li>
<li>Constraints
<dl class="org-dl">
<dt>\(x_i \geq d_i\)</dt><dd>meet demand</dd>
<dt>\(int(x_i)\)</dt><dd>\(x_i\) is integer for all days \(i\)</dd>
<dt>??</dt><dd>5-day requirement</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Minimize \(x_{\text{Sunday}} + x_{\text{Monday}} + ... + x_{\text{Saturday}}\)</li>
</ul></li>
<li>Difficult to model!</li>
</ul></li>
<li>Right model:
<ul class="org-ul">
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>number of people who <b>start</b> working on day \(i\)</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Minimize $5 &times; \(x_{\text{Sunday}} + x_{\text{Monday}} + ... + x_{\text{Saturday}}\)</li>
</ul></li>
<li>Constraints
<dl class="org-dl">
<dt>\(\sum_j \text{working on day i} x_j \geq d_i\)</dt><dd>meet demand
<ul class="org-ul">
<li>Example: \(x_{fri} + ... + x_{tue} \geq d_{tue}\)</li>
</ul></dd>
<dt>\(x_i \geq 0\)</dt><dd>non negative for all days \(i\)</dd>
<dt>\(int(x_i)\)</dt><dd>\(x_i\) is integer for all days \(i\)</dd>
</dl></li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-orgf0c63ac" class="outline-3">
<h3 id="orgf0c63ac"><span class="section-number-3">15.4.</span> M15L04: Modeling with binary variables</h3>
<div class="outline-text-3" id="text-15-4">
</div>
<div id="outline-container-org4ebaaa8" class="outline-4">
<h4 id="org4ebaaa8"><span class="section-number-4">15.4.1.</span> Example: stock market investment</h4>
<div class="outline-text-4" id="text-15-4-1">
<p>
Invest to balance risk and return
</p>
<ul class="org-ul">
<li>Where:
<dl class="org-dl">
<dt>\(B\)</dt><dd>investment budget</dd>
<dt>\(n\)</dt><dd>number of stocks available</dd>
<dt>\(r_i\)</dt><dd>expected return of stock \(i\) relative to market</dd>
<dt>\(Q_{ij}\)</dt><dd>covariance of returns of stocks \(i\) and \(j\)</dd>
</dl></li>
<li>Variables
<dl class="org-dl">
<dt>\(x_i\)</dt><dd>amount invested in stock \(i\)</dd>
</dl></li>
<li>Constraints
<dl class="org-dl">
<dt>\(\sum_ix_i \leq B\)</dt><dd>can meet budget</dd>
<dt>\(x_i \geq 0\)</dt><dd>no shorting</dd>
</dl></li>
<li>Objective function
<ul class="org-ul">
<li>Maximize \(\sum_ir_ix_i - \theta \sum_i\sum_jQ_{ij}x_ix_j\)
<ul class="org-ul">
<li>first part is return</li>
<li>second part is risk</li>
</ul></li>
</ul></li>
<li>To consider: transaction fees
<ul class="org-ul">
<li>But no binary indicators if transaction fee is paid or not paid. Can create \(y_i = 1\) if invest, else 0</li>
<li>New objective function: Maximize \(\sum_ir_ix_i - \theta \sum_i\sum_jQ_{ij}x_ix_j - \sum_ity_i\)</li>
<li>New additional constraint: \(x_i \leq By_i\), which in effect means:
<ul class="org-ul">
<li>when \(y_i = 0\): \(x_i \leq 0\)</li>
<li>when \(y_i = 1\): \(x_i \leq B\)</li>
</ul></li>
</ul></li>
<li>To consider: minimum investment in each stock
<ul class="org-ul">
<li>New term \(m_i\): the minimum dollar amount invested in stock \(i\)</li>
<li>New constraint: \(x_i \geq m_iy_i\) for all stocks \(i\)</li>
</ul></li>
<li>To consider: personal constraints e.g. can only invest in Tesla; AMZN, GOOG, AAPL
<ul class="org-ul">
<li>\(y_{Tesla} = 1\) or \(y_{Amazon} + y_{Google} + y_{Apple} \geq 1\)</li>
</ul></li>
<li>Related constraints, e..g if invest in energy stock, must invest in at least 5
<ul class="org-ul">
<li>Change constraint: sum \(y_i\) for energy stocks \(\geq y_i\) for the 5 energy stocks</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org0e137a9" class="outline-4">
<h4 id="org0e137a9"><span class="section-number-4">15.4.2.</span> Recap uses of integer variables in optimization</h4>
<div class="outline-text-4" id="text-15-4-2">
<ul class="org-ul">
<li>Fixed charges</li>
<li>Constraints in terms of choosing options</li>
<li>Constraints in requiring same or opposite choices</li>
<li>If/then constraints</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org4a7eab0" class="outline-3">
<h3 id="org4a7eab0"><span class="section-number-3">15.5.</span> M15L05: Discovering the real questions</h3>
<div class="outline-text-3" id="text-15-5">
</div>
<div id="outline-container-org5a10538" class="outline-4">
<h4 id="org5a10538"><span class="section-number-4">15.5.1.</span> Real life</h4>
<div class="outline-text-4" id="text-15-5-1">
<ul class="org-ul">
<li>Is often less specific, with information isn't fully specified or available</li>
<li>Discovery is hard
<ol class="org-ol">
<li>Too many constraints to remember or recite</li>
<li>Easy to forget obscure ones</li>
<li>Easy to omit "obvious" ones
<ol class="org-ol">
<li>E.g. 5-day work week definition</li>
<li>E.g. partial shifts</li>
</ol></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org735b0bb" class="outline-4">
<h4 id="org735b0bb"><span class="section-number-4">15.5.2.</span> Summary</h4>
<div class="outline-text-4" id="text-15-5-2">
<ul class="org-ul">
<li>Need to discover details:
<ul class="org-ul">
<li>Constraints, objective function, etc</li>
</ul></li>
<li><i>Potentially</i>, build other models to determine inputs for optimization</li>
<li>Iterate between:
<ol class="org-ol">
<li>Build model</li>
<li>Optimize</li>
<li>Get feedback</li>
<li>Tweak/build model</li>
</ol></li>
<li>Applies to other analytics/data science modelling</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org725f9e2" class="outline-2">
<h2 id="org725f9e2"><span class="section-number-2">16.</span> Module 16: Advanced Models</h2>
<div class="outline-text-2" id="text-16">
<blockquote>
<p>
Midterm 2: modules 11-16 (from variable selection to optimization and advanced models) &#x2013; weeks 8-12
</p>
</blockquote>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: W</p>
<p class="date">Created: 2023-04-02 Sun 14:41</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
