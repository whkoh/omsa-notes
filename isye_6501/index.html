<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-02-05 Sun 20:24 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>ISYE 6501 Intro to Analytics Modeling Notes</title>
<meta name="author" content="W" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/readtheorg.css"/>
<script type="text/javascript" src="src/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="src/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">ISYE 6501 Intro to Analytics Modeling Notes</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org4a967eb">1. Module 01: Intro</a>
<ul>
<li><a href="#org07d0828">1.1. What's analytics?</a></li>
<li><a href="#org6c2bd40">1.2. Modeling</a></li>
<li><a href="#org72e6dcd">1.3. Course structure</a></li>
<li><a href="#orgde6ab45">1.4. Three different things are all models</a></li>
<li><a href="#org6759092">1.5. Hence these are all "models":</a></li>
</ul>
</li>
<li><a href="#orgce84ccd">2. Module 02: Classification</a>
<ul>
<li><a href="#org134e9bf">2.1. M1L1: Intro to classification</a></li>
<li><a href="#orgc08b6ab">2.2. M1L2: Choosing a Classifier</a>
<ul>
<li><a href="#orgf4a3525">2.2.1. Example: Loan payment (Income vs credit score)</a></li>
</ul>
</li>
<li><a href="#org6a4107e">2.3. M2L3 Data definitions</a>
<ul>
<li><a href="#orgd7f12d0">2.3.1. Data terminology</a></li>
<li><a href="#orgbf14514">2.3.2. Data types</a></li>
</ul>
</li>
<li><a href="#org45961e9">2.4. M2L4: Support vector machines</a>
<ul>
<li><a href="#orga5abb7c">2.4.1. When not possible to get full separation</a></li>
</ul>
</li>
<li><a href="#org1916cac">2.5. M2L5: What SVM means</a></li>
<li><a href="#org99fe092">2.6. M2L6: Advanced SVM</a></li>
<li><a href="#org2568dfc">2.7. M2L7: Scaling and standardization</a>
<ul>
<li><a href="#org28d1761">2.7.1. Scaling data</a></li>
<li><a href="#org3bc6d77">2.7.2. Standardization of data</a></li>
<li><a href="#orgc2141e0">2.7.3. Choosing between scaling vs standardization</a></li>
</ul>
</li>
<li><a href="#orgdef9c18">2.8. M2L8: K Nearest Neighbour model (KNN)</a></li>
</ul>
</li>
<li><a href="#org40ca627">3. Module 03: Validation</a>
<ul>
<li><a href="#org7debd0d">3.1. M3L1: Training, validation and test data</a></li>
<li><a href="#orgb2ce139">3.2. M3L2: Splitting data</a></li>
<li><a href="#org35c0dfe">3.3. M3L3: Cross-validation</a></li>
<li><a href="#org778966d">3.4. M3L4: Summary</a></li>
</ul>
</li>
<li><a href="#orgea9a803">4. Module 04: Clustering</a>
<ul>
<li><a href="#org1547a50">4.1. M4L1: Introduction to clustering</a></li>
<li><a href="#orgdcdb618">4.2. M4L2: Distance Norms</a></li>
<li><a href="#org80448bf">4.3. M4L3: K-Means Clustering</a></li>
<li><a href="#org52e19a8">4.4. M4L4: Practical details for K-Means</a></li>
<li><a href="#orgba3364c">4.5. M4L5: Clustering for prediction</a></li>
<li><a href="#org5bd0e4e">4.6. M4L6: Clustering vs Classification</a></li>
</ul>
</li>
<li><a href="#org774673d">5. Module 05: Data preparation</a>
<ul>
<li><a href="#orge7f1cfd">5.1. M5L1: Common techniques and problems</a></li>
<li><a href="#org5b8ea6d">5.2. M5L2: Outliers</a></li>
<li><a href="#org84537b2">5.3. M5L3: What to do with outliers?</a>
<ul>
<li><a href="#org49fe6a5">5.3.1. Bad data</a></li>
<li><a href="#orgb545191">5.3.2. Real / correct data</a></li>
<li><a href="#org8407f3f">5.3.3. Another way to handle outliers</a></li>
<li><a href="#org5210256">5.3.4. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org9cbc0a1">6. Module 06: Change detection</a>
<ul>
<li><a href="#org98aa3f3">6.1. M6L1: Examples</a></li>
<li><a href="#org51399be">6.2. M6L2: Cumulative sum for change detection</a>
<ul>
<li><a href="#orge13ee59">6.2.1. Interpretation</a></li>
</ul>
</li>
<li><a href="#org007535e">6.3. M6L3: Ethics: Honestly reporting our results</a></li>
</ul>
</li>
<li><a href="#org8a833b2">7. Module 07: Time series</a>
<ul>
<li><a href="#org8aee84a">7.1. M7L1: Introduction to exponential smoothing</a>
<ul>
<li><a href="#orgb4092e3">7.1.1. Random variation</a></li>
<li><a href="#org77fce26">7.1.2. Definitions:</a></li>
<li><a href="#orgfe8f352">7.1.3. Exponential smoothing method</a></li>
</ul>
</li>
<li><a href="#orgc121d5f">7.2. M7L2: Trend and cyclic effects</a>
<ul>
<li><a href="#org78ecd07">7.2.1. Trends</a></li>
<li><a href="#org0717eec">7.2.2. Cyclical patterns</a></li>
<li><a href="#org52e7994">7.2.3. Summary</a></li>
</ul>
</li>
<li><a href="#orgcba411c">7.3. M7L3: Etymology (what the name means)</a>
<ul>
<li><a href="#orgb744b4b">7.3.1. Summary</a></li>
</ul>
</li>
<li><a href="#org594737e">7.4. M7L4: Forecasting</a></li>
<li><a href="#org2b9366c">7.5. M3L5: ARIMA</a>
<ul>
<li><a href="#orge4a78b1">7.5.1. (I): Differences</a></li>
<li><a href="#orge9b6ec9">7.5.2. (II): Autogression</a></li>
<li><a href="#orgd38e297">7.5.3. (III): Moving Average</a></li>
<li><a href="#orgb833a15">7.5.4. ARIMA model</a></li>
</ul>
</li>
<li><a href="#org27e4b84">7.6. M7L6: GARCH</a>
<ul>
<li><a href="#orgfc82d1e">7.6.1. Variance</a></li>
<li><a href="#org1d5604d">7.6.2. GARCH</a></li>
<li><a href="#org031bb8d">7.6.3. Summary - three models for time series analysis</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org4a967eb" class="outline-2">
<h2 id="org4a967eb"><span class="section-number-2">1.</span> Module 01: Intro</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org07d0828" class="outline-3">
<h3 id="org07d0828"><span class="section-number-3">1.1.</span> What's analytics?</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Analytics answers these questions
</p>
<ol class="org-ol">
<li>Descriptive - what happened</li>
<li>Predictive - what will happen</li>
<li>Prescriptive - what action is best</li>
<li>General questions</li>
</ol>
</div>
</div>
<div id="outline-container-org6c2bd40" class="outline-3">
<h3 id="org6c2bd40"><span class="section-number-3">1.2.</span> Modeling</h3>
<div class="outline-text-3" id="text-1-2">
<ol class="org-ol">
<li>Describe real-life situation with math</li>
<li>Analyze math</li>
<li>Turn math answer back to real situation</li>
</ol>
</div>
</div>
<div id="outline-container-org72e6dcd" class="outline-3">
<h3 id="org72e6dcd"><span class="section-number-3">1.3.</span> Course structure</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Enough math intuition and detail
</p>
<ul class="org-ul">
<li>Models
<ul class="org-ul">
<li>Machine learning</li>
<li>Regression</li>
<li>Optimizaton</li>
</ul></li>
<li>Cross-cutting
<ul class="org-ul">
<li>Data prep</li>
<li>Output quality</li>
<li>Missing data</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgde6ab45" class="outline-3">
<h3 id="orgde6ab45"><span class="section-number-3">1.4.</span> Three different things are all models</h3>
<div class="outline-text-3" id="text-1-4">
<ol class="org-ol">
<li>Real life situation expressed as math</li>
<li>Analyse the math</li>
<li>Turn mathematical analyse to real-life solution</li>
</ol>
</div>
</div>
<div id="outline-container-org6759092" class="outline-3">
<h3 id="org6759092"><span class="section-number-3">1.5.</span> Hence these are all "models":</h3>
<div class="outline-text-3" id="text-1-5">
<ol class="org-ol">
<li>Regression</li>
<li>Regression on size, weight, distance</li>
<li>Regression estimate = 37+81*Size +76*Wt, etc</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgce84ccd" class="outline-2">
<h2 id="orgce84ccd"><span class="section-number-2">2.</span> Module 02: Classification</h2>
<div class="outline-text-2" id="text-2">
<blockquote>
<p>
Definition: putting things into groups
</p>
</blockquote>
</div>
<div id="outline-container-org134e9bf" class="outline-3">
<h3 id="org134e9bf"><span class="section-number-3">2.1.</span> M1L1: Intro to classification</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Types of classification models
</p>
<ol class="org-ol">
<li>Number of groups</li>
<li>Number of dimensions
<ul class="org-ul">
<li>Can 1 dimension be sufficient to classify?</li>
</ul></li>
<li>Soft vs hard classifiers (is it 100% error-free?)</li>
</ol>
</div>
</div>
<div id="outline-container-orgc08b6ab" class="outline-3">
<h3 id="orgc08b6ab"><span class="section-number-3">2.2.</span> M1L2: Choosing a Classifier</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Definition of bad classification
</p>
<ul class="org-ul">
<li>Cost: is one type of mistake worse than the other?</li>
</ul>
</div>
<div id="outline-container-orgf4a3525" class="outline-4">
<h4 id="orgf4a3525"><span class="section-number-4">2.2.1.</span> Example: Loan payment (Income vs credit score)</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>Plot lines and find one that can separate default vs non-default.</li>
<li>How do we know the right lines are drawn?</li>
<li>We want to be as conservative as possible (less error prone)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org6a4107e" class="outline-3">
<h3 id="org6a4107e"><span class="section-number-3">2.3.</span> M2L3 Data definitions</h3>
<div class="outline-text-3" id="text-2-3">
</div>
<div id="outline-container-orgd7f12d0" class="outline-4">
<h4 id="orgd7f12d0"><span class="section-number-4">2.3.1.</span> Data terminology</h4>
<div class="outline-text-4" id="text-2-3-1">
<ol class="org-ol">
<li>Row = data point</li>
<li>Column = dimension, attribute, feature, predictor, covariate
<ol class="org-ol">
<li>Special column = response, outcome</li>
</ol></li>
</ol>
</div>
</div>
<div id="outline-container-orgbf14514" class="outline-4">
<h4 id="orgbf14514"><span class="section-number-4">2.3.2.</span> Data types</h4>
<div class="outline-text-4" id="text-2-3-2">
<ol class="org-ol">
<li>Structured data
<ol class="org-ol">
<li>Quantitative
<ul class="org-ul">
<li>Numbers with meaning</li>
</ul></li>
<li>Categorical
<ul class="org-ul">
<li>Numbers without meaning</li>
</ul></li>
<li>Binary data (subset of categorical)</li>
<li>Unrelated data</li>
<li>Time series data</li>
</ol></li>
<li>Unstructured
<ol class="org-ol">
<li>Text data</li>
</ol></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org45961e9" class="outline-3">
<h3 id="org45961e9"><span class="section-number-3">2.4.</span> M2L4: Support vector machines</h3>
<div class="outline-text-3" id="text-2-4">
<ul class="org-ul">
<li><b>Supervised</b> method (algorithm uses known results when training)</li>
<li>Terminology
<ul class="org-ul">
<li>m = number of data points</li>
<li>n = number of attributes</li>
<li>x<sub>ij</sub> = j attribute of i data point
<ul class="org-ul">
<li>e.g. x<sub>51</sub> = credit score of person 5; x<sub>52</sub> = income of person 5</li>
</ul></li>
<li>y<sub>i</sub> = response of data point i
<ul class="org-ul">
<li>e.g. 1 if data point is group 1</li>
<li>-1 if data point is group 2</li>
</ul></li>
<li>Line: \(a_1 x_1\) + \(a_2 x_2\) + &#x2026; + \(a_n x_n\) + \(a_0\) = 0</li>
<li>Note the intercept \(a_0\)</li>
</ul></li>
<li>In general: \(\sum_{j=1}^{n} a_j x_j + a_0 = 0\)</li>
<li>Separation problem: get max distance between lines</li>
<li>\(2\over{\sqrt(\sum_{j} \left(a_j\right)^2)}\)</li>
<li>i.e. Min<sub>a<sub>0</sub> &#x2026; a<sub>n</sub></sub>: \(\sum_{j=1}^{n}\left(a_j\right)^2\)</li>
<li>Subject to constraints</li>
</ul>
</div>
<div id="outline-container-orga5abb7c" class="outline-4">
<h4 id="orga5abb7c"><span class="section-number-4">2.4.1.</span> When not possible to get full separation</h4>
<div class="outline-text-4" id="text-2-4-1">
<ul class="org-ul">
<li>Then we minimize error</li>
<li>There's a trade-off between margin and error</li>
<li>Error for data point is:
\[
  \text{max} \{ 0, 1-(\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}
  \]</li>
<li>Total error is:
\[
  \sum_{i=1}^{m} \text{max} \{ 0, 1 - (\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}
  \]</li>
<li>Margin denominator: \(\sum_{j=1}^{n}(a_j)^2\)</li>

<li>We multiply margin by \(\lambda\) to <b>assign its importance of margin vs error</b>.</li>
<li>Hence, the full equation is:
\[
  \text{Minimize}_{a_0,...,a_n} \sum_{i=1}^{m} \text{max} \{ 0, 1 - (\sum_{j=1}^{n} a_j x_{ij} + a_0) y_i \}  + \lambda \sum_{j=1}^{n}(a_j)^2
  \]</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1916cac" class="outline-3">
<h3 id="org1916cac"><span class="section-number-3">2.5.</span> M2L5: What SVM means</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li>Etymology
<ul class="org-ul">
<li>Vector = point</li>
<li><b>Support vector</b> = points that holds up (or, supports) a shape. Shape is correctly balanced on parallel lines</li>
<li>Model determines the "support vectors"</li>
<li>Automatically from data hence "<b>machine</b>"</li>
</ul></li>
<li>Support can be from top or side</li>
<li>Looking for max separation i.e. the support vector touches the data points</li>
<li>Classifier is in between the two support vectors</li>
</ul>
</div>
</div>
<div id="outline-container-org99fe092" class="outline-3">
<h3 id="org99fe092"><span class="section-number-3">2.6.</span> M2L6: Advanced SVM</h3>
<div class="outline-text-3" id="text-2-6">
<ul class="org-ul">
<li>The constant term a<sub>0</sub> can be used to adjust the intercept and hence tweak the SVM model.
<ul class="org-ul">
<li>If it's more costly to grant a bad loan, e.g.: \(\frac{2}{3}(a_0-1) + \frac{1}{3}(a_0+1)\)</li>
</ul></li>
<li>For soft classification, you can add a multiplier m<sub>j</sub> for each type of error:
<ul class="org-ul">
<li>m<sub>j</sub> &gt; 1 for more costly</li>
<li>m<sub>j</sub> &lt; 1 for less costly</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org2568dfc" class="outline-3">
<h3 id="org2568dfc"><span class="section-number-3">2.7.</span> M2L7: Scaling and standardization</h3>
<div class="outline-text-3" id="text-2-7">
<ul class="org-ul">
<li>Predictive factors may have different orders of magnitude, i.e.
<ul class="org-ul">
<li>Income in \(10^5\)</li>
<li>Credit score in \(10^2\)</li>
<li>Classifier is \(0 = a_0 + \sum_{j} a_j x_j\)</li>
<li>Maximise gap by minimizing: \(\sum_{j} a_j^2\)</li>
<li>Coefficients might be 10<sup>6</sup> + 5*income + 701*credit score
<ul class="org-ul">
<li>Sum of squared coefficients:
\(\sum_j a_j^2 = 5^2 + 700^2 = 490,025\)</li>
<li>Changing credit score by 1 increases the sum by 1,401:
\(\sum_j a_j^2 = 5^2 + 701^2 = 491,426\)</li>
</ul></li>
<li>Small change in one coefficient affects the sum a lot due to difference in scales.
<ul class="org-ul">
<li>As data has such different scale.</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="outline-container-org28d1761" class="outline-4">
<h4 id="org28d1761"><span class="section-number-4">2.7.1.</span> Scaling data</h4>
<div class="outline-text-4" id="text-2-7-1">
<ul class="org-ul">
<li>Common scale is between 0 and 1</li>
<li>Scale data by factor
\[
  x_{ij}^{\text{scaled}} = \frac{x_{ij}-x_{\text{min}j}}{x_{\text{max}j} - x_{\text{min}j}}
  \]</li>
<li>General scaling between a, b:
\[
  x_{ij}^{\text{scaled}[b,a]} = x_{ij}^{\text{scaled}[0,1]}(a-b)+b
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-org3bc6d77" class="outline-4">
<h4 id="org3bc6d77"><span class="section-number-4">2.7.2.</span> Standardization of data</h4>
<div class="outline-text-4" id="text-2-7-2">
<ul class="org-ul">
<li>Scale to normal distribution</li>
<li>Common scale is:
<ul class="org-ul">
<li>Mean = 0</li>
<li>SD = 1</li>
</ul></li>
<li>Factor j has:
<ul class="org-ul">
<li>mean \(\mu_j = \frac{\sum_{i=1}^n x_{ij}}{n}\)</li>
<li>SD \(\sigma_j\)</li>
</ul></li>
<li>For each data point \(i\):
\[
  x_{ij}^{\text{standardized}} = \frac{x_{ij}-\mu_j}{\sigma_j}
  \]</li>
</ul>
</div>
</div>
<div id="outline-container-orgc2141e0" class="outline-4">
<h4 id="orgc2141e0"><span class="section-number-4">2.7.3.</span> Choosing between scaling vs standardization</h4>
<div class="outline-text-4" id="text-2-7-3">
<ul class="org-ul">
<li>Scale when:
<ul class="org-ul">
<li>Data is in bounded (defined) range, e.g.
<ul class="org-ul">
<li>Neural networks</li>
<li>Optimization models requiring bounded data</li>
<li>Batting averages (between 0 and 1)</li>
<li>RGB color scale (0-255)</li>
<li>SAT scores (200-800)</li>
</ul></li>
</ul></li>
<li>Standardization, examples:
<ul class="org-ul">
<li>PCA</li>
<li>Clustering</li>
</ul></li>
<li>Try both when not clear</li>
<li>Should be used throughout course even when not stated explicitly</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgdef9c18" class="outline-3">
<h3 id="orgdef9c18"><span class="section-number-3">2.8.</span> M2L8: K Nearest Neighbour model (KNN)</h3>
<div class="outline-text-3" id="text-2-8">
<ul class="org-ul">
<li><b>Classification</b></li>
<li>e.g. loan dataset with two predictors and a response</li>
<li>Assume each point has similar characteristics with its neighbors</li>
<li>Choice of number of points is denoted by \(k\)</li>
<li>Algorithm to find color (class) of a new point:
<ol class="org-ol">
<li>Pick \(k\) closest points (i.e., nearest neighbours) to the new one</li>
<li>The new point's class is the most common among the \(k\) neighbors</li>
</ol></li>
<li>Complexities
<ul class="org-ul">
<li>More than one distance metric (<i>c.f.</i> distance selection topic_).
<ul class="org-ul">
<li>Straight line is: \(\sqrt{\sum_{i=1}^n |x_i-y_i|^2}\)</li>
</ul></li>
<li>Attributes can be given more weight if more important, \(w_i\)
<ul class="org-ul">
<li>Weights to be found with other techniques e.g. regression</li>
</ul></li>
<li>Unimportant metrics can be removed
<ul class="org-ul">
<li><i>c.f.</i> variable selection topic</li>
<li>Choose good value of \(k\), <i>c.f.</i> validation @ <a href="#org40ca627">3</a></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org40ca627" class="outline-2">
<h2 id="org40ca627"><span class="section-number-2">3.</span> Module 03: Validation</h2>
<div class="outline-text-2" id="text-3">
<blockquote>
<p>
Check how good a model is
</p>
</blockquote>
</div>
<div id="outline-container-org7debd0d" class="outline-3">
<h3 id="org7debd0d"><span class="section-number-3">3.1.</span> M3L1: Training, validation and test data</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li><b>Cannot</b> calculate accuracy or effectiveness metrics from training dataset
<ul class="org-ul">
<li>Since model was trained on it</li>
<li>This doesn't allow separation of real effects from random effects</li>
</ul></li>
<li>When fitting a model, this captures both real and random effects
<ul class="org-ul">
<li>Real effects: exist in all datasets (or subsets)</li>
<li>Random effects: different in all datasets</li>
</ul></li>
<li>Use a <b>training</b> set of data to fit model</li>
<li>Use another <b>validation</b> set of data to judge model effectiveness</li>
<li>When comparing &gt;1 model, use a <b>test</b> dataset.
<ul class="org-ul">
<li>e.g. SVM and KNN, with 10 total models, we cannot use the effectiveness metric calculated on the validation set.</li>
</ul></li>
<li>Test data is required as high performing models have above average random effects
<ul class="org-ul">
<li>Too optimistic; it might have performed well but also likely received a boost from random effects</li>
</ul></li>
<li>Analogize with models equally good</li>
<li>Flowchart:
<img src="./img/validation01.png" alt="validation01.png" /></li>
</ul>
</div>
</div>
<div id="outline-container-orgb2ce139" class="outline-3">
<h3 id="orgb2ce139"><span class="section-number-3">3.2.</span> M3L2: Splitting data</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>How much data goes to each set?
<ol class="org-ol">
<li>70 to 90% train, remaining test</li>
<li>50 to 70% train, remaining evenly split validation &amp; test</li>
</ol></li>
<li>Methods of splitting data
<ol class="org-ol">
<li>Random</li>
<li>Rotation (take turn selecting data points into training, test, valid across the sets of split data)
<ul class="org-ul">
<li>Advantage: in time series data, may avoid all datasets having early/late data</li>
<li>Need to ensure rotation doesn't introduce bias</li>
</ul></li>
<li>Combined:
60% of Monday data for training, 60^% of Tuesday data for training, etc.</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org35c0dfe" class="outline-3">
<h3 id="org35c0dfe"><span class="section-number-3">3.3.</span> M3L3: Cross-validation</h3>
<div class="outline-text-3" id="text-3-3">
<blockquote>
<p>
What happens with important data appears only in one data set e.g., validation?
</p>
</blockquote>
<ul class="org-ul">
<li>Use cross-validation!</li>
<li>k-fold cross validation
<ol class="org-ol">
<li>Split data for testing (e.g. 20%)</li>
<li>With remaining data, use it for both training and validation by splitting into 4 x 20%, then:
<ol class="org-ol">
<li>Train 1, 2, 3, Validate 4</li>
<li>Train 1, 2, 4, Validate 3</li>
<li>Train 1, 3, 4, Validate 2</li>
<li>Train 2, 3, 4, Validate 1</li>
</ol></li>
</ol></li>
<li>Summary of k-fold cross-validation:
<ul class="org-ul">
<li>Train model on all other parts</li>
<li>Evaluate model on remaining part</li>
<li>Average \(k\) evaluations to estimate the model quality.</li>
<li>\(10\) is commonly selected for \(k\).</li>
<li><b>But</b>, the model selected from cross-validation is not used. Coefficients should also not be averaged.</li>
<li>Once model is selected, <b>retrain</b> with all data</li>
</ul></li>
<li>Advantages of k-fold cross-validation:
<ol class="org-ol">
<li>Better uses data</li>
<li>Better estimates model quality</li>
<li>Choose model more effectively</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org778966d" class="outline-3">
<h3 id="org778966d"><span class="section-number-3">3.4.</span> M3L4: Summary</h3>
<div class="outline-text-3" id="text-3-4">
<ol class="org-ol">
<li>Build model with training data</li>
<li>Pick model with validation data</li>
<li>Estimate performance with test data</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgea9a803" class="outline-2">
<h2 id="orgea9a803"><span class="section-number-2">4.</span> Module 04: Clustering</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org1547a50" class="outline-3">
<h3 id="org1547a50"><span class="section-number-3">4.1.</span> M4L1: Introduction to clustering</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li><b>Unsupervised</b> method (response not available for use in training)</li>
<li>Grouping data points</li>
<li>Might help discover attributes in the dataset</li>
<li>Example of use
<ul class="org-ul">
<li>Segmenting market of car buyers by:
<ol class="org-ol">
<li>Size</li>
<li>Price</li>
<li>Versatility, etc</li>
</ol></li>
<li>Personalized medicine</li>
<li>Locating facilities</li>
<li>Image analysis</li>
<li>Exploratory data analysis (different model for each attribute)</li>
</ul></li>
<li>Example: Miles driven vs. Age</li>
</ul>
</div>
</div>
<div id="outline-container-orgdcdb618" class="outline-3">
<h3 id="orgdcdb618"><span class="section-number-3">4.2.</span> M4L2: Distance Norms</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>Straight line distance (Euclidean)
\(\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}\)</li>
<li>Rectilinear distance (Manhattan, 1-norm)
\(|x_1-y_1| + |x_2-y_2|\)</li>
<li>Generalized p-norm (Minkowski)
\(\sqrt[p]{|x_1-y_1|^p+|x_2-y_2|^p}\)</li>
<li>&infin;-norm distance
\(\sqrt[\infty]{\sum_{i=1}^n|x_i-y_i|^{\infty}}\)
<ul class="org-ul">
<li>sum = \(|x_i-y_i|^{\infty}\)</li>
<li>\(\sqrt[\infty]{\text{max}_{i}^n|x_i-y_i|^{\infty}}\)</li>
<li>Largest term dominates the rest, hence simplifies to:</li>
<li>\(\text{max}_i |x_i-y_i|\)</li>
</ul></li>
<li>Analogize with warehouse picking robot. The operation that takes the longest dominates the total operation time.</li>
</ul>
</div>
</div>
<div id="outline-container-org80448bf" class="outline-3">
<h3 id="org80448bf"><span class="section-number-3">4.3.</span> M4L3: K-Means Clustering</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li><b>Unsupervised</b> technique</li>
<li>Steps to implement K-Means:
<ol class="org-ol">
<li>Plot data points on suitable axes (e.g., age vs temperature, sepal width vs sepal height)</li>
<li>Let:
<ul class="org-ul">
<li>\(x_{ij}\) = attribute \(j\) of data point \(i\)</li>
<li>\(y_{ik}\) = \(1\) iif data point \(i\) in cluster \(k\), else \(0\)</li>
<li>\(z_{jk}\) = coordinate \(j\) of cluster center \(k\)</li>
<li>Mathematically, but it takes too long:
\[
       \text{Min}_{y,z}\sum_i\sum_k \sqrt{\sum_{j} (x_{ij} - z_{jk})^2}
       \]
subject to: \(\sum_k y_{ik} = 1\) for each \(i\)</li>
</ul></li>
<li>Practical method:
<ul class="org-ul">
<li>Pick \(k\) cluster centers in data</li>
<li>Assign each point to nearest cluster center</li>
<li>Recalculate cluster center (centroid)
<ul class="org-ul">
<li>Now, data points might not belong to the right cluster</li>
</ul></li>
<li>Go back to assign, then re-calc, then assign, then re-calc iteratively until stable</li>
</ul></li>
<li>K-Means is a <b>heuristic</b>, i.e.:
<ul class="org-ul">
<li>it is fast and good</li>
<li><b>not guaranteed</b> to find global best solution.</li>
</ul></li>
<li>It is expectation-maximization (EM), and alternates between expectation (<i>finding cluster centers</i>) and maximization (<i>assigning points to clusters</i>)</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org52e19a8" class="outline-3">
<h3 id="org52e19a8"><span class="section-number-3">4.4.</span> M4L4: Practical details for K-Means</h3>
<div class="outline-text-3" id="text-4-4">
<p>
Algorithm just assigns outliers to nearest clusters.
</p>
<ul class="org-ul">
<li>Choosing <b>starting points</b>:
<ol class="org-ol">
<li>Run several times with different initial cluster centers</li>
<li>Algorithm is non-deterministic, <i>i.e.</i> can produce different results when run with different inputs</li>
<li>Choose the best solution from the results produced</li>
</ol></li>
<li>Handling <b>outliers</b>:
<ol class="org-ol">
<li>Discard, but may not be the 'right' answer</li>
<li>Ask why the outlier happens
<ul class="org-ul">
<li>What it means to discard or include the outlier</li>
<li>Ultimately, algorithm is just a guide. Best solution is what fits the situation.</li>
</ul></li>
</ol></li>
<li>Choosing <b>number of clusters</b>. Is adding a cluster always better?
<ul class="org-ul">
<li>It may increase the metric (total distance of each data point to their cluster center), hence clustering appears to work better.</li>
<li>However, it may defeat the purpose of clustering if every cluster just consists of one data point.</li>
</ul></li>
<li>Total distance can be compared to find the 'kink' or 'elbow'.
<ul class="org-ul">
<li>After this point, the marginal benefit of adding another cluster decreases.</li>
<li><p>
Elbow diagram:
</p>


<div id="org9d8cf4f" class="figure">
<p><img src="./img/04-elbow.png" alt="04-elbow.png" />
</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgba3364c" class="outline-3">
<h3 id="orgba3364c"><span class="section-number-3">4.5.</span> M4L5: Clustering for prediction</h3>
<div class="outline-text-3" id="text-4-5">
<blockquote>
<p>
Given a new point, which cluster should it be in?
</p>
</blockquote>
<ul class="org-ul">
<li>Is point inside cluster?</li>
<li>Otherwise, what's the nearest cluster center?</li>
<li>Asked another way: for the range of the dataset, which areas would we assign to each cluster if a new point appears there?
<ul class="org-ul">
<li>This is a <a href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi diagram</a>.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5bd0e4e" class="outline-3">
<h3 id="org5bd0e4e"><span class="section-number-3">4.6.</span> M4L6: Clustering vs Classification</h3>
<div class="outline-text-3" id="text-4-6">
<ul class="org-ul">
<li>Since both group data points&#x2026;</li>
<li>The difference is what we know about the data points.</li>
<li>For classification, the correct response is known, i.e.
<ul class="org-ul">
<li>supervised learning</li>
<li>model uses both attributes <b>and</b> response</li>
</ul></li>
<li>For clustering, the 'correct' classification is unknown
<ul class="org-ul">
<li>unsupervised learning</li>
<li>model decides clusters <b>only</b> based on the attributes</li>
</ul></li>
<li>Supervised learning is more common</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org774673d" class="outline-2">
<h2 id="org774673d"><span class="section-number-2">5.</span> Module 05: Data preparation</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orge7f1cfd" class="outline-3">
<h3 id="orge7f1cfd"><span class="section-number-3">5.1.</span> M5L1: Common techniques and problems</h3>
<div class="outline-text-3" id="text-5-1">
<ol class="org-ol">
<li>Scale data
<ul class="org-ul">
<li>Outliers?</li>
</ul></li>
<li>Extraneous (unnecessary data)
<ul class="org-ul">
<li>Complicates the model and</li>
<li>Makes it harder to interpret the solution</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org5b8ea6d" class="outline-3">
<h3 id="org5b8ea6d"><span class="section-number-3">5.2.</span> M5L2: Outliers</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>Types
<dl class="org-dl">
<dt>Point outliers</dt><dd>one / few points very different from others</dd>
<dt>Contextual outlier</dt><dd>Value far from other points in time (not in absolute value)</dd>
<dt>Collective outlier</dt><dd>Something missing in a range of points, but not sure exactly where. Outlier by omission.</dd>
</dl></li>
<li>How to detect?
<ul class="org-ul">
<li>Box-and-whisker plot if data can be plotted in 1-dimension
<ul class="org-ul">
<li>Box: 25/75th percentile
<ul class="org-ul">
<li>Line: 50th percentile</li>
</ul></li>
<li>Whiskers: 10/90th percentile, 5/95th, etc</li>
</ul></li>
<li>For multi-dimensional, no good way. We can still:
<ol class="org-ol">
<li>Fit a model.</li>
<li>Points with large error might be outlier</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org84537b2" class="outline-3">
<h3 id="org84537b2"><span class="section-number-3">5.3.</span> M5L3: What to do with outliers?</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>Need to understand why there's outliers
<ol class="org-ol">
<li>Bad data
<ul class="org-ul">
<li>Sensor fail</li>
<li>Contaminated experiment</li>
<li>Wrong data input</li>
</ul></li>
<li>Unexpected, real, data
<ul class="org-ul">
<li>Need to understand more about the data, e.g.</li>
<li>Where it came from</li>
<li>How it was compiled</li>
<li>Unique situations</li>
</ul></li>
</ol></li>
</ul>
</div>
<div id="outline-container-org49fe6a5" class="outline-4">
<h4 id="org49fe6a5"><span class="section-number-4">5.3.1.</span> Bad data</h4>
<div class="outline-text-4" id="text-5-3-1">
<ul class="org-ul">
<li>Omit the points</li>
<li>Use imputation to replace the points</li>
</ul>
</div>
</div>
<div id="outline-container-orgb545191" class="outline-4">
<h4 id="orgb545191"><span class="section-number-4">5.3.2.</span> Real / correct data</h4>
<div class="outline-text-4" id="text-5-3-2">
<ul class="org-ul">
<li>Outliers are somewhat expected in large datasets</li>
<li>E.g., for normally-distributed data:
<ul class="org-ul">
<li>4% will be outside 2 &sigma;</li>
<li>1e6 data points = 2000 outside 3 &sigma;</li>
</ul></li>
<li>Removing <b>real</b> outliers might make model too optimistic. <i>e.g.</i> not account for actual shipments that take a long time from US to Africa</li>
<li>Outliers might be due to weather, political events</li>
</ul>
</div>
</div>
<div id="outline-container-org8407f3f" class="outline-4">
<h4 id="org8407f3f"><span class="section-number-4">5.3.3.</span> Another way to handle outliers</h4>
<div class="outline-text-4" id="text-5-3-3">
<ol class="org-ol">
<li>First build a logistic regression model
<ul class="org-ul">
<li>This estimated probability of outliers under different conditions</li>
</ul></li>
<li>Next, build the regular model i.e. estimate delivery time under <b>normal conditions</b>
<ul class="org-ul">
<li>Use data without outliers</li>
<li>Report different outcomes&#x2026;</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org5210256" class="outline-4">
<h4 id="org5210256"><span class="section-number-4">5.3.4.</span> Summary</h4>
<div class="outline-text-4" id="text-5-3-4">
<ul class="org-ul">
<li>Outliers aren't predictable</li>
<li>Investigate the data in case you're wrong</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org9cbc0a1" class="outline-2">
<h2 id="org9cbc0a1"><span class="section-number-2">6.</span> Module 06: Change detection</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org98aa3f3" class="outline-3">
<h3 id="org98aa3f3"><span class="section-number-3">6.1.</span> M6L1: Examples</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>Usually with time series data</li>
<li>Determine if action is needed, e.g.,
<ul class="org-ul">
<li>Time for machine maintenance?</li>
<li>Have sales increased?</li>
</ul></li>
<li>Determine impact of some past action, e.g.,
<ul class="org-ul">
<li>Did new tax / increase rate decrease sales?</li>
<li>Did price discount increase sales?</li>
</ul></li>
<li>Determine changes of current actions, e.g.
<ul class="org-ul">
<li>Did voting patterns change?</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org51399be" class="outline-3">
<h3 id="org51399be"><span class="section-number-3">6.2.</span> M6L2: Cumulative sum for change detection</h3>
<div class="outline-text-3" id="text-6-2">
<blockquote>
<p>
Answers whether mean of the observed distribution gone above a critical level
</p>
</blockquote>
<ul class="org-ul">
<li>x<sub>t</sub> is observed value at time \(t\)</li>
<li>&mu; is mean of \(x\), if no change in distribution</li>
<li>Hence, \((x_t - \mu)\) is how much the observation is above mean at time \(t\)</li>
<li>Detecting an increase
\[
  S_t = \text{max}\{ 0, s_{t-1}+(x_t-\mu-C) \}
  \]
<ul class="org-ul">
<li>Determine threshold \(T\) and ask whether S<sub>t</sub> ⩾ T?
<ul class="org-ul">
<li>If running total &lt; 0, it's irrelevant</li>
<li>There should still be some randomness</li>
<li>C is a term to control how faster S<sub>t</sub> increases</li>
</ul></li>
</ul></li>
<li>Detecting a decrease
\[
  S_t = \text{max}\{ 0, s_{t-1}+(\mu-x_t-C) \}
  \]
<ul class="org-ul">
<li>Is S<sub>t</sub> ⩾ T?</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orge13ee59" class="outline-4">
<h4 id="orge13ee59"><span class="section-number-4">6.2.1.</span> Interpretation</h4>
<div class="outline-text-4" id="text-6-2-1">
<ul class="org-ul">
<li>Choices of model parameters
<dl class="org-dl">
<dt>T</dt><dd>the threshold, above which alarm is raised</dd>
<dt>C</dt><dd>the control term (smaller = more sensitive)</dd>
</dl></li>
<li>Consider / trade off:
<ol class="org-ol">
<li>How costly is it to delay detection? (false negative) -&gt; if it's costly, use small C</li>
<li>How costly is false positive? -&gt; if it's costly, use big C</li>
</ol></li>
<li>Use a control chart and plot S<sub>t</sub> vs t with \(T\) as a horizontal line
<img src="./img/06-control-chart.png" alt="06-control-chart.png" /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org007535e" class="outline-3">
<h3 id="org007535e"><span class="section-number-3">6.3.</span> M6L3: Ethics: Honestly reporting our results</h3>
<div class="outline-text-3" id="text-6-3">
<ul class="org-ul">
<li>Be faithful to data</li>
<li>Have sound conclusions drawn from the model and not your own conceptions</li>
<li>Always be honest and true to your analysis</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org8a833b2" class="outline-2">
<h2 id="org8a833b2"><span class="section-number-2">7.</span> Module 07: Time series</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org8aee84a" class="outline-3">
<h3 id="org8aee84a"><span class="section-number-3">7.1.</span> M7L1: Introduction to exponential smoothing</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>Data for the same response is known for many time periods</li>
<li>Examples:
<ul class="org-ul">
<li>Temperature readings</li>
<li>Price of stocks</li>
<li>Daily sales of hamburgers</li>
<li>Blood pressure readings</li>
</ul></li>
<li>Variation in time series data:
<ol class="org-ol">
<li>Trends increase or decrease</li>
<li>Cyclical variables over a year or a week</li>
</ol></li>
</ul>
</div>
<div id="outline-container-orgb4092e3" class="outline-4">
<h4 id="orgb4092e3"><span class="section-number-4">7.1.1.</span> Random variation</h4>
<div class="outline-text-4" id="text-7-1-1">
<ul class="org-ul">
<li>No underlying reason for the variation</li>
</ul>
</div>
</div>
<div id="outline-container-org77fce26" class="outline-4">
<h4 id="org77fce26"><span class="section-number-4">7.1.2.</span> Definitions:</h4>
<div class="outline-text-4" id="text-7-1-2">
<ul class="org-ul">
<li>\(S_t\): expected <b>baseline</b> response at time period \(t\)</li>
<li>\(x_t\): the observed response at \(t\)</li>
<li>Seeing a increase over time, is it
<ol class="org-ol">
<li>A real increase?</li>
<li>Random?</li>
</ol></li>
<li>There are two ways to answer:
<ol class="org-ol">
<li>It's a real increase, hence \(S_t = x_t\)
<ul class="org-ul">
<li>the observed reading is real indicator of revised baseline</li>
</ul></li>
<li>It's random, hence \(S_t = S_{t-1}\)
<ul class="org-ul">
<li>today's baseline = yesterday's baseline</li>
</ul></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-orgfe8f352" class="outline-4">
<h4 id="orgfe8f352"><span class="section-number-4">7.1.3.</span> Exponential smoothing method</h4>
<div class="outline-text-4" id="text-7-1-3">
<p>
Combines both, i.e.
\(S_t = \alpha x_t + (1-\alpha)S_{t-1}\)
</p>
<ul class="org-ul">
<li><p>
0 &lt; &alpha; &lt;1
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&alpha;</th>
<th scope="col" class="org-left">example value of &alpha;</th>
<th scope="col" class="org-left">randomness</th>
<th scope="col" class="org-left">trust</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">small</td>
<td class="org-left">&rarr; 0 (e.g. 0.01)</td>
<td class="org-left">high</td>
<td class="org-left">previous baseline i.e. \(S_{t-1}\)</td>
</tr>

<tr>
<td class="org-left">large</td>
<td class="org-left">&rarr; 1 (e.g. 0.99)</td>
<td class="org-left">low</td>
<td class="org-left">today's estimate i.e. \(x_t\)</td>
</tr>
</tbody>
</table></li>

<li>How to start? \(S_1 = x_1\)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc121d5f" class="outline-3">
<h3 id="orgc121d5f"><span class="section-number-3">7.2.</span> M7L2: Trend and cyclic effects</h3>
<div class="outline-text-3" id="text-7-2">
<p>
Complexities!
</p>
<ul class="org-ul">
<li>Trends, increasing or decreasing</li>
<li>Cyclical patterns, e.g. annual, weekly, daily</li>
</ul>
</div>
<div id="outline-container-org78ecd07" class="outline-4">
<h4 id="org78ecd07"><span class="section-number-4">7.2.1.</span> Trends</h4>
<div class="outline-text-4" id="text-7-2-1">
<ul class="org-ul">
<li>\(T_t\): the trend at time period \(t\)</li>
<li>\(S_t = \alpha x_t + (1-\alpha)S_{t-1}\)</li>
<li>\(T_t = \beta(S_t - S_{t-1}) + (1-\beta)T_{t-1}\)</li>
<li>Initial condition: \(T_1=0\)</li>
</ul>
</div>
</div>
<div id="outline-container-org0717eec" class="outline-4">
<h4 id="org0717eec"><span class="section-number-4">7.2.2.</span> Cyclical patterns</h4>
<div class="outline-text-4" id="text-7-2-2">
<ul class="org-ul">
<li>Make cycles additive: behaves like trend</li>
<li>Make cycles multiplicative: more notation required
<ul class="org-ul">
<li>L = length of cycle</li>
<li>\(C_t\) = the multiplicative seasonality factor
<ul class="org-ul">
<li>This inflates or deflates the observation</li>
</ul></li>
<li>New baseline formula
\[
    S_t = \frac{\alpha x_t}{C_{t-L}} + (1-\alpha)(S_{t-1}+T_{t-1})
    \]</li>
<li>Need to use the factor from \(L\) time periods ago
<ul class="org-ul">
<li>as that's the most recent cyclic factor we have from that part of the cycle</li>
</ul></li>
<li>Update the cyclic factor in a similar way i.e.:
<ul class="org-ul">
<li>\(C_t = \gamma(x_t/S_t) + (1-\gamma)(C_{t-L})\)</li>
<li>C<sub>1</sub>, &#x2026;, C<sub>L</sub> = 1
<ul class="org-ul">
<li>meaning there's no initial cyclic effect</li>
</ul></li>
<li>If C = 1.1 on Sunday:
<ul class="org-ul">
<li>sales are higher by 10% just because it's Sunday</li>
</ul></li>
</ul></li>
<li>Initial values: first \(L\) are set to 1. Multiplying by 1 = no effect</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org52e7994" class="outline-4">
<h4 id="org52e7994"><span class="section-number-4">7.2.3.</span> Summary</h4>
<div class="outline-text-4" id="text-7-2-3">
<ul class="org-ul">
<li>Exponential smoothing
<ul class="org-ul">
<li>Single</li>
<li>Double (with trend)</li>
<li>Triple (with trend and cyclic effects)
<ul class="org-ul">
<li>AKA Winter's method, or Holt-Winters</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgcba411c" class="outline-3">
<h3 id="orgcba411c"><span class="section-number-3">7.3.</span> M7L3: Etymology (what the name means)</h3>
<div class="outline-text-3" id="text-7-3">
<p>
Example equation when \(\alpha = \frac{1}{2}\):
\(S_t = 0.5 x_t + 0.5 S_{t-1}\)
</p>
</div>
<ol class="org-ol">
<li><a id="orge55694a"></a>Smoothing<br />
<div class="outline-text-5" id="text-7-3-0-1">
<ul class="org-ul">
<li>Note: when x<sub>t</sub> is high, S<sub>t</sub> is <b>not</b> as high, as \((1-\alpha)S_{t-1}\) pulls it down</li>
<li>Conversely: when x<sub>t</sub> is low, S<sub>t</sub> is <b>not</b> as low, as \((1-\alpha)S_{t-1}\) pulls it up</li>
<li>Peaks and valleys are smoothed out
<img src="./img/07-smoothed-graph.png" alt="07-smoothed-graph.png" /></li>
</ul>
</div>
</li>
<li><a id="org8e4e154"></a>Exponential<br />
<div class="outline-text-5" id="text-7-3-0-2">
<ul class="org-ul">
<li>Each \(S_{t-1}\) actually contains every previous value of x!
<ul class="org-ul">
<li>When written or expanded out, e.g.
\[
    S_t = \alpha x_t + (1-\alpha)S_{t-1}
    \]
\[
    S_{t} = \alpha x_t + (1-\alpha)[\alpha x_{t-1} + (1-\alpha)S_{t-2}]
    \]
\[
    S_{t} = \alpha x_t + (1-\alpha)\alpha x_{t-1} + (1-\alpha)^2S_{t-2}
    \]</li>
</ul></li>
<li>Each S<sub>t</sub> is weighed by (1-&alpha;) to an increasing <b>exponent</b></li>
<li>This means not only the current observation matters; instead, every past observation contributes to the current baseline estimate</li>
<li>However, more recent observations are more important as they have higher weight</li>
</ul>
</div>
</li>
</ol>
<div id="outline-container-orgb744b4b" class="outline-4">
<h4 id="orgb744b4b"><span class="section-number-4">7.3.1.</span> Summary</h4>
<div class="outline-text-4" id="text-7-3-1">
<ul class="org-ul">
<li>Exponential smoothing smooths out jumps in observed data</li>
<li>It's an exponential weighting of all past observations</li>
<li>More recent observations are more important to the current baseline estimate</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org594737e" class="outline-3">
<h3 id="org594737e"><span class="section-number-3">7.4.</span> M7L4: Forecasting</h3>
<div class="outline-text-3" id="text-7-4">
<ul class="org-ul">
<li>Recap: \(S_t = \alpha x_t + (1-\alpha)S_{t-1}\)</li>
<li>Prediction:
<ul class="org-ul">
<li>\(S_{t+1} = \alpha x_{t+1} + (1-\alpha)S_{t}\)</li>
<li>However x<sub>t+1</sub> is unknown</li>
<li>Best guess for x<sub>t+1</sub> is \(S_t\)</li>
</ul></li>
<li>Our forecast for \(t+1\) is hence (after substituting):
\[
  F_{t+1}=\alpha S_t + (1-\alpha) S_t \\
  F_{t+1} = S_t \\
  F_{t+k} = S_t \text{when } k=1, 2, ...
  \]
<ul class="org-ul">
<li>note that forecast error becomes larger for larger \(k\)</li>
</ul></li>
<li>If including trend:
\[
  S_t = \alpha x_t + (1-\alpha)(S_{t-1}+T_{t-1}) \\
  T_t = \beta (S_t-S_{t-1})+(1-\beta)T_{t-1} \\
  F_{t+1} = S_t + T_t \\
  F_{t+k} = S_t + kT_t, k=1,2,...
  \]
<dl class="org-dl">
<dt>Best estimate of next baseline</dt><dd>the most current baseline estimate</dd>
<dt>Best estimate of the trend</dt><dd>the most current trend estimate</dd>
</dl></li>
<li>If including multiplicative seasonality:
\[
  S_t = \alpha x_t/C_{t-L} + (1-\alpha)(S_{t-1}+T_{t-1})
  F_{t+1} = (S_t+T_t)C_{(t+1)-L}
  \]
<dl class="org-dl">
<dt>Best estimate of next time period seasonal factor</dt><dd>the corresponding (lagged) seasonal factor, i.e. \(C_{t+1}=C_{t+1-L}\)</dd>
</dl></li>
<li>Finding the right &alpha;, &beta;, &gamma;: use optimization, to be covered in future
<ul class="org-ul">
<li>\(\min{(F_t-x_t)^2}\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org2b9366c" class="outline-3">
<h3 id="org2b9366c"><span class="section-number-3">7.5.</span> M3L5: ARIMA</h3>
<div class="outline-text-3" id="text-7-5">
<p>
AutoRegressive Integrated Moving Average.
</p>
<ul class="org-ul">
<li>ARIMA <b>theory</b> is not covered in IAM.</li>
</ul>
</div>
<div id="outline-container-orge4a78b1" class="outline-4">
<h4 id="orge4a78b1"><span class="section-number-4">7.5.1.</span> (I): Differences</h4>
<div class="outline-text-4" id="text-7-5-1">
<ul class="org-ul">
<li>Exponential smoothing assumes <b>stationary</b> data, i.e.
<ul class="org-ul">
<li>mean, variance, other measures are constant over time</li>
</ul></li>
<li>ARIMA works for data that's not stationary
<ul class="org-ul">
<li>if differences in data are stationary
<dl class="org-dl">
<dt>1st order difference D<sub>(1)</sub></dt><dd>difference of consecutive observations, i.e. \(D_{(1)t}=(x_t-x_{t-1})\)</dd>
<dt>2nd order difference D<sub>(2)</sub></dt><dd>difference of the differences i.e.
\(D_{(2)t}=(x_t-x_{t-1})-(x_{t-1}-x_{t-2})\)</dd>
<dt>d<sup>th</sup> order difference D<sub>(d)</sub></dt><dd>diff&#x2026; d times</dd>
</dl></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge9b6ec9" class="outline-4">
<h4 id="orge9b6ec9"><span class="section-number-4">7.5.2.</span> (II): Autogression</h4>
<div class="outline-text-4" id="text-7-5-2">
<ul class="org-ul">
<li>Predicting current values based on previous period's values</li>
<li>Regression: predicting value based on other factors</li>
<li>Auto: use earlier values to predict. Only works with time series</li>
<li>When used to forecast, exponential smoothing is an order-&infin; autoregressive model
<ul class="org-ul">
<li>All previous values are used to make current prediction</li>
</ul></li>
<li>Order-p autoregressive model: S<sub>t</sub> is function of \(\{x_t, x_{t-1}, ..., x_{t-(p-1)}\}\)
<ul class="org-ul">
<li>Only go back \(p\) periods</li>
</ul></li>
<li>ARIMA: combines autoregression and differencing
<ul class="org-ul">
<li>Autoregression on the differences</li>
<li>Use \(p\) time periods of previous observations to predict \(d^{th}\) order differences</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd38e297" class="outline-4">
<h4 id="orgd38e297"><span class="section-number-4">7.5.3.</span> (III): Moving Average</h4>
<div class="outline-text-4" id="text-7-5-3">
<ul class="org-ul">
<li>Use previous errors &epsilon;<sub>t</sub> as predictors
<ul class="org-ul">
<li>\(\epsilon_t = (\hat{x_t}-x_t)\)</li>
</ul></li>
<li>Order-q moving average
<ul class="org-ul">
<li>go back \(q\) time periods</li>
<li>\(\epsilon_{t-1}, \epsilon_{t-2}, ..., \epsilon_{t-q}\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb833a15" class="outline-4">
<h4 id="orgb833a15"><span class="section-number-4">7.5.4.</span> ARIMA model</h4>
<div class="outline-text-4" id="text-7-5-4">
<p>
ARIMA (p,d,q) model
</p>
<ul class="org-ul">
<li>\(d^{th}\) order differences</li>
<li>\(p^{th}\) order autoregression</li>
<li>\(q^{th}\) order moving average</li>
<li><a id="org9e03187"></a>Equation:
\[
  D_{(d)t} = \mu + \sum^p_{i=1}\alpha_i D_{(d)t-i} - \sum^q_{i=1} \theta_i (\hat{x}_{t-i}-x_{t-i})
  \]</li>
<li>Software can find \(d, p, q\)</li>
<li>Extensions
<ol class="org-ol">
<li>Add seasonality (out of scope for IAM)</li>
<li>Specific models:
<dl class="org-dl">
<dt>ARIMA(0,0,0)</dt><dd>white noise</dd>
<dt>ARIMA(0,1,0)</dt><dd>random walk</dd>
<dt>ARIMA(p,0,0)</dt><dd>AR (autoregressive) model</dd>
<dt>ARIMA(0,0,q)</dt><dd>MA (moving avg) model</dd>
<dt>ARIMA(0,1,1)</dt><dd>basic exponential smoothing model</dd>
</dl></li>
</ol></li>
<li>Can be used for short-term forecasting
<ul class="org-ul">
<li>ARIMA is better than ES when data is more stable with fewer peaks, valleys, outliers</li>
<li>ARIMA needs 40+ historical data points to work well</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org27e4b84" class="outline-3">
<h3 id="org27e4b84"><span class="section-number-3">7.6.</span> M7L6: GARCH</h3>
<div class="outline-text-3" id="text-7-6">
<dl class="org-dl">
<dt>GARCH</dt><dd>Generalized Autoregressive Conditional Heteroskedasticity</dd>
</dl>
<p>
To estimate or forecast the variance
</p>
</div>
<div id="outline-container-orgfc82d1e" class="outline-4">
<h4 id="orgfc82d1e"><span class="section-number-4">7.6.1.</span> Variance</h4>
<div class="outline-text-4" id="text-7-6-1">
<ul class="org-ul">
<li>Estimates the amount of error</li>
<li>E.g. forecasting demand for trucks
<ul class="org-ul">
<li>tell you how much forecast might be higher/lower than the actual value you see (later) to plan accordingly</li>
</ul></li>
<li>In investment (portfolio optimization):
<ul class="org-ul">
<li>Balance the expected return in investment with amount of volatility.
<dl class="org-dl">
<dt>Riskier</dt><dd>higher expected return</dd>
<dt>Less risky</dt><dd>lower expected return</dd>
</dl></li>
<li>Variance is a proxy for amount of volatility or risk</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org1d5604d" class="outline-4">
<h4 id="org1d5604d"><span class="section-number-4">7.6.2.</span> GARCH</h4>
<div class="outline-text-4" id="text-7-6-2">
<p>
\[
\sigma^2_t = \omega + \sum^p_{i=1}\beta_i\sigma^2_{t-1}+\sum^q_{i=1} \gamma_i \epsilon^2_{t-i}
\]
It looks very similar to <a href="#org9e03187">ARIMA Equation</a>, but:
<b>Differences</b>:
</p>
<dl class="org-dl">
<dt>GARCH deals with variances and squared errors</dt><dd>ARIMA deals with observations and linear errors</dd>
<dt>GARCH deals with raw variances</dt><dd>ARIMA deals with differences of variances</dd>
</dl>
</div>
</div>
<div id="outline-container-org031bb8d" class="outline-4">
<h4 id="org031bb8d"><span class="section-number-4">7.6.3.</span> Summary - three models for time series analysis</h4>
<div class="outline-text-4" id="text-7-6-3">
<ol class="org-ol">
<li>Exponential smoothing</li>
<li>ARIMA, a generalization of exponential smoothing</li>
<li>GARCH, an ARIMA-like model for analyzing variance</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: W</p>
<p class="date">Created: 2023-02-05 Sun 20:24</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
